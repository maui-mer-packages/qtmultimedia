diff --git a/config.tests/gstreamer/gstreamer.pro b/config.tests/gstreamer/gstreamer.pro
index 02a7e34..6b9843a 100644
--- a/config.tests/gstreamer/gstreamer.pro
+++ b/config.tests/gstreamer/gstreamer.pro
@@ -3,11 +3,10 @@ SOURCES += main.cpp
 CONFIG += link_pkgconfig
 
 PKGCONFIG += \
-    gstreamer-0.10 \
-    gstreamer-base-0.10 \
-    gstreamer-interfaces-0.10 \
-    gstreamer-audio-0.10 \
-    gstreamer-video-0.10 \
-    gstreamer-pbutils-0.10
+    gstreamer-$$GST_VERSION \
+    gstreamer-base-$$GST_VERSION \
+    gstreamer-audio-$$GST_VERSION \
+    gstreamer-video-$$GST_VERSION \
+    gstreamer-pbutils-$$GST_VERSION
 
 
diff --git a/config.tests/gstreamer_appsrc/gstreamer_appsrc.pro b/config.tests/gstreamer_appsrc/gstreamer_appsrc.pro
index 9f61703..0f3ca2b 100644
--- a/config.tests/gstreamer_appsrc/gstreamer_appsrc.pro
+++ b/config.tests/gstreamer_appsrc/gstreamer_appsrc.pro
@@ -3,11 +3,8 @@ SOURCES += main.cpp
 CONFIG += link_pkgconfig
 
 PKGCONFIG += \
-    gstreamer-0.10 \
-    gstreamer-base-0.10 \
-    gstreamer-interfaces-0.10 \
-    gstreamer-audio-0.10 \
-    gstreamer-video-0.10 \
-    gstreamer-app-0.10
-
-
+    gstreamer-$$GST_VERSION \
+    gstreamer-base-$$GST_VERSION \
+    gstreamer-audio-$$GST_VERSION \
+    gstreamer-video-$$GST_VERSION \
+    gstreamer-pbutils-$$GST_VERSION
diff --git a/config.tests/gstreamer_encodingprofiles/gstreamer_encodingprofiles.pro b/config.tests/gstreamer_encodingprofiles/gstreamer_encodingprofiles.pro
index 7e8a9e7..fad40b0 100644
--- a/config.tests/gstreamer_encodingprofiles/gstreamer_encodingprofiles.pro
+++ b/config.tests/gstreamer_encodingprofiles/gstreamer_encodingprofiles.pro
@@ -2,11 +2,10 @@ SOURCES += main.cpp
 
 CONFIG += link_pkgconfig
 
-PKGCONFIG += \
-    gstreamer-0.10 \
-    gstreamer-base-0.10 \
-    gstreamer-interfaces-0.10 \
-    gstreamer-audio-0.10 \
-    gstreamer-video-0.10 \
-    gstreamer-pbutils-0.10
 
+PKGCONFIG += \
+    gstreamer-$$GST_VERSION \
+    gstreamer-base-$$GST_VERSION \
+    gstreamer-audio-$$GST_VERSION \
+    gstreamer-video-$$GST_VERSION \
+    gstreamer-pbutils-$$GST_VERSION
diff --git a/config.tests/gstreamer_photography/gstreamer_photography.pro b/config.tests/gstreamer_photography/gstreamer_photography.pro
index 6b530cb..975991f 100644
--- a/config.tests/gstreamer_photography/gstreamer_photography.pro
+++ b/config.tests/gstreamer_photography/gstreamer_photography.pro
@@ -3,12 +3,11 @@ SOURCES += main.cpp
 CONFIG += link_pkgconfig
 
 PKGCONFIG += \
-    gstreamer-0.10 \
-    gstreamer-base-0.10 \
-    gstreamer-interfaces-0.10 \
-    gstreamer-audio-0.10 \
-    gstreamer-video-0.10 \
-    gstreamer-pbutils-0.10
-
-LIBS += -lgstphotography-0.10
+    gstreamer-$$GST_VERSION \
+    gstreamer-base-$$GST_VERSION \
+    gstreamer-audio-$$GST_VERSION \
+    gstreamer-video-$$GST_VERSION \
+    gstreamer-pbutils-$$GST_VERSION
+
+LIBS += -lgstphotography-$$GST_VERSION
 
diff --git a/examples/multimedia/audiooutput/audiooutput.cpp b/examples/multimedia/audiooutput/audiooutput.cpp
index fdb640d..daa7bfd 100644
--- a/examples/multimedia/audiooutput/audiooutput.cpp
+++ b/examples/multimedia/audiooutput/audiooutput.cpp
@@ -66,7 +66,8 @@ Generator::Generator(const QAudioFormat &format,
     :   QIODevice(parent)
     ,   m_pos(0)
 {
-    generateData(format, durationUs, sampleRate);
+    if (format.isValid())
+        generateData(format, durationUs, sampleRate);
 }
 
 Generator::~Generator()
@@ -133,11 +134,13 @@ void Generator::generateData(const QAudioFormat &format, qint64 durationUs, int
 qint64 Generator::readData(char *data, qint64 len)
 {
     qint64 total = 0;
-    while (len - total > 0) {
-        const qint64 chunk = qMin((m_buffer.size() - m_pos), len - total);
-        memcpy(data + total, m_buffer.constData() + m_pos, chunk);
-        m_pos = (m_pos + chunk) % m_buffer.size();
-        total += chunk;
+    if (!m_buffer.isEmpty()) {
+        while (len - total > 0) {
+            const qint64 chunk = qMin((m_buffer.size() - m_pos), len - total);
+            memcpy(data + total, m_buffer.constData() + m_pos, chunk);
+            m_pos = (m_pos + chunk) % m_buffer.size();
+            total += chunk;
+        }
     }
     return total;
 }
diff --git a/examples/multimedia/audiorecorder/audiorecorder.cpp b/examples/multimedia/audiorecorder/audiorecorder.cpp
index c77396b..2291fed 100644
--- a/examples/multimedia/audiorecorder/audiorecorder.cpp
+++ b/examples/multimedia/audiorecorder/audiorecorder.cpp
@@ -47,11 +47,7 @@
 #include "audiorecorder.h"
 #include "qaudiolevel.h"
 
-#if defined(Q_WS_MAEMO_6)
-#include "ui_audiorecorder_small.h"
-#else
 #include "ui_audiorecorder.h"
-#endif
 
 static qreal getPeakValue(const QAudioFormat &format);
 static QVector<qreal> getBufferLevels(const QAudioBuffer &buffer);
diff --git a/examples/multimedia/audiorecorder/audiorecorder.pro b/examples/multimedia/audiorecorder/audiorecorder.pro
index 7ea4c6f..79d6caf 100644
--- a/examples/multimedia/audiorecorder/audiorecorder.pro
+++ b/examples/multimedia/audiorecorder/audiorecorder.pro
@@ -14,11 +14,7 @@ SOURCES = \
     audiorecorder.cpp \
     qaudiolevel.cpp
 
-maemo*: {
-    FORMS += audiorecorder_small.ui
-}else {
-    FORMS += audiorecorder.ui
-}
+FORMS += audiorecorder.ui
 
 target.path = $$[QT_INSTALL_EXAMPLES]/multimedia/audiorecorder
 INSTALLS += target
diff --git a/examples/multimedia/audiorecorder/audiorecorder_small.ui b/examples/multimedia/audiorecorder/audiorecorder_small.ui
deleted file mode 100644
index 2030ab9..0000000
--- a/examples/multimedia/audiorecorder/audiorecorder_small.ui
+++ /dev/null
@@ -1,286 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<ui version="4.0">
- <class>AudioRecorder</class>
- <widget class="QMainWindow" name="AudioRecorder">
-  <property name="geometry">
-   <rect>
-    <x>0</x>
-    <y>0</y>
-    <width>420</width>
-    <height>346</height>
-   </rect>
-  </property>
-  <property name="windowTitle">
-   <string>MainWindow</string>
-  </property>
-  <widget class="QWidget" name="centralwidget">
-   <layout class="QGridLayout" name="gridLayout_5">
-    <item row="0" column="0" colspan="3">
-     <widget class="QScrollArea" name="scrollArea">
-      <property name="focusPolicy">
-       <enum>Qt::ClickFocus</enum>
-      </property>
-      <property name="widgetResizable">
-       <bool>true</bool>
-      </property>
-      <widget class="QWidget" name="scrollAreaWidgetContents">
-       <property name="geometry">
-        <rect>
-         <x>0</x>
-         <y>0</y>
-         <width>400</width>
-         <height>277</height>
-        </rect>
-       </property>
-       <layout class="QGridLayout" name="gridLayout_4">
-        <item row="0" column="0">
-         <widget class="QWidget" name="widget" native="true">
-          <layout class="QGridLayout" name="gridLayout_3">
-           <item row="3" column="0">
-            <widget class="QLabel" name="label_6">
-             <property name="text">
-              <string>Audio Level:</string>
-             </property>
-            </widget>
-           </item>
-           <item row="2" column="0">
-            <spacer name="verticalSpacer">
-             <property name="orientation">
-              <enum>Qt::Vertical</enum>
-             </property>
-             <property name="sizeHint" stdset="0">
-              <size>
-               <width>20</width>
-               <height>29</height>
-              </size>
-             </property>
-            </spacer>
-           </item>
-           <item row="1" column="0">
-            <layout class="QGridLayout" name="gridLayout">
-             <item row="0" column="0">
-              <widget class="QRadioButton" name="constantQualityRadioButton">
-               <property name="text">
-                <string>Quality:</string>
-               </property>
-               <property name="checked">
-                <bool>true</bool>
-               </property>
-              </widget>
-             </item>
-             <item row="0" column="1">
-              <widget class="QRadioButton" name="constantBitrateRadioButton">
-               <property name="text">
-                <string>Bitrate:</string>
-               </property>
-              </widget>
-             </item>
-             <item row="1" column="0">
-              <widget class="QSlider" name="qualitySlider">
-               <property name="sizePolicy">
-                <sizepolicy hsizetype="Expanding" vsizetype="Fixed">
-                 <horstretch>1</horstretch>
-                 <verstretch>0</verstretch>
-                </sizepolicy>
-               </property>
-               <property name="orientation">
-                <enum>Qt::Horizontal</enum>
-               </property>
-              </widget>
-             </item>
-             <item row="1" column="1">
-              <widget class="QComboBox" name="bitrateBox">
-               <property name="enabled">
-                <bool>false</bool>
-               </property>
-               <property name="sizePolicy">
-                <sizepolicy hsizetype="Preferred" vsizetype="Fixed">
-                 <horstretch>1</horstretch>
-                 <verstretch>0</verstretch>
-                </sizepolicy>
-               </property>
-              </widget>
-             </item>
-            </layout>
-           </item>
-           <item row="0" column="0">
-            <layout class="QGridLayout" name="gridLayout_2">
-             <item row="3" column="0">
-              <widget class="QLabel" name="label_4">
-               <property name="text">
-                <string>Sample rate:</string>
-               </property>
-              </widget>
-             </item>
-             <item row="1" column="0">
-              <widget class="QLabel" name="label_2">
-               <property name="text">
-                <string>Audio Codec:</string>
-               </property>
-              </widget>
-             </item>
-             <item row="2" column="1">
-              <widget class="QComboBox" name="containerBox"/>
-             </item>
-             <item row="0" column="1">
-              <widget class="QComboBox" name="audioDeviceBox"/>
-             </item>
-             <item row="3" column="1">
-              <widget class="QComboBox" name="sampleRateBox"/>
-             </item>
-             <item row="1" column="1">
-              <widget class="QComboBox" name="audioCodecBox"/>
-             </item>
-             <item row="2" column="0">
-              <widget class="QLabel" name="label_3">
-               <property name="text">
-                <string>File Container:</string>
-               </property>
-              </widget>
-             </item>
-             <item row="0" column="0">
-              <widget class="QLabel" name="label">
-               <property name="text">
-                <string>Input Device:</string>
-               </property>
-              </widget>
-             </item>
-             <item row="4" column="0">
-              <widget class="QLabel" name="label_5">
-               <property name="text">
-                <string>Channels:</string>
-               </property>
-              </widget>
-             </item>
-             <item row="4" column="1">
-              <widget class="QComboBox" name="channelsBox"/>
-             </item>
-            </layout>
-           </item>
-           <item row="4" column="0">
-            <layout class="QVBoxLayout" name="levelsLayout"/>
-           </item>
-          </layout>
-         </widget>
-        </item>
-       </layout>
-      </widget>
-     </widget>
-    </item>
-    <item row="1" column="0">
-     <widget class="QPushButton" name="outputButton">
-      <property name="text">
-       <string>Output...</string>
-      </property>
-     </widget>
-    </item>
-    <item row="1" column="1">
-     <widget class="QPushButton" name="recordButton">
-      <property name="text">
-       <string>Record</string>
-      </property>
-     </widget>
-    </item>
-    <item row="1" column="2">
-     <widget class="QPushButton" name="pauseButton">
-      <property name="enabled">
-       <bool>false</bool>
-      </property>
-      <property name="text">
-       <string>Pause</string>
-      </property>
-     </widget>
-    </item>
-   </layout>
-  </widget>
-  <widget class="QStatusBar" name="statusbar"/>
- </widget>
- <resources/>
- <connections>
-  <connection>
-   <sender>constantQualityRadioButton</sender>
-   <signal>toggled(bool)</signal>
-   <receiver>qualitySlider</receiver>
-   <slot>setEnabled(bool)</slot>
-   <hints>
-    <hint type="sourcelabel">
-     <x>113</x>
-     <y>197</y>
-    </hint>
-    <hint type="destinationlabel">
-     <x>115</x>
-     <y>223</y>
-    </hint>
-   </hints>
-  </connection>
-  <connection>
-   <sender>constantBitrateRadioButton</sender>
-   <signal>toggled(bool)</signal>
-   <receiver>bitrateBox</receiver>
-   <slot>setEnabled(bool)</slot>
-   <hints>
-    <hint type="sourcelabel">
-     <x>173</x>
-     <y>259</y>
-    </hint>
-    <hint type="destinationlabel">
-     <x>190</x>
-     <y>291</y>
-    </hint>
-   </hints>
-  </connection>
-  <connection>
-   <sender>outputButton</sender>
-   <signal>clicked()</signal>
-   <receiver>AudioRecorder</receiver>
-   <slot>setOutputLocation()</slot>
-   <hints>
-    <hint type="sourcelabel">
-     <x>46</x>
-     <y>340</y>
-    </hint>
-    <hint type="destinationlabel">
-     <x>6</x>
-     <y>302</y>
-    </hint>
-   </hints>
-  </connection>
-  <connection>
-   <sender>recordButton</sender>
-   <signal>clicked()</signal>
-   <receiver>AudioRecorder</receiver>
-   <slot>toggleRecord()</slot>
-   <hints>
-    <hint type="sourcelabel">
-     <x>191</x>
-     <y>340</y>
-    </hint>
-    <hint type="destinationlabel">
-     <x>113</x>
-     <y>317</y>
-    </hint>
-   </hints>
-  </connection>
-  <connection>
-   <sender>pauseButton</sender>
-   <signal>clicked()</signal>
-   <receiver>AudioRecorder</receiver>
-   <slot>togglePause()</slot>
-   <hints>
-    <hint type="sourcelabel">
-     <x>252</x>
-     <y>334</y>
-    </hint>
-    <hint type="destinationlabel">
-     <x>258</x>
-     <y>346</y>
-    </hint>
-   </hints>
-  </connection>
- </connections>
- <slots>
-  <slot>setOutputLocation()</slot>
-  <slot>toggleRecord()</slot>
-  <slot>togglePause()</slot>
- </slots>
-</ui>
diff --git a/examples/multimedia/declarative-camera/declarative-camera.qml b/examples/multimedia/declarative-camera/declarative-camera.qml
index b22d5cf..6db45af 100644
--- a/examples/multimedia/declarative-camera/declarative-camera.qml
+++ b/examples/multimedia/declarative-camera/declarative-camera.qml
@@ -96,7 +96,7 @@ Rectangle {
 
         videoRecorder {
              resolution: "640x480"
-             frameRate: 15
+             frameRate: 30
         }
     }
 
diff --git a/examples/multimedia/video/doc/src/qmlvideofx.qdoc b/examples/multimedia/video/doc/src/qmlvideofx.qdoc
index edbd369..b241140 100644
--- a/examples/multimedia/video/doc/src/qmlvideofx.qdoc
+++ b/examples/multimedia/video/doc/src/qmlvideofx.qdoc
@@ -181,8 +181,7 @@ that the divider should be displayed.
 
 The main.qml file shows a
 \l{video/qmlvideofx/qml/qmlvideofx/FileOpen.qml}{FileOpen}, which allows
-the user to select the input source and an
-\l{video/qmlvideofx/qml/qmlvideofx/EffectSelectionPanel.qml}{EffectSelectionPanel}
+the user to select the input source and an EffectSelectionPanel
 item, which lists each of the available shader effects.  As described above, a
 \l{video/qmlvideofx/qml/qmlvideofx/Content.qml}{Content} item is used to load the
 appropriate input and effect type.  A
diff --git a/examples/multimediawidgets/camera/camera.cpp b/examples/multimediawidgets/camera/camera.cpp
index abbbf83..3afe593 100644
--- a/examples/multimediawidgets/camera/camera.cpp
+++ b/examples/multimediawidgets/camera/camera.cpp
@@ -53,10 +53,6 @@
 
 #include <QtWidgets>
 
-#if (defined(Q_WS_MAEMO_6)) && QT_VERSION >= 0x040700
-#define HAVE_CAMERA_BUTTONS
-#endif
-
 Camera::Camera(QWidget *parent) :
     QMainWindow(parent),
     ui(new Ui::Camera),
@@ -88,10 +84,6 @@ Camera::Camera(QWidget *parent) :
     connect(videoDevicesGroup, SIGNAL(triggered(QAction*)), SLOT(updateCameraDevice(QAction*)));
     connect(ui->captureWidget, SIGNAL(currentChanged(int)), SLOT(updateCaptureMode()));
 
-#ifdef HAVE_CAMERA_BUTTONS
-    ui->lockButton->hide();
-#endif
-
     setCamera(cameraDevice);
 }
 
diff --git a/examples/multimediawidgets/player/main.cpp b/examples/multimediawidgets/player/main.cpp
index 3009d29..60867ce 100644
--- a/examples/multimediawidgets/player/main.cpp
+++ b/examples/multimediawidgets/player/main.cpp
@@ -44,10 +44,6 @@
 
 int main(int argc, char *argv[])
 {
-#ifdef Q_WS_MAEMO_6
-    //Meego graphics system conflicts with xvideo during fullscreen transition
-    QApplication::setGraphicsSystem("raster");
-#endif
     QApplication app(argc, argv);
 
     Player player;
diff --git a/qtmultimedia.pro b/qtmultimedia.pro
index c7f093c..1b52a90 100644
--- a/qtmultimedia.pro
+++ b/qtmultimedia.pro
@@ -21,10 +21,25 @@ win32 {
 } else {
     qtCompileTest(alsa)
     qtCompileTest(pulseaudio)
-    qtCompileTest(gstreamer) {
-        qtCompileTest(gstreamer_photography)
-        qtCompileTest(gstreamer_encodingprofiles)
-        qtCompileTest(gstreamer_appsrc)
+    !done_config_gstreamer {
+        gstver=1.0
+        !isEmpty(GST_VERSION): gstver=GST_VERSION
+        cache(GST_VERSION, set, gstver);
+        qtCompileTest(gstreamer) {
+            qtCompileTest(gstreamer_photography)
+            qtCompileTest(gstreamer_encodingprofiles)
+            qtCompileTest(gstreamer_appsrc)
+        } else {
+            gstver=0.10
+            cache(GST_VERSION, set, gstver);
+            # Force a re-run of the test
+            CONFIG -= done_config_gstreamer
+            qtCompileTest(gstreamer) {
+                qtCompileTest(gstreamer_photography)
+                qtCompileTest(gstreamer_encodingprofiles)
+                qtCompileTest(gstreamer_appsrc)
+            }
+        }
     }
     qtCompileTest(resourcepolicy)
     qtCompileTest(gpu_vivante)
diff --git a/src/gsttools/gsttools.pro b/src/gsttools/gsttools.pro
index 15edd04..8ac4179 100644
--- a/src/gsttools/gsttools.pro
+++ b/src/gsttools/gsttools.pro
@@ -2,6 +2,7 @@ TEMPLATE = lib
 
 TARGET = qgsttools_p
 QPRO_PWD = $$PWD
+
 QT = core-private multimedia-private gui-private
 
 !static:DEFINES += QT_MAKEDLL
@@ -15,15 +16,16 @@ LIBS_PRIVATE += \
 
 CONFIG += link_pkgconfig
 
-PKGCONFIG_PRIVATE += \
-    gstreamer-0.10 \
-    gstreamer-base-0.10 \
-    gstreamer-interfaces-0.10 \
-    gstreamer-audio-0.10 \
-    gstreamer-video-0.10 \
-    gstreamer-pbutils-0.10
+PKGCONFIG += \
+    gstreamer-$$GST_VERSION \
+    gstreamer-base-$$GST_VERSION \
+    gstreamer-audio-$$GST_VERSION \
+    gstreamer-video-$$GST_VERSION \
+    gstreamer-pbutils-$$GST_VERSION
+
+equals(GST_VERSION,"0.10"): PKGCONFIG_PRIVATE += gstreamer-interfaces-$$GST_VERSION
 
-maemo*: PKGCONFIG_PRIVATE +=gstreamer-plugins-bad-0.10
+equals(GST_VERSION,"0.10"): maemo*: PKGCONFIG_PRIVATE +=gstreamer-plugins-bad-0.10
 
 config_resourcepolicy {
     DEFINES += HAVE_RESOURCE_POLICY
@@ -33,8 +35,10 @@ config_resourcepolicy {
 # Header files must go inside source directory of a module
 # to be installed by syncqt.
 INCLUDEPATH += ../multimedia/gsttools_headers/
+INCLUDEPATH += ../plugins/gstreamer/mediaplayer/
 VPATH += ../multimedia/gsttools_headers/
 
+# FIXME: Move qgstreamermirtexturerenderer_p.h and .c to section like maemo6
 PRIVATE_HEADERS += \
     qgstbufferpoolinterface_p.h \
     qgstreamerbushelper_p.h \
@@ -42,6 +46,7 @@ PRIVATE_HEADERS += \
     qgstutils_p.h \
     qgstvideobuffer_p.h \
     qvideosurfacegstsink_p.h \
+    qgstreamerbufferprobe_p.h \
     qgstreamervideorendererinterface_p.h \
     qgstreameraudioinputselector_p.h \
     qgstreamervideorenderer_p.h \
@@ -53,12 +58,11 @@ PRIVATE_HEADERS += \
     qgstreamervideowindow_p.h
 
 SOURCES += \
-    qgstbufferpoolinterface.cpp \
     qgstreamerbushelper.cpp \
     qgstreamermessage.cpp \
     qgstutils.cpp \
     qgstvideobuffer.cpp \
-    qvideosurfacegstsink.cpp \
+    qgstreamerbufferprobe.cpp \
     qgstreamervideorendererinterface.cpp \
     qgstreameraudioinputselector.cpp \
     qgstreamervideorenderer.cpp \
@@ -79,25 +83,49 @@ qtHaveModule(widgets) {
         qgstreamervideowidget.cpp
 }
 
-maemo6 {
-    PKGCONFIG_PRIVATE += qmsystem2
+equals(GST_VERSION,"0.10") {
+    SOURCES += \
+            qgstbufferpoolinterface.cpp \
+            qvideosurfacegstsink.cpp \
+
+    maemo6 {
+        PKGCONFIG_PRIVATE += qmsystem2
+
+        contains(QT_CONFIG, opengles2):qtHaveModule(widgets) {
+            PRIVATE_HEADERS += qgstreamergltexturerenderer_p.h
+            SOURCES += qgstreamergltexturerenderer.cpp
+            QT += opengl
+            LIBS_PRIVATE += -lEGL -lgstmeegointerfaces-0.10
+        }
+    }
+} else {
+    HEADERS += \
+        qgstvideorendererplugin_p.h \
+        qgstvideorenderersink_p.h
+
+    SOURCES += \
+        qgstvideorendererplugin.cpp \
+        qgstvideorenderersink.cpp
+}
 
+mir: {
     contains(QT_CONFIG, opengles2):qtHaveModule(widgets) {
-        PRIVATE_HEADERS += qgstreamergltexturerenderer_p.h
-        SOURCES += qgstreamergltexturerenderer.cpp
-        QT += opengl
-        LIBS_PRIVATE += -lEGL -lgstmeegointerfaces-0.10
+        PRIVATE_HEADERS += qgstreamermirtexturerenderer_p.h
+        SOURCES += qgstreamermirtexturerenderer.cpp
+        QT += opengl quick
+        LIBS += -lEGL
     }
+    DEFINES += HAVE_MIR
 }
 
 config_gstreamer_appsrc {
-    PKGCONFIG_PRIVATE += gstreamer-app-0.10
+    PKGCONFIG_PRIVATE += gstreamer-app-$$GST_VERSION
     PRIVATE_HEADERS += qgstappsrc_p.h
     SOURCES += qgstappsrc.cpp
 
     DEFINES += HAVE_GST_APPSRC
 
-    LIBS_PRIVATE += -lgstapp-0.10
+    LIBS_PRIVATE += -lgstapp-$$GST_VERSION
 }
 
 HEADERS += $$PRIVATE_HEADERS
diff --git a/src/gsttools/gstvideoconnector.c b/src/gsttools/gstvideoconnector.c
index 3e08fe5..374371d 100644
--- a/src/gsttools/gstvideoconnector.c
+++ b/src/gsttools/gstvideoconnector.c
@@ -67,26 +67,93 @@ GST_STATIC_PAD_TEMPLATE ("src",
                          GST_PAD_ALWAYS,
                          GST_STATIC_CAPS_ANY);
 
+
+#if GST_CHECK_VERSION(1,0,0)
+
+G_DEFINE_TYPE(GstVideoConnector, gst_video_connector, GST_TYPE_ELEMENT);
+#else
 #define _do_init(bla) \
     GST_DEBUG_CATEGORY_INIT (video_connector_debug, \
     "video-connector", 0, "An identity like element for reconnecting video stream");
 
 GST_BOILERPLATE_FULL (GstVideoConnector, gst_video_connector, GstElement,
                       GST_TYPE_ELEMENT, _do_init);
+#endif
 
 static void gst_video_connector_dispose (GObject * object);
+
+#if GST_CHECK_VERSION(1,0,0)
+static GstFlowReturn gst_video_connector_chain (GstPad * pad, GstObject* parent, GstBuffer * buf);
+#else
 static GstFlowReturn gst_video_connector_chain (GstPad * pad, GstBuffer * buf);
 static GstFlowReturn gst_video_connector_buffer_alloc (GstPad * pad,
                                                        guint64 offset, guint size, GstCaps * caps, GstBuffer ** buf);
+#endif
+
 static GstStateChangeReturn gst_video_connector_change_state (GstElement *
                                                               element, GstStateChange transition);
+
+#if GST_CHECK_VERSION(1,0,0)
+static gboolean gst_video_connector_handle_sink_event (GstPad * pad, GstObject* parent,
+                                                       GstEvent * event);
+#else
 static gboolean gst_video_connector_handle_sink_event (GstPad * pad,
                                                        GstEvent * event);
+#endif
+
+#if GST_CHECK_VERSION(1,0,0)
+static GstPadProbeReturn gst_video_connector_new_buffer_probe(GstPad *pad, GstPadProbeInfo *info, gpointer object);
+static GstPadProbeReturn gst_video_connector_new_event_probe(GstPad *pad, GstPadProbeInfo *info, gpointer object);
+static GstPadProbeReturn gst_video_connector_new_query_probe(GstPad *pad, GstPadProbeInfo *info, gpointer object);
+#else
 static gboolean gst_video_connector_new_buffer_probe(GstObject *pad, GstBuffer *buffer, guint * object);
-static void gst_video_connector_resend_new_segment(GstElement * element, gboolean emitFailedSignal);
 static gboolean gst_video_connector_setcaps (GstPad  *pad, GstCaps *caps);
 static GstCaps *gst_video_connector_getcaps (GstPad * pad);
 static gboolean gst_video_connector_acceptcaps (GstPad * pad, GstCaps * caps);
+#endif
+
+static void gst_video_connector_resend_new_segment(GstElement * element, gboolean emitFailedSignal);
+
+#if GST_CHECK_VERSION(1,0,0)
+static void
+gst_video_connector_class_init (GstVideoConnectorClass * klass)
+{
+    GObjectClass *gobject_class = G_OBJECT_CLASS (klass);
+    GstElementClass *gstelement_class = GST_ELEMENT_CLASS (klass);
+
+    gst_element_class_set_details_simple (gstelement_class, "Video Connector",
+                                          "Generic",
+                                          "An identity like element used for reconnecting video stream",
+                                          "Dmytro Poplavskiy <dmytro.poplavskiy@nokia.com>");
+    gst_element_class_add_pad_template (gstelement_class,
+                                        gst_static_pad_template_get (&gst_video_connector_sink_factory));
+    gst_element_class_add_pad_template (gstelement_class,
+                                        gst_static_pad_template_get (&gst_video_connector_src_factory));
+
+    gst_video_connector_parent_class = g_type_class_peek_parent (klass);
+
+    gobject_class->dispose = gst_video_connector_dispose;
+    gstelement_class->change_state = gst_video_connector_change_state;
+    klass->resend_new_segment = gst_video_connector_resend_new_segment;
+
+    gst_video_connector_signals[SIGNAL_RESEND_NEW_SEGMENT] =
+            g_signal_new ("resend-new-segment", G_TYPE_FROM_CLASS (klass),
+                          G_SIGNAL_RUN_LAST | G_SIGNAL_ACTION,
+                          G_STRUCT_OFFSET (GstVideoConnectorClass, resend_new_segment), NULL, NULL,
+                          g_cclosure_marshal_VOID__BOOLEAN, G_TYPE_NONE, 1, G_TYPE_BOOLEAN);
+
+    gst_video_connector_signals[SIGNAL_CONNECTION_FAILED] =
+            g_signal_new ("connection-failed", G_TYPE_FROM_CLASS (klass),
+                          G_SIGNAL_RUN_LAST,
+                          0, NULL, NULL,
+                          g_cclosure_marshal_VOID__VOID, G_TYPE_NONE, 0);
+
+    GST_DEBUG_CATEGORY_INIT(video_connector_debug, "video-connector", 0,
+                            "An identity like element for reconnecting video stream");
+
+}
+
+#else
 
 static void
 gst_video_connector_base_init (gpointer g_class)
@@ -128,18 +195,33 @@ gst_video_connector_class_init (GstVideoConnectorClass * klass)
                           g_cclosure_marshal_VOID__VOID, G_TYPE_NONE, 0);
 }
 
+#endif
+
 static void
-gst_video_connector_init (GstVideoConnector *element,
-                          GstVideoConnectorClass *g_class)
+gst_video_connector_init (GstVideoConnector *element
+#if GST_CHECK_VERSION(1,0,0)
+#else
+                          ,GstVideoConnectorClass *g_class
+#endif
+                          )
 {
+#if GST_CHECK_VERSION(1,0,0)
+#else
     (void) g_class;
+#endif
     element->sinkpad =
             gst_pad_new_from_static_template (&gst_video_connector_sink_factory,
                                               "sink");
     gst_pad_set_chain_function(element->sinkpad,
                                GST_DEBUG_FUNCPTR (gst_video_connector_chain));
+#if GST_CHECK_VERSION(1,0,0)
+    /* gstreamer 1.x uses QUERIES and EVENTS for allocation and caps handiling purposes */
+    GST_OBJECT_FLAG_SET (element->sinkpad, GST_PAD_FLAG_PROXY_CAPS);
+    GST_OBJECT_FLAG_SET (element->sinkpad, GST_PAD_FLAG_PROXY_ALLOCATION);
+#else
     gst_pad_set_event_function(element->sinkpad,
                                GST_DEBUG_FUNCPTR (gst_video_connector_handle_sink_event));
+
     gst_pad_set_bufferalloc_function(element->sinkpad,
                                      GST_DEBUG_FUNCPTR (gst_video_connector_buffer_alloc));
     gst_pad_set_setcaps_function(element->sinkpad,
@@ -148,14 +230,23 @@ gst_video_connector_init (GstVideoConnector *element,
                                GST_DEBUG_FUNCPTR(gst_video_connector_getcaps));
     gst_pad_set_acceptcaps_function(element->sinkpad,
                                GST_DEBUG_FUNCPTR(gst_video_connector_acceptcaps));
-
+#endif
     gst_element_add_pad (GST_ELEMENT (element), element->sinkpad);
 
     element->srcpad =
             gst_pad_new_from_static_template (&gst_video_connector_src_factory,
                                               "src");
+#if GST_CHECK_VERSION(1,0,0)
+    gst_pad_add_probe(element->srcpad, GST_PAD_PROBE_TYPE_BUFFER,
+                             gst_video_connector_new_buffer_probe, element, NULL);
+    gst_pad_add_probe(element->srcpad, GST_PAD_PROBE_TYPE_QUERY_DOWNSTREAM,
+                             gst_video_connector_new_query_probe, element, NULL);
+    gst_pad_add_probe(element->sinkpad, GST_PAD_PROBE_TYPE_EVENT_DOWNSTREAM,
+                             gst_video_connector_new_event_probe, element, NULL);
+#else
     gst_pad_add_buffer_probe(element->srcpad,
                              G_CALLBACK(gst_video_connector_new_buffer_probe), element);
+#endif
     gst_element_add_pad (GST_ELEMENT (element), element->srcpad);
 
     element->relinked = FALSE;
@@ -183,9 +274,16 @@ gst_video_connector_dispose (GObject * object)
 
     gst_video_connector_reset (element);
 
+#if GST_CHECK_VERSION(1,0,0)
+    G_OBJECT_CLASS (gst_video_connector_parent_class)->dispose (object);
+#else
     G_OBJECT_CLASS (parent_class)->dispose (object);
+#endif
 }
 
+#if GST_CHECK_VERSION(1,0,0)
+/* For gstreamer 1.x we handle it in ALLOCATION Query */
+#else
 // "When this function returns anything else than GST_FLOW_OK,
 // the buffer allocation failed and buf does not contain valid data."
 static GstFlowReturn
@@ -229,6 +327,7 @@ gst_video_connector_buffer_alloc (GstPad * pad, guint64 offset, guint size,
                 if (state == GST_STATE_NULL) {
                     GST_DEBUG_OBJECT (element, "Downstream element is in NULL state");
                     // Downstream filter seems to be in the wrong state
+
                     return GST_FLOW_UNEXPECTED;
                 }
             }
@@ -301,6 +400,7 @@ static GstCaps *gst_video_connector_getcaps (GstPad * pad)
     return caps;
 }
 
+
 static gboolean gst_video_connector_acceptcaps (GstPad * pad, GstCaps * caps)
 {
     GstVideoConnector *element;
@@ -308,6 +408,7 @@ static gboolean gst_video_connector_acceptcaps (GstPad * pad, GstCaps * caps)
 
     return gst_pad_peer_accept_caps(element->srcpad, caps);
 }
+#endif
 
 static void
 gst_video_connector_resend_new_segment(GstElement * element, gboolean emitFailedSignal)
@@ -319,11 +420,39 @@ gst_video_connector_resend_new_segment(GstElement * element, gboolean emitFailed
         connector->failedSignalEmited = FALSE;
 }
 
+#if GST_CHECK_VERSION(1,0,0)
+static GstPadProbeReturn gst_video_connector_new_event_probe(GstPad *pad, GstPadProbeInfo *info, gpointer object)
+{
+    GstVideoConnector *connector = GST_VIDEO_CONNECTOR (object);
+    GstEvent *event = gst_pad_probe_info_get_event(info);
+
+    GST_DEBUG_OBJECT(connector, "Event %"GST_PTR_FORMAT" received\n", event);
+
+    return GST_PAD_PROBE_OK;
+}
+
+static GstPadProbeReturn gst_video_connector_new_query_probe(GstPad *pad, GstPadProbeInfo *info, gpointer object)
+{
+    GstVideoConnector *connector = GST_VIDEO_CONNECTOR (object);
+    GstQuery *query = gst_pad_probe_info_get_query(info);
+
+    GST_DEBUG_OBJECT(connector, "Query %"GST_PTR_FORMAT" received\n", query);
+
+    return GST_PAD_PROBE_OK;
+}
+#endif
 
+#if GST_CHECK_VERSION(1,0,0)
+static GstPadProbeReturn gst_video_connector_new_buffer_probe(GstPad *pad, GstPadProbeInfo *info, gpointer object)
+{
+    (void) info;
+#else
 static gboolean gst_video_connector_new_buffer_probe(GstObject *pad, GstBuffer *buffer, guint * object)
 {
-    (void) pad;
     (void) buffer;
+#endif
+    (void) pad;
+
 
     GstVideoConnector *element = GST_VIDEO_CONNECTOR (object);
 
@@ -335,16 +464,27 @@ static gboolean gst_video_connector_new_buffer_probe(GstObject *pad, GstBuffer *
     if (element->relinked)
         GST_LOG_OBJECT(element, "rejected buffer because of new segment request");
 
+#if GST_CHECK_VERSION(1,0,0)
+    return element->relinked ? GST_PAD_PROBE_DROP : GST_PAD_PROBE_OK;
+#else
     return !element->relinked;
+#endif
 }
 
-
 static GstFlowReturn
+#if GST_CHECK_VERSION(1,0,0)
+gst_video_connector_chain (GstPad * pad, GstObject* parent, GstBuffer * buf)
+#else
 gst_video_connector_chain (GstPad * pad, GstBuffer * buf)
+#endif
 {
     GstFlowReturn res;
     GstVideoConnector *element;
 
+#if GST_CHECK_VERSION(1,0,0)
+    (void)parent;
+#endif
+
     element = GST_VIDEO_CONNECTOR (gst_pad_get_parent (pad));
 
     do {
@@ -356,20 +496,29 @@ gst_video_connector_chain (GstPad * pad, GstBuffer * buf)
         */
         while (element->relinked) {
             element->relinked = FALSE;
-
+#if GST_CHECK_VERSION(1,0,0)
+            if (element->latest_buffer && GST_BUFFER_TIMESTAMP_IS_VALID(element->latest_buffer)) {
+                element->segment.position = GST_BUFFER_TIMESTAMP (element->latest_buffer);
+            }
+#else
             gint64 pos = element->segment.last_stop;
-
             if (element->latest_buffer && GST_BUFFER_TIMESTAMP_IS_VALID(element->latest_buffer)) {
                 pos = GST_BUFFER_TIMESTAMP (element->latest_buffer);
             }
+#endif
 
             //push a new segment and last buffer
+#if GST_CHECK_VERSION(1,0,0)
+            GstEvent *ev = gst_event_new_segment (&element->segment);
+
+#else
             GstEvent *ev = gst_event_new_new_segment (TRUE,
                                                       element->segment.rate,
                                                       element->segment.format,
                                                       pos, //start
                                                       element->segment.stop,
                                                       pos);
+#endif
 
             GST_DEBUG_OBJECT (element, "Pushing new segment event");
             if (!gst_pad_push_event (element->srcpad, ev)) {
@@ -432,8 +581,11 @@ gst_video_connector_change_state (GstElement * element,
     GstStateChangeReturn result;
 
     connector = GST_VIDEO_CONNECTOR(element);
+#if GST_CHECK_VERSION(1,0,0)
+    result = GST_ELEMENT_CLASS (gst_video_connector_parent_class)->change_state(element, transition);
+#else
     result = GST_ELEMENT_CLASS (parent_class)->change_state(element, transition);
-
+#endif
     switch (transition) {
     case GST_STATE_CHANGE_PAUSED_TO_READY:
         gst_video_connector_reset (connector);
@@ -448,8 +600,29 @@ gst_video_connector_change_state (GstElement * element,
     return result;
 }
 
-static gboolean
-gst_video_connector_handle_sink_event (GstPad * pad, GstEvent * event)
+#if GST_CHECK_VERSION(1,0,0)
+static gboolean gst_video_connector_handle_sink_event (GstPad * pad, GstObject* parent,
+                                                       GstEvent * event)
+{
+    GstVideoConnector *element = GST_VIDEO_CONNECTOR (gst_pad_get_parent (pad));
+
+    switch (GST_EVENT_TYPE (event)) {
+      case GST_EVENT_SEGMENT:
+      break;
+      case GST_EVENT_CAPS:
+      break;
+    default:
+      break;
+    }
+
+    gst_object_unref (element);
+    return gst_pad_event_default (pad, parent, event);
+}
+
+#else
+
+static gboolean gst_video_connector_handle_sink_event (GstPad * pad,
+                                                       GstEvent * event)
 {
     if (GST_EVENT_TYPE (event) == GST_EVENT_NEWSEGMENT) {
         GstVideoConnector *element = GST_VIDEO_CONNECTOR (gst_pad_get_parent (pad));
@@ -461,7 +634,6 @@ gst_video_connector_handle_sink_event (GstPad * pad, GstEvent * event)
 
         gst_event_parse_new_segment_full (event, &update, &rate, &arate, &format,
                                           &start, &stop, &time);
-
         GST_LOG_OBJECT (element,
                           "NEWSEGMENT update %d, rate %lf, applied rate %lf, "
                           "format %d, " "%" G_GINT64_FORMAT " -- %" G_GINT64_FORMAT ", time %"
@@ -469,9 +641,10 @@ gst_video_connector_handle_sink_event (GstPad * pad, GstEvent * event)
 
         gst_segment_set_newsegment_full (&element->segment, update,
                                          rate, arate, format, start, stop, time);
-
         gst_object_unref (element);
     }
 
     return gst_pad_event_default (pad, event);
 }
+
+#endif
diff --git a/src/gsttools/qgstappsrc.cpp b/src/gsttools/qgstappsrc.cpp
index 2c9f64c..cc046af 100644
--- a/src/gsttools/qgstappsrc.cpp
+++ b/src/gsttools/qgstappsrc.cpp
@@ -51,7 +51,7 @@ QGstAppSrc::QGstAppSrc(QObject *parent)
     ,m_sequential(false)
     ,m_maxBytes(0)
     ,m_setup(false)
-    ,m_dataRequestSize(-1)
+    ,m_dataRequestSize(~0)
     ,m_dataRequested(false)
     ,m_enoughData(false)
     ,m_forceData(false)
@@ -102,7 +102,7 @@ void QGstAppSrc::setStream(QIODevice *stream)
     if (m_appSrc)
         gst_object_unref(G_OBJECT(m_appSrc));
 
-    m_dataRequestSize = -1;
+    m_dataRequestSize = ~0;
     m_dataRequested = false;
     m_enoughData = false;
     m_forceData = false;
@@ -149,29 +149,50 @@ void QGstAppSrc::pushDataToAppSrc()
 
     if (m_dataRequested && !m_enoughData) {
         qint64 size;
-        if (m_dataRequestSize == (unsigned int)-1)
+        if (m_dataRequestSize == ~0)
             size = qMin(m_stream->bytesAvailable(), queueSize());
         else
             size = qMin(m_stream->bytesAvailable(), (qint64)m_dataRequestSize);
 
         if (size) {
-            void *data = g_malloc(size);
-            GstBuffer* buffer = gst_app_buffer_new(data, size, g_free, data);
+            GstBuffer* buffer = gst_buffer_new_and_alloc(size);
+
+#if GST_CHECK_VERSION(1,0,0)
+            GstMapInfo mapInfo;
+            gst_buffer_map(buffer, &mapInfo, GST_MAP_WRITE);
+            void* bufferData = mapInfo.data;
+#else
+            void* bufferData = GST_BUFFER_DATA(buffer);
+#endif
+            
             buffer->offset = m_stream->pos();
-            qint64 bytesRead = m_stream->read((char*)GST_BUFFER_DATA(buffer), size);
+            qint64 bytesRead = m_stream->read((char*)bufferData, size);
             buffer->offset_end =  buffer->offset + bytesRead - 1;
 
+#if GST_CHECK_VERSION(1,0,0)
+            gst_buffer_unmap(buffer, &mapInfo);
+#endif
+            
             if (bytesRead > 0) {
                 m_dataRequested = false;
                 m_enoughData = false;
                 GstFlowReturn ret = gst_app_src_push_buffer (GST_APP_SRC (element()), buffer);
                 if (ret == GST_FLOW_ERROR) {
                     qWarning()<<"appsrc: push buffer error";
+#if GST_CHECK_VERSION(1,0,0)
+                } else if (ret == GST_FLOW_FLUSHING) {
+                    qWarning()<<"appsrc: push buffer wrong state";
+                }
+#else
                 } else if (ret == GST_FLOW_WRONG_STATE) {
                     qWarning()<<"appsrc: push buffer wrong state";
-                } else if (ret == GST_FLOW_RESEND) {
+                }
+#endif
+#if GST_VERSION_MAJOR < 1
+                else if (ret == GST_FLOW_RESEND) {
                     qWarning()<<"appsrc: push buffer resend";
                 }
+#endif
             }
         } else {
             sendEOS();
diff --git a/src/gsttools/qgstcodecsinfo.cpp b/src/gsttools/qgstcodecsinfo.cpp
index 6db9b01..150a069 100644
--- a/src/gsttools/qgstcodecsinfo.cpp
+++ b/src/gsttools/qgstcodecsinfo.cpp
@@ -40,7 +40,7 @@
 ****************************************************************************/
 
 #include "qgstcodecsinfo_p.h"
-
+#include "qgstutils_p.h"
 #include <QtCore/qset.h>
 
 #ifdef QMEDIA_GSTREAMER_CAMERABIN
@@ -154,7 +154,7 @@ GstCaps* QGstCodecsInfo::supportedElementCaps(GstElementFactoryListType elementT
                     if (fakeEncoderMimeTypes.contains(gst_structure_get_name(structure)))
                         continue;
 
-                    GstStructure *newStructure = gst_structure_new(gst_structure_get_name(structure), NULL);
+                    GstStructure *newStructure = qt_gst_structure_new_empty(gst_structure_get_name(structure));
 
                     //add structure fields to distinguish between formats with similar mime types,
                     //like audio/mpeg
@@ -174,7 +174,11 @@ GstCaps* QGstCodecsInfo::supportedElementCaps(GstElementFactoryListType elementT
                         }
                     }
 
+#if GST_CHECK_VERSION(1,0,0)
+                    res =
+#endif
                     gst_caps_merge_structure(res, newStructure);
+
                 }
                 gst_caps_unref(caps);
             }
diff --git a/src/gsttools/qgstreameraudioprobecontrol.cpp b/src/gsttools/qgstreameraudioprobecontrol.cpp
index 94d07c9..d988e20 100644
--- a/src/gsttools/qgstreameraudioprobecontrol.cpp
+++ b/src/gsttools/qgstreameraudioprobecontrol.cpp
@@ -45,32 +45,48 @@
 QGstreamerAudioProbeControl::QGstreamerAudioProbeControl(QObject *parent)
     : QMediaAudioProbeControl(parent)
 {
-
 }
 
 QGstreamerAudioProbeControl::~QGstreamerAudioProbeControl()
 {
-
 }
 
-void QGstreamerAudioProbeControl::bufferProbed(GstBuffer* buffer)
+void QGstreamerAudioProbeControl::probeCaps(GstCaps *caps)
 {
-    GstCaps* caps = gst_buffer_get_caps(buffer);
-    if (!caps)
-        return;
-
     QAudioFormat format = QGstUtils::audioFormatForCaps(caps);
-    gst_caps_unref(caps);
-    if (!format.isValid())
-        return;
 
-    QAudioBuffer audioBuffer = QAudioBuffer(QByteArray((const char*)buffer->data, buffer->size), format);
+    QMutexLocker locker(&m_bufferMutex);
+    m_format = format;
+}
 
-    {
-        QMutexLocker locker(&m_bufferMutex);
-        m_pendingBuffer = audioBuffer;
-        QMetaObject::invokeMethod(this, "bufferProbed", Qt::QueuedConnection);
+bool QGstreamerAudioProbeControl::probeBuffer(GstBuffer *buffer)
+{
+    qint64 position = GST_BUFFER_TIMESTAMP(buffer);
+    position = position >= 0
+            ? position / G_GINT64_CONSTANT(1000) // microseconds
+            : -1;
+
+    QByteArray data;
+#if GST_CHECK_VERSION(1,0,0)
+    GstMapInfo info;
+    if (gst_buffer_map(buffer, &info, GST_MAP_READ)) {
+        data = QByteArray(reinterpret_cast<const char *>(info.data), info.size);
+        gst_buffer_unmap(buffer, &info);
+    } else {
+        return true;
+    }
+#else
+    data = QByteArray(reinterpret_cast<const char *>(buffer->data), buffer->size);
+#endif
+
+    QMutexLocker locker(&m_bufferMutex);
+    if (m_format.isValid()) {
+        if (!m_pendingBuffer.isValid())
+            QMetaObject::invokeMethod(this, "bufferProbed", Qt::QueuedConnection);
+        m_pendingBuffer = QAudioBuffer(data, m_format, position);
     }
+
+    return true;
 }
 
 void QGstreamerAudioProbeControl::bufferProbed()
@@ -81,6 +97,7 @@ void QGstreamerAudioProbeControl::bufferProbed()
         if (!m_pendingBuffer.isValid())
             return;
         audioBuffer = m_pendingBuffer;
+        m_pendingBuffer = QAudioBuffer();
     }
     emit audioBufferProbed(audioBuffer);
 }
diff --git a/src/gsttools/qgstreamerbufferprobe.cpp b/src/gsttools/qgstreamerbufferprobe.cpp
new file mode 100644
index 0000000..91f8126
--- /dev/null
+++ b/src/gsttools/qgstreamerbufferprobe.cpp
@@ -0,0 +1,174 @@
+/****************************************************************************
+**
+** Copyright (C) 2014 Jolla Ltd.
+** Contact: http://www.qt-project.org/legal
+**
+** This file is part of the Qt Toolkit.
+**
+** $QT_BEGIN_LICENSE:LGPL$
+** Commercial License Usage
+** Licensees holding valid commercial Qt licenses may use this file in
+** accordance with the commercial license agreement provided with the
+** Software or, alternatively, in accordance with the terms contained in
+** a written agreement between you and Digia.  For licensing terms and
+** conditions see http://qt.digia.com/licensing.  For further information
+** use the contact form at http://qt.digia.com/contact-us.
+**
+** GNU Lesser General Public License Usage
+** Alternatively, this file may be used under the terms of the GNU Lesser
+** General Public License version 2.1 as published by the Free Software
+** Foundation and appearing in the file LICENSE.LGPL included in the
+** packaging of this file.  Please review the following information to
+** ensure the GNU Lesser General Public License version 2.1 requirements
+** will be met: http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html.
+**
+** In addition, as a special exception, Digia gives you certain additional
+** rights.  These rights are described in the Digia Qt LGPL Exception
+** version 1.1, included in the file LGPL_EXCEPTION.txt in this package.
+**
+** GNU General Public License Usage
+** Alternatively, this file may be used under the terms of the GNU
+** General Public License version 3.0 as published by the Free Software
+** Foundation and appearing in the file LICENSE.GPL included in the
+** packaging of this file.  Please review the following information to
+** ensure the GNU General Public License version 3.0 requirements will be
+** met: http://www.gnu.org/copyleft/gpl.html.
+**
+**
+** $QT_END_LICENSE$
+**
+****************************************************************************/
+
+#include "qgstreamerbufferprobe_p.h"
+#include "qgstutils_p.h"
+
+QT_BEGIN_NAMESPACE
+
+QGstreamerBufferProbe::QGstreamerBufferProbe(Flags flags)
+#if GST_CHECK_VERSION(1,0,0)
+    : m_capsProbeId(-1)
+#else
+    : m_caps(0)
+#endif
+    , m_bufferProbeId(-1)
+    , m_flags(flags)
+{
+}
+
+QGstreamerBufferProbe::~QGstreamerBufferProbe()
+{
+#if !GST_CHECK_VERSION(1,0,0)
+    if (m_caps)
+        gst_caps_unref(m_caps);
+#endif
+}
+
+void QGstreamerBufferProbe::addProbeToPad(GstPad *pad, bool downstream)
+{
+    if (GstCaps *caps = qt_gst_pad_get_current_caps(pad)) {
+        probeCaps(caps);
+        gst_caps_unref(caps);
+    }
+#if GST_CHECK_VERSION(1,0,0)
+    if (m_flags & ProbeCaps) {
+        m_capsProbeId = gst_pad_add_probe(
+                    pad,
+                    downstream
+                        ? GST_PAD_PROBE_TYPE_EVENT_DOWNSTREAM
+                        : GST_PAD_PROBE_TYPE_EVENT_UPSTREAM,
+                    capsProbe,
+                    this,
+                    NULL);
+    }
+    if (m_flags & ProbeBuffers) {
+        m_bufferProbeId = gst_pad_add_probe(
+                    pad, GST_PAD_PROBE_TYPE_BUFFER, bufferProbe, this, NULL);
+    }
+#else
+    Q_UNUSED(downstream);
+
+    m_bufferProbeId = gst_pad_add_buffer_probe(pad, G_CALLBACK(bufferProbe), this);
+#endif
+}
+
+void QGstreamerBufferProbe::removeProbeFromPad(GstPad *pad)
+{
+#if GST_CHECK_VERSION(1,0,0)
+    if (m_capsProbeId != -1) {
+        gst_pad_remove_probe(pad, m_capsProbeId);
+        m_capsProbeId = -1;
+    }
+    if (m_bufferProbeId != -1) {
+        gst_pad_remove_probe(pad, m_bufferProbeId);
+        m_bufferProbeId = -1;
+    }
+#else
+    if (m_bufferProbeId != -1) {
+        gst_pad_remove_buffer_probe(pad, m_bufferProbeId);
+        m_bufferProbeId = -1;
+        if (m_caps) {
+            gst_caps_unref(m_caps);
+            m_caps = 0;
+        }
+    }
+#endif
+}
+
+void QGstreamerBufferProbe::probeCaps(GstCaps *)
+{
+}
+
+bool QGstreamerBufferProbe::probeBuffer(GstBuffer *)
+{
+    return true;
+}
+
+#if GST_CHECK_VERSION(1,0,0)
+GstPadProbeReturn QGstreamerBufferProbe::capsProbe(
+        GstPad *, GstPadProbeInfo *info, gpointer user_data)
+{
+    QGstreamerBufferProbe * const control = static_cast<QGstreamerBufferProbe *>(user_data);
+
+    if (GstEvent * const event = gst_pad_probe_info_get_event(info)) {
+        if (GST_EVENT_TYPE(event) == GST_EVENT_CAPS) {
+            GstCaps *caps;
+            gst_event_parse_caps(event, &caps);
+
+            control->probeCaps(caps);
+        }
+    }
+    return GST_PAD_PROBE_OK;
+}
+
+GstPadProbeReturn QGstreamerBufferProbe::bufferProbe(
+        GstPad *, GstPadProbeInfo *info, gpointer user_data)
+{
+    QGstreamerBufferProbe * const control = static_cast<QGstreamerBufferProbe *>(user_data);
+    if (GstBuffer * const buffer = gst_pad_probe_info_get_buffer(info))
+        return control->probeBuffer(buffer) ? GST_PAD_PROBE_OK : GST_PAD_PROBE_DROP;
+    return GST_PAD_PROBE_OK;
+}
+#else
+gboolean QGstreamerBufferProbe::bufferProbe(GstElement *, GstBuffer *buffer, gpointer user_data)
+{
+    QGstreamerBufferProbe * const control = static_cast<QGstreamerBufferProbe *>(user_data);
+
+    if (control->m_flags & ProbeCaps) {
+        GstCaps *caps = gst_buffer_get_caps(buffer);
+        if (caps && (!control->m_caps || !gst_caps_is_equal(control->m_caps, caps))) {
+            qSwap(caps, control->m_caps);
+            control->probeCaps(control->m_caps);
+        }
+        if (caps)
+            gst_caps_unref(caps);
+    }
+
+    if (control->m_flags & ProbeBuffers) {
+        return control->probeBuffer(buffer) ? TRUE : FALSE;
+    } else {
+        return TRUE;
+    }
+}
+#endif
+
+QT_END_NAMESPACE
diff --git a/src/gsttools/qgstreamerbushelper.cpp b/src/gsttools/qgstreamerbushelper.cpp
index da7506e..6b4cdd2 100644
--- a/src/gsttools/qgstreamerbushelper.cpp
+++ b/src/gsttools/qgstreamerbushelper.cpp
@@ -162,13 +162,21 @@ QGstreamerBusHelper::QGstreamerBusHelper(GstBus* bus, QObject* parent):
     QObject(parent)
 {
     d = new QGstreamerBusHelperPrivate(this, bus);
+#if GST_CHECK_VERSION(1,0,0)
+    gst_bus_set_sync_handler(bus, (GstBusSyncHandler)syncGstBusFilter, d, 0);
+#else
     gst_bus_set_sync_handler(bus, (GstBusSyncHandler)syncGstBusFilter, d);
+#endif
     gst_object_ref(GST_OBJECT(bus));
 }
 
 QGstreamerBusHelper::~QGstreamerBusHelper()
 {
+#if GST_CHECK_VERSION(1,0,0)
+    gst_bus_set_sync_handler(d->bus(), 0, 0, 0);
+#else
     gst_bus_set_sync_handler(d->bus(),0,0);
+#endif
     gst_object_unref(GST_OBJECT(d->bus()));
 }
 
diff --git a/src/gsttools/qgstreamermirtexturerenderer.cpp b/src/gsttools/qgstreamermirtexturerenderer.cpp
new file mode 100644
index 0000000..5156393
--- /dev/null
+++ b/src/gsttools/qgstreamermirtexturerenderer.cpp
@@ -0,0 +1,360 @@
+/****************************************************************************
+**
+** Copyright (C) 2013 Canonical Ltd.
+** Contact: jim.hodapp@canonical.com
+**
+** This file is part of the Qt Toolkit.
+**
+// TODO: Fix this license
+** $QT_BEGIN_LICENSE:LGPL$
+** Commercial License Usage
+** Licensees holding valid commercial Qt licenses may use this file in
+** accordance with the commercial license agreement provided with the
+** Software or, alternatively, in accordance with the terms contained in
+** a written agreement between you and Digia.  For licensing terms and
+** conditions see http://qt.digia.com/licensing.  For further information
+** use the contact form at http://qt.digia.com/contact-us.
+**
+** GNU Lesser General Public License Usage
+** Alternatively, this file may be used under the terms of the GNU Lesser
+** General Public License version 2.1 as published by the Free Software
+** Foundation and appearing in the file LICENSE.LGPL included in the
+** packaging of this file.  Please review the following information to
+** ensure the GNU Lesser General Public License version 2.1 requirements
+** will be met: http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html.
+**
+** In addition, as a special exception, Digia gives you certain additional
+** rights.  These rights are described in the Digia Qt LGPL Exception
+** version 1.1, included in the file LGPL_EXCEPTION.txt in this package.
+**
+** GNU General Public License Usage
+** Alternatively, this file may be used under the terms of the GNU
+** General Public License version 3.0 as published by the Free Software
+** Foundation and appearing in the file LICENSE.GPL included in the
+** packaging of this file.  Please review the following information to
+** ensure the GNU General Public License version 3.0 requirements will be
+** met: http://www.gnu.org/copyleft/gpl.html.
+**
+**
+** $QT_END_LICENSE$
+**
+****************************************************************************/
+
+#include "qgstreamermirtexturerenderer_p.h"
+
+#include <qgstreamerplayersession.h>
+#include <private/qvideosurfacegstsink_p.h>
+#include <private/qgstutils_p.h>
+#include <qabstractvideosurface.h>
+
+#include <QAbstractVideoBuffer>
+#include <QGuiApplication>
+#include <QDebug>
+#include <QtQuick/QQuickWindow>
+#include <QOpenGLContext>
+#include <QGLContext>
+#include <QGuiApplication>
+#include <qgl.h>
+
+#include <gst/gst.h>
+
+static QGstreamerMirTextureRenderer *rendererInstance = NULL;
+
+class QGstreamerMirTextureBuffer : public QAbstractVideoBuffer
+{
+public:
+    QGstreamerMirTextureBuffer(GLuint textureId) :
+        QAbstractVideoBuffer(QAbstractVideoBuffer::GLTextureHandle),
+        m_textureId(textureId)
+    {
+    }
+
+    MapMode mapMode() const { return NotMapped; }
+
+    uchar *map(MapMode mode, int *numBytes, int *bytesPerLine)
+    {
+        qDebug() << Q_FUNC_INFO;
+        Q_UNUSED(mode);
+        Q_UNUSED(numBytes);
+        Q_UNUSED(bytesPerLine);
+
+        return NULL;
+    }
+
+    void unmap() { qDebug() << Q_FUNC_INFO; }
+
+    QVariant handle() const { return QVariant::fromValue<unsigned int>(m_textureId); }
+
+    GLuint textureId() { return m_textureId; }
+
+private:
+    GLuint m_textureId;
+};
+
+QGstreamerMirTextureRenderer::QGstreamerMirTextureRenderer(QObject *parent
+        , const QGstreamerPlayerSession *playerSession)
+    : QVideoRendererControl(0), m_videoSink(0), m_surface(0),
+      m_glSurface(0),
+      m_context(0),
+      m_glContext(0),
+      m_textureId(0),
+      m_offscreenSurface(0),
+      m_textureBuffer(0)
+{
+    Q_UNUSED(parent);
+    setPlayerSession(playerSession);
+}
+
+QGstreamerMirTextureRenderer::~QGstreamerMirTextureRenderer()
+{
+    if (m_videoSink)
+        gst_object_unref(GST_OBJECT(m_videoSink));
+
+    delete m_glContext;
+    delete m_offscreenSurface;
+}
+
+GstElement *QGstreamerMirTextureRenderer::videoSink()
+{
+    qDebug() << Q_FUNC_INFO;
+
+    // FIXME: Ugly hack until I figure out why passing this segfaults in the g_signal handler
+    rendererInstance = const_cast<QGstreamerMirTextureRenderer*>(this);
+
+    if (!m_videoSink && m_surface) {
+        qDebug() << Q_FUNC_INFO << ": using mirsink, (this: " << this << ")";
+
+        m_videoSink = gst_element_factory_make("mirsink", "video-output");
+
+        connect(QGuiApplication::instance(), SIGNAL(focusWindowChanged(QWindow*)),
+                this, SLOT(handleFocusWindowChanged(QWindow*)), Qt::QueuedConnection);
+
+        g_signal_connect(G_OBJECT(m_videoSink), "frame-ready", G_CALLBACK(handleFrameReady),
+                (gpointer)this);
+    }
+
+    if (m_videoSink) {
+        gst_object_ref_sink(GST_OBJECT(m_videoSink));
+
+        GstPad *pad = gst_element_get_static_pad(m_videoSink, "sink");
+        gst_pad_add_probe(pad, GST_PAD_PROBE_TYPE_BUFFER,
+                padBufferProbe, this, NULL);
+    }
+
+    return m_videoSink;
+}
+
+QWindow *QGstreamerMirTextureRenderer::createOffscreenWindow(const QSurfaceFormat &format)
+{
+    QWindow *w = new QWindow();
+    w->setSurfaceType(QWindow::OpenGLSurface);
+    w->setFormat(format);
+    w->setGeometry(0, 0, 1, 1);
+    w->setFlags(w->flags() | Qt::WindowTransparentForInput);
+    w->create();
+
+    return w;
+}
+
+void QGstreamerMirTextureRenderer::handleFrameReady(gpointer userData)
+{
+    QGstreamerMirTextureRenderer *renderer = reinterpret_cast<QGstreamerMirTextureRenderer*>(userData);
+#if 1
+    QMutexLocker locker(&rendererInstance->m_mutex);
+    QMetaObject::invokeMethod(rendererInstance, "renderFrame", Qt::QueuedConnection);
+#else
+    // FIXME!
+    //QMutexLocker locker(&renderer->m_mutex);
+    QMetaObject::invokeMethod(renderer, "renderFrame", Qt::QueuedConnection);
+#endif
+}
+
+void QGstreamerMirTextureRenderer::renderFrame()
+{
+    //qDebug() << Q_FUNC_INFO;
+
+    if (m_context)
+        m_context->makeCurrent();
+
+    GstState pendingState = GST_STATE_NULL;
+    GstState newState = GST_STATE_NULL;
+    // Don't block and return immediately:
+    GstStateChangeReturn ret = gst_element_get_state(m_videoSink, &newState,
+                                                     &pendingState, 0);
+    if (ret == GST_STATE_CHANGE_FAILURE || newState == GST_STATE_NULL||
+            pendingState == GST_STATE_NULL) {
+        qWarning() << "Invalid state change for renderer, aborting";
+        stopRenderer();
+        return;
+    }
+
+    if (!m_surface->isActive()) {
+        qDebug() << "m_surface is not active";
+        GstPad *pad = gst_element_get_static_pad(m_videoSink, "sink");
+        GstCaps *caps = gst_pad_get_current_caps(pad);
+
+        if (caps) {
+            // Get the native video size from the video sink
+            QSize newNativeSize = QGstUtils::capsCorrectedResolution(caps);
+            if (m_nativeSize != newNativeSize) {
+                m_nativeSize = newNativeSize;
+                emit nativeSizeChanged();
+            }
+            gst_caps_unref(caps);
+        }
+
+        // Start the surface
+        QVideoSurfaceFormat format(m_nativeSize, QVideoFrame::Format_RGB32, QAbstractVideoBuffer::GLTextureHandle);
+        qDebug() << "m_nativeSize: " << m_nativeSize;
+        qDebug() << "format: " << format;
+        if (!m_surface->start(format)) {
+            qWarning() << Q_FUNC_INFO << ": failed to start the video surface " << format;
+            return;
+        }
+    }
+
+    QGstreamerMirTextureBuffer *buffer = new QGstreamerMirTextureBuffer(m_textureId);
+    //qDebug() << "frameSize: " << m_surface->surfaceFormat().frameSize();
+    QVideoFrame frame(buffer, m_surface->surfaceFormat().frameSize(),
+                      m_surface->surfaceFormat().pixelFormat());
+
+    frame.setMetaData("TextureId", m_textureId);
+
+    // Display the video frame on the surface:
+    m_surface->present(frame);
+}
+
+GstPadProbeReturn QGstreamerMirTextureRenderer::padBufferProbe(GstPad *pad, GstPadProbeInfo *info, gpointer userData)
+{
+    Q_UNUSED(pad);
+    Q_UNUSED(info);
+
+    QGstreamerMirTextureRenderer *control = reinterpret_cast<QGstreamerMirTextureRenderer*>(userData);
+    QMetaObject::invokeMethod(control, "updateNativeVideoSize", Qt::QueuedConnection);
+
+    return GST_PAD_PROBE_REMOVE;
+}
+
+void QGstreamerMirTextureRenderer::stopRenderer()
+{
+    if (m_surface)
+        m_surface->stop();
+}
+
+QAbstractVideoSurface *QGstreamerMirTextureRenderer::surface() const
+{
+    return m_surface;
+}
+
+void QGstreamerMirTextureRenderer::setSurface(QAbstractVideoSurface *surface)
+{
+    qDebug() << Q_FUNC_INFO;
+
+    if (m_surface != surface) {
+        qDebug() << "Saving current QGLContext";
+        m_context = const_cast<QGLContext*>(QGLContext::currentContext());
+
+        if (m_videoSink)
+            gst_object_unref(GST_OBJECT(m_videoSink));
+
+        m_videoSink = 0;
+
+        if (m_surface) {
+            disconnect(m_surface.data(), SIGNAL(supportedFormatsChanged()),
+                       this, SLOT(handleFormatChange()));
+        }
+
+        bool wasReady = isReady();
+
+        m_surface = surface;
+
+        if (m_surface) {
+            connect(m_surface.data(), SIGNAL(supportedFormatsChanged()),
+                    this, SLOT(handleFormatChange()));
+        }
+
+        if (wasReady != isReady())
+            emit readyChanged(isReady());
+
+        emit sinkChanged();
+    }
+}
+
+void QGstreamerMirTextureRenderer::setPlayerSession(const QGstreamerPlayerSession *playerSession)
+{
+    m_playerSession = const_cast<QGstreamerPlayerSession*>(playerSession);
+}
+
+void QGstreamerMirTextureRenderer::handleFormatChange()
+{
+    qDebug() << "Supported formats list has changed, reload video output";
+
+    if (m_videoSink)
+        gst_object_unref(GST_OBJECT(m_videoSink));
+
+    m_videoSink = 0;
+    emit sinkChanged();
+}
+
+void QGstreamerMirTextureRenderer::updateNativeVideoSize()
+{
+    //qDebug() << Q_FUNC_INFO;
+    const QSize oldSize = m_nativeSize;
+
+    if (m_videoSink) {
+        // Find video native size to update video widget size hint
+        GstPad *pad = gst_element_get_static_pad(m_videoSink,"sink");
+        GstCaps *caps = gst_pad_get_current_caps(pad);
+
+        if (caps) {
+            m_nativeSize = QGstUtils::capsCorrectedResolution(caps);
+            gst_caps_unref(caps);
+        }
+    } else {
+        m_nativeSize = QSize();
+    }
+    qDebug() << Q_FUNC_INFO << oldSize << m_nativeSize << m_videoSink;
+
+    if (m_nativeSize != oldSize)
+        emit nativeSizeChanged();
+}
+
+void QGstreamerMirTextureRenderer::handleFocusWindowChanged(QWindow *window)
+{
+    qDebug() << Q_FUNC_INFO;
+
+    QOpenGLContext *currContext = QOpenGLContext::currentContext();
+
+    QQuickWindow *w = dynamic_cast<QQuickWindow*>(window);
+    // If we don't have a GL context in the current thread, create one and share it
+    // with the render thread GL context
+    if (!currContext && !m_glContext) {
+        // This emulates the new QOffscreenWindow class with Qt5.1
+        m_offscreenSurface = createOffscreenWindow(w->openglContext()->surface()->format());
+        m_offscreenSurface->setParent(window);
+
+        QOpenGLContext *shareContext = 0;
+        if (m_surface)
+            shareContext = qobject_cast<QOpenGLContext*>(m_surface->property("GLContext").value<QObject*>());
+        m_glContext = new QOpenGLContext;
+        m_glContext->setFormat(m_offscreenSurface->requestedFormat());
+
+        if (shareContext)
+            m_glContext->setShareContext(shareContext);
+
+        if (!m_glContext->create())
+        {
+            qWarning() << "Failed to create new shared context.";
+            return;
+        }
+    }
+
+    if (m_glContext)
+        m_glContext->makeCurrent(m_offscreenSurface);
+
+    if (m_textureId == 0) {
+        glGenTextures(1, &m_textureId);
+        qDebug() << "texture_id (handleFocusWindowChanged): " << m_textureId << endl;
+        g_object_set(G_OBJECT(m_videoSink), "texture-id", m_textureId, (char*)NULL);
+    }
+}
diff --git a/src/gsttools/qgstreamervideoinputdevicecontrol.cpp b/src/gsttools/qgstreamervideoinputdevicecontrol.cpp
index e4e202c..c26029c 100644
--- a/src/gsttools/qgstreamervideoinputdevicecontrol.cpp
+++ b/src/gsttools/qgstreamervideoinputdevicecontrol.cpp
@@ -44,43 +44,40 @@
 #include <QtCore/QDir>
 #include <QtCore/QDebug>
 
-#include <private/qcore_unix_p.h>
-#include <linux/videodev2.h>
+#include <private/qgstutils_p.h>
 
 QGstreamerVideoInputDeviceControl::QGstreamerVideoInputDeviceControl(QObject *parent)
-    :QVideoDeviceSelectorControl(parent), m_source(0), m_selectedDevice(0)
+    :QVideoDeviceSelectorControl(parent), m_factory(0), m_selectedDevice(0)
 {
-    update();
 }
 
-QGstreamerVideoInputDeviceControl::QGstreamerVideoInputDeviceControl(GstElement *source, QObject *parent)
-    :QVideoDeviceSelectorControl(parent), m_source(source), m_selectedDevice(0)
+QGstreamerVideoInputDeviceControl::QGstreamerVideoInputDeviceControl(
+        GstElementFactory *factory, QObject *parent)
+    : QVideoDeviceSelectorControl(parent), m_factory(factory), m_selectedDevice(0)
 {
-    if (m_source)
-        gst_object_ref(GST_OBJECT(m_source));
-
-    update();
+    if (m_factory)
+        gst_object_ref(GST_OBJECT(m_factory));
 }
 
 QGstreamerVideoInputDeviceControl::~QGstreamerVideoInputDeviceControl()
 {
-    if (m_source)
-        gst_object_unref(GST_OBJECT(m_source));
+    if (m_factory)
+        gst_object_unref(GST_OBJECT(m_factory));
 }
 
 int QGstreamerVideoInputDeviceControl::deviceCount() const
 {
-    return m_names.size();
+    return QGstUtils::enumerateCameras(m_factory).count();
 }
 
 QString QGstreamerVideoInputDeviceControl::deviceName(int index) const
 {
-    return m_names[index];
+    return QGstUtils::enumerateCameras(m_factory).value(index).name;
 }
 
 QString QGstreamerVideoInputDeviceControl::deviceDescription(int index) const
 {
-    return m_descriptions[index];
+    return QGstUtils::enumerateCameras(m_factory).value(index).description;
 }
 
 int QGstreamerVideoInputDeviceControl::defaultDevice() const
@@ -93,7 +90,6 @@ int QGstreamerVideoInputDeviceControl::selectedDevice() const
     return m_selectedDevice;
 }
 
-
 void QGstreamerVideoInputDeviceControl::setSelectedDevice(int index)
 {
     if (index != m_selectedDevice) {
@@ -102,60 +98,3 @@ void QGstreamerVideoInputDeviceControl::setSelectedDevice(int index)
         emit selectedDeviceChanged(deviceName(index));
     }
 }
-
-
-void QGstreamerVideoInputDeviceControl::update()
-{
-    m_names.clear();
-    m_descriptions.clear();
-
-    // subdevsrc and the like have a camera-device property that takes an enumeration
-    // identifying a primary or secondary camera, so return identifiers that map to those
-    // instead of a list of actual devices.
-    if (m_source && g_object_class_find_property(G_OBJECT_GET_CLASS(m_source), "camera-device")) {
-        m_names << QLatin1String("primary") << QLatin1String("secondary");
-        m_descriptions << tr("Main camera") << tr("Front camera");
-        return;
-    }
-
-    QDir devDir("/dev");
-    devDir.setFilter(QDir::System);
-
-    QFileInfoList entries = devDir.entryInfoList(QStringList() << "video*");
-
-    foreach( const QFileInfo &entryInfo, entries ) {
-        //qDebug() << "Try" << entryInfo.filePath();
-
-        int fd = qt_safe_open(entryInfo.filePath().toLatin1().constData(), O_RDWR );
-        if (fd == -1)
-            continue;
-
-        bool isCamera = false;
-
-        v4l2_input input;
-        memset(&input, 0, sizeof(input));
-        for (; ::ioctl(fd, VIDIOC_ENUMINPUT, &input) >= 0; ++input.index) {
-            if(input.type == V4L2_INPUT_TYPE_CAMERA || input.type == 0) {
-                isCamera = ::ioctl(fd, VIDIOC_S_INPUT, input.index) != 0;
-                break;
-            }
-        }
-
-        if (isCamera) {
-            // find out its driver "name"
-            QString name;
-            struct v4l2_capability vcap;
-            memset(&vcap, 0, sizeof(struct v4l2_capability));
-
-            if (ioctl(fd, VIDIOC_QUERYCAP, &vcap) != 0)
-                name = entryInfo.fileName();
-            else
-                name = QString((const char*)vcap.card);
-            //qDebug() << "found camera: " << name;
-
-            m_names.append(entryInfo.filePath());
-            m_descriptions.append(name);
-        }
-        qt_safe_close(fd);
-    }
-}
diff --git a/src/gsttools/qgstreamervideoprobecontrol.cpp b/src/gsttools/qgstreamervideoprobecontrol.cpp
index f2e6c3f..057c7ea 100644
--- a/src/gsttools/qgstreamervideoprobecontrol.cpp
+++ b/src/gsttools/qgstreamervideoprobecontrol.cpp
@@ -40,7 +40,8 @@
 ****************************************************************************/
 
 #include "qgstreamervideoprobecontrol_p.h"
-#include <private/qvideosurfacegstsink_p.h>
+
+#include "qgstutils_p.h"
 #include <private/qgstvideobuffer_p.h>
 
 QGstreamerVideoProbeControl::QGstreamerVideoProbeControl(QObject *parent)
@@ -48,12 +49,10 @@ QGstreamerVideoProbeControl::QGstreamerVideoProbeControl(QObject *parent)
     , m_flushing(false)
     , m_frameProbed(false)
 {
-
 }
 
 QGstreamerVideoProbeControl::~QGstreamerVideoProbeControl()
 {
-
 }
 
 void QGstreamerVideoProbeControl::startFlushing()
@@ -75,33 +74,49 @@ void QGstreamerVideoProbeControl::stopFlushing()
     m_flushing = false;
 }
 
-void QGstreamerVideoProbeControl::bufferProbed(GstBuffer* buffer)
+void QGstreamerVideoProbeControl::probeCaps(GstCaps *caps)
 {
-    if (m_flushing)
-        return;
-
-    GstCaps* caps = gst_buffer_get_caps(buffer);
-    if (!caps)
-        return;
+#if GST_CHECK_VERSION(1,0,0)
+    GstVideoInfo videoInfo;
+    QVideoSurfaceFormat format = QGstUtils::formatForCaps(caps, &videoInfo);
 
+    QMutexLocker locker(&m_frameMutex);
+    m_videoInfo = videoInfo;
+#else
     int bytesPerLine = 0;
-    QVideoSurfaceFormat format = QVideoSurfaceGstSink::formatForCaps(caps, &bytesPerLine);
-    gst_caps_unref(caps);
-    if (!format.isValid() || !bytesPerLine)
-        return;
+    QVideoSurfaceFormat format = QGstUtils::formatForCaps(caps, &bytesPerLine);
+
+    QMutexLocker locker(&m_frameMutex);
+    m_bytesPerLine = bytesPerLine;
+#endif
+    m_format = format;
+}
+
+bool QGstreamerVideoProbeControl::probeBuffer(GstBuffer *buffer)
+{
+    QMutexLocker locker(&m_frameMutex);
+
+    if (m_flushing || !m_format.isValid())
+        return true;
 
-    QVideoFrame frame = QVideoFrame(new QGstVideoBuffer(buffer, bytesPerLine),
-                                    format.frameSize(), format.pixelFormat());
+    QVideoFrame frame(
+#if GST_CHECK_VERSION(1,0,0)
+                new QGstVideoBuffer(buffer, m_videoInfo),
+#else
+                new QGstVideoBuffer(buffer, m_bytesPerLine),
+#endif
+                m_format.frameSize(),
+                m_format.pixelFormat());
 
-    QVideoSurfaceGstSink::setFrameTimeStamps(&frame, buffer);
+    QGstUtils::setFrameTimeStamps(&frame, buffer);
 
     m_frameProbed = true;
 
-    {
-        QMutexLocker locker(&m_frameMutex);
-        m_pendingFrame = frame;
+    if (!m_pendingFrame.isValid())
         QMetaObject::invokeMethod(this, "frameProbed", Qt::QueuedConnection);
-    }
+    m_pendingFrame = frame;
+
+    return true;
 }
 
 void QGstreamerVideoProbeControl::frameProbed()
@@ -112,6 +127,7 @@ void QGstreamerVideoProbeControl::frameProbed()
         if (!m_pendingFrame.isValid())
             return;
         frame = m_pendingFrame;
+        m_pendingFrame = QVideoFrame();
     }
     emit videoFrameProbed(frame);
 }
diff --git a/src/gsttools/qgstreamervideorenderer.cpp b/src/gsttools/qgstreamervideorenderer.cpp
index 36c9f78..da85dea 100644
--- a/src/gsttools/qgstreamervideorenderer.cpp
+++ b/src/gsttools/qgstreamervideorenderer.cpp
@@ -43,8 +43,7 @@
 #include <private/qvideosurfacegstsink_p.h>
 #include <private/qgstutils_p.h>
 #include <qabstractvideosurface.h>
-
-#include <QDebug>
+#include <QtCore/qdebug.h>
 
 #include <gst/gst.h>
 
diff --git a/src/gsttools/qgstreamervideowidget.cpp b/src/gsttools/qgstreamervideowidget.cpp
index 7e11bfb..4c33def 100644
--- a/src/gsttools/qgstreamervideowidget.cpp
+++ b/src/gsttools/qgstreamervideowidget.cpp
@@ -48,8 +48,13 @@
 #include <QtGui/qpainter.h>
 
 #include <gst/gst.h>
+
+#if !GST_CHECK_VERSION(1,0,0)
 #include <gst/interfaces/xoverlay.h>
 #include <gst/interfaces/propertyprobe.h>
+#else
+#include <gst/video/videooverlay.h>
+#endif
 
 QT_BEGIN_NAMESPACE
 
@@ -138,8 +143,6 @@ void QGstreamerVideoWidgetControl::createVideoWidget()
         m_videoSink = gst_element_factory_make ("ximagesink", NULL);
 
     qt_gst_object_ref_sink(GST_OBJECT (m_videoSink)); //Take ownership
-
-
 }
 
 GstElement *QGstreamerVideoWidgetControl::videoSink()
@@ -177,9 +180,13 @@ bool QGstreamerVideoWidgetControl::processSyncMessage(const QGstreamerMessage &m
 {
     GstMessage* gm = message.rawMessage();
 
+#if !GST_CHECK_VERSION(1,0,0)
     if (gm && (GST_MESSAGE_TYPE(gm) == GST_MESSAGE_ELEMENT) &&
             gst_structure_has_name(gm->structure, "prepare-xwindow-id")) {
-
+#else
+      if (gm && (GST_MESSAGE_TYPE(gm) == GST_MESSAGE_ELEMENT) &&
+              gst_structure_has_name(gst_message_get_structure(gm), "prepare-window-handle")) {
+#endif
         setOverlay();
         QMetaObject::invokeMethod(this, "updateNativeVideoSize", Qt::QueuedConnection);
         return true;
@@ -207,17 +214,24 @@ bool QGstreamerVideoWidgetControl::processBusMessage(const QGstreamerMessage &me
 
 void QGstreamerVideoWidgetControl::setOverlay()
 {
+#if !GST_CHECK_VERSION(1,0,0)
     if (m_videoSink && GST_IS_X_OVERLAY(m_videoSink)) {
         gst_x_overlay_set_xwindow_id(GST_X_OVERLAY(m_videoSink), m_windowId);
     }
+#else
+    if (m_videoSink && GST_IS_VIDEO_OVERLAY(m_videoSink)) {
+        gst_video_overlay_set_window_handle(GST_VIDEO_OVERLAY(m_videoSink), m_windowId);
+    }
+#endif
 }
 
 void QGstreamerVideoWidgetControl::updateNativeVideoSize()
 {
     if (m_videoSink) {
         //find video native size to update video widget size hint
-        GstPad *pad = gst_element_get_static_pad(m_videoSink,"sink");
-        GstCaps *caps = gst_pad_get_negotiated_caps(pad);
+        GstPad *pad = gst_element_get_static_pad(m_videoSink, "sink");
+        GstCaps *caps = qt_gst_pad_get_current_caps(pad);
+
         gst_object_unref(GST_OBJECT(pad));
 
         if (caps) {
@@ -233,8 +247,13 @@ void QGstreamerVideoWidgetControl::updateNativeVideoSize()
 
 void QGstreamerVideoWidgetControl::windowExposed()
 {
+#if !GST_CHECK_VERSION(1,0,0)
     if (m_videoSink && GST_IS_X_OVERLAY(m_videoSink))
         gst_x_overlay_expose(GST_X_OVERLAY(m_videoSink));
+#else
+    if (m_videoSink && GST_IS_VIDEO_OVERLAY(m_videoSink))
+        gst_video_overlay_expose(GST_VIDEO_OVERLAY(m_videoSink));
+#endif
 }
 
 QWidget *QGstreamerVideoWidgetControl::videoWidget()
diff --git a/src/gsttools/qgstreamervideowindow.cpp b/src/gsttools/qgstreamervideowindow.cpp
index 2dc3510..ef0d802 100644
--- a/src/gsttools/qgstreamervideowindow.cpp
+++ b/src/gsttools/qgstreamervideowindow.cpp
@@ -45,36 +45,49 @@
 #include <QtCore/qdebug.h>
 
 #include <gst/gst.h>
+
+#if !GST_CHECK_VERSION(1,0,0)
 #include <gst/interfaces/xoverlay.h>
 #include <gst/interfaces/propertyprobe.h>
+#else
+#include <gst/video/videooverlay.h>
+#endif
 
 
 QGstreamerVideoWindow::QGstreamerVideoWindow(QObject *parent, const char *elementName)
     : QVideoWindowControl(parent)
+    , QGstreamerBufferProbe(QGstreamerBufferProbe::ProbeCaps)
     , m_videoSink(0)
     , m_windowId(0)
     , m_aspectRatioMode(Qt::KeepAspectRatio)
     , m_fullScreen(false)
     , m_colorKey(QColor::Invalid)
 {
-    if (elementName)
+    if (elementName) {
         m_videoSink = gst_element_factory_make(elementName, NULL);
-    else
+    } else {
         m_videoSink = gst_element_factory_make("xvimagesink", NULL);
+    }
 
     if (m_videoSink) {
         qt_gst_object_ref_sink(GST_OBJECT(m_videoSink)); //Take ownership
 
-        GstPad *pad = gst_element_get_static_pad(m_videoSink,"sink");
-        m_bufferProbeId = gst_pad_add_buffer_probe(pad, G_CALLBACK(padBufferProbe), this);
+        GstPad *pad = gst_element_get_static_pad(m_videoSink, "sink");
+        addProbeToPad(pad);
         gst_object_unref(GST_OBJECT(pad));
     }
+    else
+        qDebug() << "No m_videoSink available!";
 }
 
 QGstreamerVideoWindow::~QGstreamerVideoWindow()
 {
-    if (m_videoSink)
+    if (m_videoSink) {
+        GstPad *pad = gst_element_get_static_pad(m_videoSink,"sink");
+        removeProbeFromPad(pad);
+        gst_object_unref(GST_OBJECT(pad));
         gst_object_unref(GST_OBJECT(m_videoSink));
+    }
 }
 
 WId QGstreamerVideoWindow::winId() const
@@ -90,11 +103,15 @@ void QGstreamerVideoWindow::setWinId(WId id)
     WId oldId = m_windowId;
 
     m_windowId = id;
-
+#if GST_CHECK_VERSION(1,0,0)
+    if (m_videoSink && GST_IS_VIDEO_OVERLAY(m_videoSink)) {
+        gst_video_overlay_set_window_handle(GST_VIDEO_OVERLAY(m_videoSink), m_windowId);
+    }
+#else
     if (m_videoSink && GST_IS_X_OVERLAY(m_videoSink)) {
         gst_x_overlay_set_xwindow_id(GST_X_OVERLAY(m_videoSink), m_windowId);
     }
-
+#endif
     if (!oldId)
         emit readyChanged(true);
 
@@ -105,20 +122,26 @@ void QGstreamerVideoWindow::setWinId(WId id)
 bool QGstreamerVideoWindow::processSyncMessage(const QGstreamerMessage &message)
 {
     GstMessage* gm = message.rawMessage();
+#if GST_CHECK_VERSION(1,0,0)
+    const GstStructure *s = gst_message_get_structure(gm);
+    if ((GST_MESSAGE_TYPE(gm) == GST_MESSAGE_ELEMENT) &&
+            gst_structure_has_name(s, "prepare-window-handle") &&
+            m_videoSink && GST_IS_VIDEO_OVERLAY(m_videoSink)) {
+
+        gst_video_overlay_set_window_handle(GST_VIDEO_OVERLAY(m_videoSink), m_windowId);
 
+        return true;
+    }
+#else
     if ((GST_MESSAGE_TYPE(gm) == GST_MESSAGE_ELEMENT) &&
             gst_structure_has_name(gm->structure, "prepare-xwindow-id") &&
             m_videoSink && GST_IS_X_OVERLAY(m_videoSink)) {
 
         gst_x_overlay_set_xwindow_id(GST_X_OVERLAY(m_videoSink), m_windowId);
 
-        GstPad *pad = gst_element_get_static_pad(m_videoSink,"sink");
-        m_bufferProbeId = gst_pad_add_buffer_probe(pad, G_CALLBACK(padBufferProbe), this);
-        gst_object_unref(GST_OBJECT(pad));
-
         return true;
     }
-
+#endif
     return false;
 }
 
@@ -130,7 +153,19 @@ QRect QGstreamerVideoWindow::displayRect() const
 void QGstreamerVideoWindow::setDisplayRect(const QRect &rect)
 {
     m_displayRect = rect;
-
+#if GST_CHECK_VERSION(1,0,0)
+    if (m_videoSink && GST_IS_VIDEO_OVERLAY(m_videoSink)) {
+        if (m_displayRect.isEmpty())
+            gst_video_overlay_set_render_rectangle(GST_VIDEO_OVERLAY(m_videoSink), -1, -1, -1, -1);
+        else
+            gst_video_overlay_set_render_rectangle(GST_VIDEO_OVERLAY(m_videoSink),
+                                               m_displayRect.x(),
+                                               m_displayRect.y(),
+                                               m_displayRect.width(),
+                                               m_displayRect.height());
+        repaint();
+    }
+#else
     if (m_videoSink && GST_IS_X_OVERLAY(m_videoSink)) {
 #if GST_VERSION_MICRO >= 29
         if (m_displayRect.isEmpty())
@@ -144,6 +179,7 @@ void QGstreamerVideoWindow::setDisplayRect(const QRect &rect)
         repaint();
 #endif
     }
+#endif
 }
 
 Qt::AspectRatioMode QGstreamerVideoWindow::aspectRatioMode() const
@@ -165,6 +201,16 @@ void QGstreamerVideoWindow::setAspectRatioMode(Qt::AspectRatioMode mode)
 
 void QGstreamerVideoWindow::repaint()
 {
+#if GST_CHECK_VERSION(1,0,0)
+    if (m_videoSink && GST_IS_VIDEO_OVERLAY(m_videoSink)) {
+        //don't call gst_x_overlay_expose if the sink is in null state
+        GstState state = GST_STATE_NULL;
+        GstStateChangeReturn res = gst_element_get_state(m_videoSink, &state, NULL, 1000000);
+        if (res != GST_STATE_CHANGE_FAILURE && state != GST_STATE_NULL) {
+            gst_video_overlay_expose(GST_VIDEO_OVERLAY(m_videoSink));
+        }
+    }
+#else
     if (m_videoSink && GST_IS_X_OVERLAY(m_videoSink)) {
         //don't call gst_x_overlay_expose if the sink is in null state
         GstState state = GST_STATE_NULL;
@@ -173,6 +219,7 @@ void QGstreamerVideoWindow::repaint()
             gst_x_overlay_expose(GST_X_OVERLAY(m_videoSink));
         }
     }
+#endif
 }
 
 QColor QGstreamerVideoWindow::colorKey() const
@@ -304,32 +351,22 @@ QSize QGstreamerVideoWindow::nativeSize() const
     return m_nativeSize;
 }
 
-void QGstreamerVideoWindow::padBufferProbe(GstPad *pad, GstBuffer * /* buffer */, gpointer user_data)
+void QGstreamerVideoWindow::probeCaps(GstCaps *caps)
 {
-    QGstreamerVideoWindow *control = reinterpret_cast<QGstreamerVideoWindow*>(user_data);
-    QMetaObject::invokeMethod(control, "updateNativeVideoSize", Qt::QueuedConnection);
-    gst_pad_remove_buffer_probe(pad, control->m_bufferProbeId);
+    QSize resolution = QGstUtils::capsCorrectedResolution(caps);
+    QMetaObject::invokeMethod(
+                this,
+                "updateNativeVideoSize",
+                Qt::QueuedConnection,
+                Q_ARG(QSize, resolution));
 }
 
-void QGstreamerVideoWindow::updateNativeVideoSize()
+void QGstreamerVideoWindow::updateNativeVideoSize(const QSize &size)
 {
-    const QSize oldSize = m_nativeSize;
-    m_nativeSize = QSize();
-
-    if (m_videoSink) {
-        //find video native size to update video widget size hint
-        GstPad *pad = gst_element_get_static_pad(m_videoSink,"sink");
-        GstCaps *caps = gst_pad_get_negotiated_caps(pad);
-        gst_object_unref(GST_OBJECT(pad));
-
-        if (caps) {
-            m_nativeSize = QGstUtils::capsCorrectedResolution(caps);
-            gst_caps_unref(caps);
-        }
-    }
-
-    if (m_nativeSize != oldSize)
+    if (m_nativeSize != size) {
+        m_nativeSize = size;
         emit nativeSizeChanged();
+    }
 }
 
 GstElement *QGstreamerVideoWindow::videoSink()
diff --git a/src/gsttools/qgstutils.cpp b/src/gsttools/qgstutils.cpp
index 41bd005..6598774 100644
--- a/src/gsttools/qgstutils.cpp
+++ b/src/gsttools/qgstutils.cpp
@@ -42,12 +42,25 @@
 #include "qgstutils_p.h"
 
 #include <QtCore/qdatetime.h>
+#include <QtCore/qdir.h>
 #include <QtCore/qbytearray.h>
 #include <QtCore/qvariant.h>
 #include <QtCore/qsize.h>
 #include <QtCore/qset.h>
 #include <QtCore/qstringlist.h>
+#include <QtGui/qimage.h>
 #include <qaudioformat.h>
+#include <QtMultimedia/qvideosurfaceformat.h>
+
+#include <gst/audio/audio.h>
+#include <gst/video/video.h>
+
+template<typename T, int N> static int lengthOf(const T (&)[N]) { return N; }
+
+#include <private/qcore_unix_p.h>
+#include <linux/videodev2.h>
+
+#include "qgstreamervideoinputdevicecontrol_p.h"
 
 QT_BEGIN_NAMESPACE
 
@@ -82,15 +95,20 @@ static void addTagToMap(const GstTagList *list,
             map->insert(QByteArray(tag), g_value_get_boolean(&val));
             break;
         case G_TYPE_CHAR:
-            map->insert(QByteArray(tag), g_value_get_char(&val));
+            map->insert(QByteArray(tag), g_value_get_schar(&val));
             break;
         case G_TYPE_DOUBLE:
             map->insert(QByteArray(tag), g_value_get_double(&val));
             break;
         default:
             // GST_TYPE_DATE is a function, not a constant, so pull it out of the switch
+#if GST_CHECK_VERSION(1,0,0)
+            if (G_VALUE_TYPE(&val) == G_TYPE_DATE) {
+                const GDate *date = (const GDate *)g_value_get_boxed(&val);
+#else
             if (G_VALUE_TYPE(&val) == GST_TYPE_DATE) {
                 const GDate *date = gst_value_get_date(&val);
+#endif
                 if (g_date_valid(date)) {
                     int year = g_date_get_year(date);
                     int month = g_date_get_month(date);
@@ -169,6 +187,42 @@ QSize QGstUtils::capsCorrectedResolution(const GstCaps *caps)
     return size;
 }
 
+
+#if GST_CHECK_VERSION(1,0,0)
+namespace {
+
+struct AudioFormat
+{
+    GstAudioFormat format;
+    QAudioFormat::SampleType sampleType;
+    QAudioFormat::Endian byteOrder;
+    int sampleSize;
+};
+static const AudioFormat qt_audioLookup[] =
+{
+    { GST_AUDIO_FORMAT_S8   , QAudioFormat::SignedInt  , QAudioFormat::LittleEndian, 8  },
+    { GST_AUDIO_FORMAT_U8   , QAudioFormat::UnSignedInt, QAudioFormat::LittleEndian, 8  },
+    { GST_AUDIO_FORMAT_S16LE, QAudioFormat::SignedInt  , QAudioFormat::LittleEndian, 16 },
+    { GST_AUDIO_FORMAT_S16BE, QAudioFormat::SignedInt  , QAudioFormat::BigEndian   , 16 },
+    { GST_AUDIO_FORMAT_U16LE, QAudioFormat::UnSignedInt, QAudioFormat::LittleEndian, 16 },
+    { GST_AUDIO_FORMAT_U16BE, QAudioFormat::UnSignedInt, QAudioFormat::BigEndian   , 16 },
+    { GST_AUDIO_FORMAT_S32LE, QAudioFormat::SignedInt  , QAudioFormat::LittleEndian, 32 },
+    { GST_AUDIO_FORMAT_S32BE, QAudioFormat::SignedInt  , QAudioFormat::BigEndian   , 32 },
+    { GST_AUDIO_FORMAT_U32LE, QAudioFormat::UnSignedInt, QAudioFormat::LittleEndian, 32 },
+    { GST_AUDIO_FORMAT_U32BE, QAudioFormat::UnSignedInt, QAudioFormat::BigEndian   , 32 },
+    { GST_AUDIO_FORMAT_S24LE, QAudioFormat::SignedInt  , QAudioFormat::LittleEndian, 24 },
+    { GST_AUDIO_FORMAT_S24BE, QAudioFormat::SignedInt  , QAudioFormat::BigEndian   , 24 },
+    { GST_AUDIO_FORMAT_U24LE, QAudioFormat::UnSignedInt, QAudioFormat::LittleEndian, 24 },
+    { GST_AUDIO_FORMAT_U24BE, QAudioFormat::UnSignedInt, QAudioFormat::BigEndian   , 24 },
+    { GST_AUDIO_FORMAT_F32LE, QAudioFormat::Float      , QAudioFormat::LittleEndian, 32 },
+    { GST_AUDIO_FORMAT_F32BE, QAudioFormat::Float      , QAudioFormat::BigEndian   , 32 },
+    { GST_AUDIO_FORMAT_F64LE, QAudioFormat::Float      , QAudioFormat::LittleEndian, 64 },
+    { GST_AUDIO_FORMAT_F64BE, QAudioFormat::Float      , QAudioFormat::BigEndian   , 64 }
+};
+
+}
+#endif
+
 /*!
   Returns audio format for caps.
   If caps doesn't have a valid audio format, an empty QAudioFormat is returned.
@@ -176,9 +230,26 @@ QSize QGstUtils::capsCorrectedResolution(const GstCaps *caps)
 
 QAudioFormat QGstUtils::audioFormatForCaps(const GstCaps *caps)
 {
-    const GstStructure *structure = gst_caps_get_structure(caps, 0);
-
     QAudioFormat format;
+#if GST_CHECK_VERSION(1,0,0)
+    GstAudioInfo info;
+    if (gst_audio_info_from_caps(&info, caps)) {
+        for (int i = 0; i < lengthOf(qt_audioLookup); ++i) {
+            if (qt_audioLookup[i].format != info.finfo->format)
+                continue;
+
+            format.setSampleType(qt_audioLookup[i].sampleType);
+            format.setByteOrder(qt_audioLookup[i].byteOrder);
+            format.setSampleSize(qt_audioLookup[i].sampleSize);
+            format.setSampleRate(info.rate);
+            format.setChannelCount(info.channels);
+            format.setCodec(QStringLiteral("audio/pcm"));
+
+            return format;
+        }
+    }
+#else
+    const GstStructure *structure = gst_caps_get_structure(caps, 0);
 
     if (qstrcmp(gst_structure_get_name(structure), "audio/x-raw-int") == 0) {
 
@@ -249,16 +320,28 @@ QAudioFormat QGstUtils::audioFormatForCaps(const GstCaps *caps)
     } else {
         return QAudioFormat();
     }
-
+#endif
     return format;
 }
 
+#if GST_CHECK_VERSION(1,0,0)
+/*!
+  Returns audio format for a sample.
+  If the buffer doesn't have a valid audio format, an empty QAudioFormat is returned.
+*/
+QAudioFormat QGstUtils::audioFormatForSample(GstSample *sample)
+{
+    GstCaps* caps = gst_sample_get_caps(sample);
+    if (!caps)
+        return QAudioFormat();
 
+    return QGstUtils::audioFormatForCaps(caps);
+}
+#else
 /*!
   Returns audio format for a buffer.
   If the buffer doesn't have a valid audio format, an empty QAudioFormat is returned.
 */
-
 QAudioFormat QGstUtils::audioFormatForBuffer(GstBuffer *buffer)
 {
     GstCaps* caps = gst_buffer_get_caps(buffer);
@@ -269,7 +352,7 @@ QAudioFormat QGstUtils::audioFormatForBuffer(GstBuffer *buffer)
     gst_caps_unref(caps);
     return format;
 }
-
+#endif
 
 /*!
   Builds GstCaps for an audio format.
@@ -277,8 +360,32 @@ QAudioFormat QGstUtils::audioFormatForBuffer(GstBuffer *buffer)
   Caller must unref GstCaps.
 */
 
-GstCaps *QGstUtils::capsForAudioFormat(QAudioFormat format)
+GstCaps *QGstUtils::capsForAudioFormat(const QAudioFormat &format)
 {
+    if (!format.isValid())
+        return 0;
+
+#if GST_CHECK_VERSION(1,0,0)
+    const QAudioFormat::SampleType sampleType = format.sampleType();
+    const QAudioFormat::Endian byteOrder = format.byteOrder();
+    const int sampleSize = format.sampleSize();
+
+    for (int i = 0; i < lengthOf(qt_audioLookup); ++i) {
+        if (qt_audioLookup[i].sampleType != sampleType
+                || qt_audioLookup[i].byteOrder != byteOrder
+                || qt_audioLookup[i].sampleSize != sampleSize) {
+            continue;
+        }
+
+        return gst_caps_new_simple(
+                    "audio/x-raw",
+                    "format"  , G_TYPE_STRING, gst_audio_format_to_string(qt_audioLookup[i].format),
+                    "rate"    , G_TYPE_INT   , format.sampleRate(),
+                    "channels", G_TYPE_INT   , format.channelCount(),
+                    NULL);
+    }
+    return 0;
+#else
     GstStructure *structure = 0;
 
     if (format.isValid()) {
@@ -313,6 +420,7 @@ GstCaps *QGstUtils::capsForAudioFormat(QAudioFormat format)
     }
 
     return caps;
+#endif
 }
 
 void QGstUtils::initializeGst()
@@ -401,9 +509,785 @@ QMultimedia::SupportEstimate QGstUtils::hasSupport(const QString &mimeType,
     return QMultimedia::MaybeSupported;
 }
 
+namespace {
+
+typedef QHash<GstElementFactory *, QVector<QGstUtils::CameraInfo> > FactoryCameraInfoMap;
+
+Q_GLOBAL_STATIC(FactoryCameraInfoMap, qt_camera_device_info);
+
+}
+
+QVector<QGstUtils::CameraInfo> QGstUtils::enumerateCameras(GstElementFactory *factory)
+{
+    FactoryCameraInfoMap::const_iterator it = qt_camera_device_info()->constFind(factory);
+    if (it != qt_camera_device_info()->constEnd())
+        return *it;
+
+    QVector<CameraInfo> &devices = (*qt_camera_device_info())[factory];
+
+    if (factory) {
+        bool hasVideoSource = false;
+
+        const GType type = gst_element_factory_get_element_type(factory);
+        GObjectClass * const objectClass = type
+                ? static_cast<GObjectClass *>(g_type_class_ref(type))
+                : 0;
+        if (objectClass) {
+            if (g_object_class_find_property(objectClass, "camera-device")) {
+                const CameraInfo primary = {
+                    QStringLiteral("primary"),
+                    QGstreamerVideoInputDeviceControl::primaryCamera(),
+                    0,
+                    QCamera::BackFace
+                };
+                const CameraInfo secondary = {
+                    QStringLiteral("secondary"),
+                    QGstreamerVideoInputDeviceControl::secondaryCamera(),
+                    0,
+                    QCamera::FrontFace
+                };
+
+                devices.append(primary);
+                devices.append(secondary);
+
+                GstElement *camera = g_object_class_find_property(objectClass, "sensor-mount-angle")
+                        ? gst_element_factory_create(factory, 0)
+                        : 0;
+                if (camera) {
+                    if (gst_element_set_state(camera, GST_STATE_READY) != GST_STATE_CHANGE_SUCCESS) {
+                        // no-op
+                    } else for (int i = 0; i < 2; ++i) {
+                        gint orientation = 0;
+                        g_object_set(G_OBJECT(camera), "camera-device", i, NULL);
+                        g_object_get(G_OBJECT(camera), "sensor-mount-angle", &orientation, NULL);
+
+                        devices[i].orientation = (720 - orientation) % 360;
+                    }
+                    gst_element_set_state(camera, GST_STATE_NULL);
+                    gst_object_unref(GST_OBJECT(camera));
+
+                }
+            } else if (g_object_class_find_property(objectClass, "video-source")) {
+                hasVideoSource = true;
+            }
+
+            g_type_class_unref(objectClass);
+        }
+
+        if (!devices.isEmpty() || !hasVideoSource) {
+            return devices;
+        }
+    }
+
+    QDir devDir(QStringLiteral("/dev"));
+    devDir.setFilter(QDir::System);
+
+    QFileInfoList entries = devDir.entryInfoList(QStringList()
+                << QStringLiteral("video*"));
+
+    foreach (const QFileInfo &entryInfo, entries) {
+        //qDebug() << "Try" << entryInfo.filePath();
+
+        int fd = qt_safe_open(entryInfo.filePath().toLatin1().constData(), O_RDWR );
+        if (fd == -1)
+            continue;
+
+        bool isCamera = false;
+
+        v4l2_input input;
+        memset(&input, 0, sizeof(input));
+        for (; ::ioctl(fd, VIDIOC_ENUMINPUT, &input) >= 0; ++input.index) {
+            if (input.type == V4L2_INPUT_TYPE_CAMERA || input.type == 0) {
+                isCamera = ::ioctl(fd, VIDIOC_S_INPUT, input.index) != 0;
+                break;
+            }
+        }
+
+        if (isCamera) {
+            // find out its driver "name"
+            QString name;
+            struct v4l2_capability vcap;
+            memset(&vcap, 0, sizeof(struct v4l2_capability));
+
+            if (ioctl(fd, VIDIOC_QUERYCAP, &vcap) != 0)
+                name = entryInfo.fileName();
+            else
+                name = QString::fromUtf8((const char*)vcap.card);
+            //qDebug() << "found camera: " << name;
+
+
+            CameraInfo device = {
+                entryInfo.absoluteFilePath(),
+                name,
+                0,
+                QCamera::UnspecifiedPosition
+            };
+            devices.append(device);
+        }
+        qt_safe_close(fd);
+    }
+
+    return devices;
+}
+
+QList<QByteArray> QGstUtils::cameraDevices(GstElementFactory * factory)
+{
+    QList<QByteArray> devices;
+
+    foreach (const CameraInfo &camera, enumerateCameras(factory))
+        devices.append(camera.name.toUtf8());
+
+    return devices;
+}
+
+QString QGstUtils::cameraDescription(const QString &device, GstElementFactory * factory)
+{
+    foreach (const CameraInfo &camera, enumerateCameras(factory)) {
+        if (camera.name == device)
+            return camera.description;
+    }
+    return QString();
+}
+
+QCamera::Position QGstUtils::cameraPosition(const QString &device, GstElementFactory * factory)
+{
+    foreach (const CameraInfo &camera, enumerateCameras(factory)) {
+        if (camera.name == device)
+            return camera.position;
+    }
+    return QCamera::UnspecifiedPosition;
+}
+
+int QGstUtils::cameraOrientation(const QString &device, GstElementFactory * factory)
+{
+    foreach (const CameraInfo &camera, enumerateCameras(factory)) {
+        if (camera.name == device)
+            return camera.orientation;
+    }
+    return 0;
+}
+
+QSet<QString> QGstUtils::supportedMimeTypes(bool (*isValidFactory)(GstElementFactory *factory))
+{
+    QSet<QString> supportedMimeTypes;
+
+    //enumerate supported mime types
+    gst_init(NULL, NULL);
+
+#if GST_CHECK_VERSION(1,0,0)
+    GstRegistry *registry = gst_registry_get();
+    GList *orig_plugins = gst_registry_get_plugin_list(registry);
+#else
+    GstRegistry *registry = gst_registry_get_default();
+    GList *orig_plugins = gst_default_registry_get_plugin_list ();
+#endif
+    for (GList *plugins = orig_plugins; plugins; plugins = g_list_next(plugins)) {
+        GstPlugin *plugin = (GstPlugin *) (plugins->data);
+#if GST_CHECK_VERSION(1,0,0)
+        if (GST_OBJECT_FLAG_IS_SET(GST_OBJECT(plugin), GST_PLUGIN_FLAG_BLACKLISTED))
+            continue;
+#else
+        if (plugin->flags & (1<<1)) //GST_PLUGIN_FLAG_BLACKLISTED
+            continue;
+#endif
+
+        GList *orig_features = gst_registry_get_feature_list_by_plugin(
+                    registry, gst_plugin_get_name(plugin));
+        for (GList *features = orig_features; features; features = g_list_next(features)) {
+            if (G_UNLIKELY(features->data == NULL))
+                continue;
+
+            GstPluginFeature *feature = GST_PLUGIN_FEATURE(features->data);
+            GstElementFactory *factory;
+
+            if (GST_IS_TYPE_FIND_FACTORY(feature)) {
+                QString name(gst_plugin_feature_get_name(feature));
+                if (name.contains('/')) //filter out any string without '/' which is obviously not a mime type
+                    supportedMimeTypes.insert(name.toLower());
+                continue;
+            } else if (!GST_IS_ELEMENT_FACTORY (feature)
+                        || !(factory = GST_ELEMENT_FACTORY(gst_plugin_feature_load(feature)))) {
+                continue;
+            } else if (!isValidFactory(factory)) {
+                // Do nothing
+            } else for (const GList *pads = gst_element_factory_get_static_pad_templates(factory);
+                        pads;
+                        pads = g_list_next(pads)) {
+                GstStaticPadTemplate *padtemplate = static_cast<GstStaticPadTemplate *>(pads->data);
+
+                if (padtemplate->direction == GST_PAD_SINK && padtemplate->static_caps.string) {
+                    GstCaps *caps = gst_static_caps_get(&padtemplate->static_caps);
+                    if (gst_caps_is_any(caps) || gst_caps_is_empty(caps)) {
+                    } else for (guint i = 0; i < gst_caps_get_size(caps); i++) {
+                        GstStructure *structure = gst_caps_get_structure(caps, i);
+                        QString nameLowcase = QString(gst_structure_get_name(structure)).toLower();
+
+                        supportedMimeTypes.insert(nameLowcase);
+                        if (nameLowcase.contains("mpeg")) {
+                            //Because mpeg version number is only included in the detail
+                            //description,  it is necessary to manually extract this information
+                            //in order to match the mime type of mpeg4.
+                            const GValue *value = gst_structure_get_value(structure, "mpegversion");
+                            if (value) {
+                                gchar *str = gst_value_serialize(value);
+                                QString versions(str);
+                                QStringList elements = versions.split(QRegExp("\\D+"), QString::SkipEmptyParts);
+                                foreach (const QString &e, elements)
+                                    supportedMimeTypes.insert(nameLowcase + e);
+                                g_free(str);
+                            }
+                        }
+                    }
+                }
+            }
+            gst_object_unref(factory);
+        }
+        gst_plugin_feature_list_free(orig_features);
+    }
+    gst_plugin_list_free (orig_plugins);
+
+#if defined QT_SUPPORTEDMIMETYPES_DEBUG
+    QStringList list = supportedMimeTypes.toList();
+    list.sort();
+    if (qgetenv("QT_DEBUG_PLUGINS").toInt() > 0) {
+        foreach (const QString &type, list)
+            qDebug() << type;
+    }
+#endif
+    return supportedMimeTypes;
+}
+
+namespace {
+
+struct ColorFormat { QImage::Format imageFormat; GstVideoFormat gstFormat; };
+static const ColorFormat qt_colorLookup[] =
+{
+    { QImage::Format_RGBX8888, GST_VIDEO_FORMAT_RGBx  },
+    { QImage::Format_RGBA8888, GST_VIDEO_FORMAT_RGBA  },
+    { QImage::Format_RGB888  , GST_VIDEO_FORMAT_RGB   },
+    { QImage::Format_RGB16   , GST_VIDEO_FORMAT_RGB16 }
+};
+
+}
+
+#if GST_CHECK_VERSION(1,0,0)
+QImage QGstUtils::bufferToImage(GstBuffer *buffer, const GstVideoInfo &videoInfo)
+#else
+QImage QGstUtils::bufferToImage(GstBuffer *buffer)
+#endif
+{
+    QImage img;
+
+#if GST_CHECK_VERSION(1,0,0)
+    GstVideoInfo info = videoInfo;
+    GstVideoFrame frame;
+    if (!gst_video_frame_map(&frame, &info, buffer, GST_MAP_READ))
+        return img;
+#else
+    GstCaps *caps = gst_buffer_get_caps(buffer);
+    if (!caps)
+        return img;
+
+    GstStructure *structure = gst_caps_get_structure (caps, 0);
+    gint width = 0;
+    gint height = 0;
+
+    if (!structure
+            || !gst_structure_get_int(structure, "width", &width)
+            || !gst_structure_get_int(structure, "height", &height)
+            || width <= 0
+            || height <= 0) {
+        gst_caps_unref(caps);
+        return img;
+    }
+    gst_caps_unref(caps);
+#endif
+
+#if GST_CHECK_VERSION(1,0,0)
+    if (videoInfo.finfo->format == GST_VIDEO_FORMAT_I420) {
+        const int width = videoInfo.width;
+        const int height = videoInfo.height;
+
+        const int stride[] = { frame.info.stride[0], frame.info.stride[1], frame.info.stride[2] };
+        const uchar *data[] = {
+            static_cast<const uchar *>(frame.data[0]),
+            static_cast<const uchar *>(frame.data[1]),
+            static_cast<const uchar *>(frame.data[2])
+        };
+#else
+    if (qstrcmp(gst_structure_get_name(structure), "video/x-raw-yuv") == 0) {
+        const int stride[] = { width, width / 2, width / 2 };
+        const uchar *data[] = {
+            (const uchar *)buffer->data,
+            (const uchar *)buffer->data + width * height,
+            (const uchar *)buffer->data + width * height * 5 / 4
+        };
+#endif
+        img = QImage(width/2, height/2, QImage::Format_RGB32);
+
+        for (int y=0; y<height; y+=2) {
+            const uchar *yLine = data[0] + (y * stride[0]);
+            const uchar *uLine = data[1] + (y * stride[1] / 2);
+            const uchar *vLine = data[2] + (y * stride[2] / 2);
+
+            for (int x=0; x<width; x+=2) {
+                const qreal Y = 1.164*(yLine[x]-16);
+                const int U = uLine[x/2]-128;
+                const int V = vLine[x/2]-128;
+
+                int b = qBound(0, int(Y + 2.018*U), 255);
+                int g = qBound(0, int(Y - 0.813*V - 0.391*U), 255);
+                int r = qBound(0, int(Y + 1.596*V), 255);
+
+                img.setPixel(x/2,y/2,qRgb(r,g,b));
+            }
+        }
+#if GST_CHECK_VERSION(1,0,0)
+    } else for (int i = 0; i < lengthOf(qt_colorLookup); ++i) {
+        if (qt_colorLookup[i].gstFormat != videoInfo.finfo->format)
+            continue;
+
+        const QImage image(
+                    static_cast<const uchar *>(frame.data[0]),
+                    videoInfo.width,
+                    videoInfo.height,
+                    frame.info.stride[0],
+                    qt_colorLookup[i].imageFormat);
+        img = image;
+        img.detach();
+
+        break;
+    }
+
+    gst_video_frame_unmap(&frame);
+#else
+    } else if (qstrcmp(gst_structure_get_name(structure), "video/x-raw-rgb") == 0) {
+        QImage::Format format = QImage::Format_Invalid;
+        int bpp = 0;
+        gst_structure_get_int(structure, "bpp", &bpp);
+
+        if (bpp == 24)
+            format = QImage::Format_RGB888;
+        else if (bpp == 32)
+            format = QImage::Format_RGB32;
+
+        if (format != QImage::Format_Invalid) {
+            img = QImage((const uchar *)buffer->data,
+                         width,
+                         height,
+                         format);
+            img.bits(); //detach
+        }
+    }
+#endif
+    return img;
+}
+
+
+namespace {
+
+#if GST_CHECK_VERSION(1,0,0)
+
+struct VideoFormat
+{
+    QVideoFrame::PixelFormat pixelFormat;
+    GstVideoFormat gstFormat;
+};
+
+static const VideoFormat qt_videoFormatLookup[] =
+{
+    { QVideoFrame::Format_YUV420P, GST_VIDEO_FORMAT_I420 },
+    { QVideoFrame::Format_YV12   , GST_VIDEO_FORMAT_YV12 },
+    { QVideoFrame::Format_UYVY   , GST_VIDEO_FORMAT_UYVY },
+    { QVideoFrame::Format_YUYV   , GST_VIDEO_FORMAT_YUY2 },
+    { QVideoFrame::Format_NV12   , GST_VIDEO_FORMAT_NV12 },
+    { QVideoFrame::Format_NV21   , GST_VIDEO_FORMAT_NV21 },
+    { QVideoFrame::Format_AYUV444, GST_VIDEO_FORMAT_AYUV },
+#if Q_BYTE_ORDER == Q_LITTLE_ENDIAN
+    { QVideoFrame::Format_RGB32 ,  GST_VIDEO_FORMAT_BGRx },
+    { QVideoFrame::Format_BGR32 ,  GST_VIDEO_FORMAT_RGBx },
+    { QVideoFrame::Format_ARGB32,  GST_VIDEO_FORMAT_BGRA },
+    { QVideoFrame::Format_BGRA32,  GST_VIDEO_FORMAT_ARGB },
+#else
+    { QVideoFrame::Format_RGB32 ,  GST_VIDEO_FORMAT_xRGB },
+    { QVideoFrame::Format_BGR32 ,  GST_VIDEO_FORMAT_xBGR },
+    { QVideoFrame::Format_ARGB32,  GST_VIDEO_FORMAT_ARGB },
+    { QVideoFrame::Format_BGRA32,  GST_VIDEO_FORMAT_BGRA },
+#endif
+    { QVideoFrame::Format_RGB24 ,  GST_VIDEO_FORMAT_RGB },
+    { QVideoFrame::Format_BGR24 ,  GST_VIDEO_FORMAT_BGR },
+    { QVideoFrame::Format_RGB565,  GST_VIDEO_FORMAT_RGB16 }
+};
+
+static int indexOfVideoFormat(QVideoFrame::PixelFormat format)
+{
+    for (int i = 0; i < lengthOf(qt_videoFormatLookup); ++i)
+        if (qt_videoFormatLookup[i].pixelFormat == format)
+            return i;
+
+    return -1;
+}
+
+static int indexOfVideoFormat(GstVideoFormat format)
+{
+    for (int i = 0; i < lengthOf(qt_videoFormatLookup); ++i)
+        if (qt_videoFormatLookup[i].gstFormat == format)
+            return i;
+
+    return -1;
+}
+
+#else
+
+struct YuvFormat
+{
+    QVideoFrame::PixelFormat pixelFormat;
+    guint32 fourcc;
+    int bitsPerPixel;
+};
+
+static const YuvFormat qt_yuvColorLookup[] =
+{
+    { QVideoFrame::Format_YUV420P, GST_MAKE_FOURCC('I','4','2','0'), 8 },
+    { QVideoFrame::Format_YV12,    GST_MAKE_FOURCC('Y','V','1','2'), 8 },
+    { QVideoFrame::Format_UYVY,    GST_MAKE_FOURCC('U','Y','V','Y'), 16 },
+    { QVideoFrame::Format_YUYV,    GST_MAKE_FOURCC('Y','U','Y','2'), 16 },
+    { QVideoFrame::Format_NV12,    GST_MAKE_FOURCC('N','V','1','2'), 8 },
+    { QVideoFrame::Format_NV21,    GST_MAKE_FOURCC('N','V','2','1'), 8 },
+    { QVideoFrame::Format_AYUV444, GST_MAKE_FOURCC('A','Y','U','V'), 32 }
+};
+
+static int indexOfYuvColor(QVideoFrame::PixelFormat format)
+{
+    const int count = sizeof(qt_yuvColorLookup) / sizeof(YuvFormat);
+
+    for (int i = 0; i < count; ++i)
+        if (qt_yuvColorLookup[i].pixelFormat == format)
+            return i;
+
+    return -1;
+}
+
+static int indexOfYuvColor(guint32 fourcc)
+{
+    const int count = sizeof(qt_yuvColorLookup) / sizeof(YuvFormat);
+
+    for (int i = 0; i < count; ++i)
+        if (qt_yuvColorLookup[i].fourcc == fourcc)
+            return i;
+
+    return -1;
+}
+
+struct RgbFormat
+{
+    QVideoFrame::PixelFormat pixelFormat;
+    int bitsPerPixel;
+    int depth;
+    int endianness;
+    int red;
+    int green;
+    int blue;
+    int alpha;
+};
+
+static const RgbFormat qt_rgbColorLookup[] =
+{
+    { QVideoFrame::Format_RGB32 , 32, 24, 4321, 0x0000FF00, 0x00FF0000, int(0xFF000000), 0x00000000 },
+    { QVideoFrame::Format_RGB32 , 32, 24, 1234, 0x00FF0000, 0x0000FF00, 0x000000FF, 0x00000000 },
+    { QVideoFrame::Format_BGR32 , 32, 24, 4321, int(0xFF000000), 0x00FF0000, 0x0000FF00, 0x00000000 },
+    { QVideoFrame::Format_BGR32 , 32, 24, 1234, 0x000000FF, 0x0000FF00, 0x00FF0000, 0x00000000 },
+    { QVideoFrame::Format_ARGB32, 32, 24, 4321, 0x0000FF00, 0x00FF0000, int(0xFF000000), 0x000000FF },
+    { QVideoFrame::Format_ARGB32, 32, 24, 1234, 0x00FF0000, 0x0000FF00, 0x000000FF, int(0xFF000000) },
+    { QVideoFrame::Format_RGB24 , 24, 24, 4321, 0x00FF0000, 0x0000FF00, 0x000000FF, 0x00000000 },
+    { QVideoFrame::Format_BGR24 , 24, 24, 4321, 0x000000FF, 0x0000FF00, 0x00FF0000, 0x00000000 },
+    { QVideoFrame::Format_RGB565, 16, 16, 1234, 0x0000F800, 0x000007E0, 0x0000001F, 0x00000000 }
+};
+
+static int indexOfRgbColor(
+        int bits, int depth, int endianness, int red, int green, int blue, int alpha)
+{
+    const int count = sizeof(qt_rgbColorLookup) / sizeof(RgbFormat);
+
+    for (int i = 0; i < count; ++i) {
+        if (qt_rgbColorLookup[i].bitsPerPixel == bits
+            && qt_rgbColorLookup[i].depth == depth
+            && qt_rgbColorLookup[i].endianness == endianness
+            && qt_rgbColorLookup[i].red == red
+            && qt_rgbColorLookup[i].green == green
+            && qt_rgbColorLookup[i].blue == blue
+            && qt_rgbColorLookup[i].alpha == alpha) {
+            return i;
+        }
+    }
+    return -1;
+}
+#endif
+
+}
+
+#if GST_CHECK_VERSION(1,0,0)
+
+QVideoSurfaceFormat QGstUtils::formatForCaps(
+        GstCaps *caps, GstVideoInfo *info, QAbstractVideoBuffer::HandleType handleType)
+{
+    if (gst_video_info_from_caps(info, caps)) {
+        int index = indexOfVideoFormat(info->finfo->format);
+
+        if (index != -1) {
+            QVideoSurfaceFormat format(
+                        QSize(info->width, info->height),
+                        qt_videoFormatLookup[index].pixelFormat,
+                        handleType);
+
+            if (info->fps_d > 0)
+                format.setFrameRate(qreal(info->fps_d) / info->fps_n);
+
+            if (info->par_d > 0)
+                format.setPixelAspectRatio(info->par_n, info->par_d);
+
+            return format;
+        }
+    }
+    return QVideoSurfaceFormat();
+}
+
+#else
+
+QVideoSurfaceFormat QGstUtils::formatForCaps(
+        GstCaps *caps, int *bytesPerLine, QAbstractVideoBuffer::HandleType handleType)
+{
+    const GstStructure *structure = gst_caps_get_structure(caps, 0);
+
+    QVideoFrame::PixelFormat pixelFormat = QVideoFrame::Format_Invalid;
+    int bitsPerPixel = 0;
+
+    QSize size;
+    gst_structure_get_int(structure, "width", &size.rwidth());
+    gst_structure_get_int(structure, "height", &size.rheight());
+
+    if (qstrcmp(gst_structure_get_name(structure), "video/x-raw-yuv") == 0) {
+        guint32 fourcc = 0;
+        gst_structure_get_fourcc(structure, "format", &fourcc);
+
+        int index = indexOfYuvColor(fourcc);
+        if (index != -1) {
+            pixelFormat = qt_yuvColorLookup[index].pixelFormat;
+            bitsPerPixel = qt_yuvColorLookup[index].bitsPerPixel;
+        }
+    } else if (qstrcmp(gst_structure_get_name(structure), "video/x-raw-rgb") == 0) {
+        int depth = 0;
+        int endianness = 0;
+        int red = 0;
+        int green = 0;
+        int blue = 0;
+        int alpha = 0;
+
+        gst_structure_get_int(structure, "bpp", &bitsPerPixel);
+        gst_structure_get_int(structure, "depth", &depth);
+        gst_structure_get_int(structure, "endianness", &endianness);
+        gst_structure_get_int(structure, "red_mask", &red);
+        gst_structure_get_int(structure, "green_mask", &green);
+        gst_structure_get_int(structure, "blue_mask", &blue);
+        gst_structure_get_int(structure, "alpha_mask", &alpha);
+
+        int index = indexOfRgbColor(bitsPerPixel, depth, endianness, red, green, blue, alpha);
+
+        if (index != -1)
+            pixelFormat = qt_rgbColorLookup[index].pixelFormat;
+    }
+
+    if (pixelFormat != QVideoFrame::Format_Invalid) {
+        QVideoSurfaceFormat format(size, pixelFormat, handleType);
+
+        QPair<int, int> rate;
+        gst_structure_get_fraction(structure, "framerate", &rate.first, &rate.second);
+
+        if (rate.second)
+            format.setFrameRate(qreal(rate.first)/rate.second);
+
+        gint aspectNum = 0;
+        gint aspectDenum = 0;
+        if (gst_structure_get_fraction(
+                structure, "pixel-aspect-ratio", &aspectNum, &aspectDenum)) {
+            if (aspectDenum > 0)
+                format.setPixelAspectRatio(aspectNum, aspectDenum);
+        }
+
+        if (bytesPerLine)
+            *bytesPerLine = ((size.width() * bitsPerPixel / 8) + 3) & ~3;
+
+        return format;
+    }
+    return QVideoSurfaceFormat();
+}
+
+#endif
+
+GstCaps *QGstUtils::capsForFormats(const QList<QVideoFrame::PixelFormat> &formats)
+{
+    GstCaps *caps = gst_caps_new_empty();
+
+#if GST_CHECK_VERSION(1,0,0)
+    foreach (QVideoFrame::PixelFormat format, formats) {
+        int index = indexOfVideoFormat(format);
+
+        if (index != -1) {
+            gst_caps_append_structure(caps, gst_structure_new(
+                    "video/x-raw",
+                    "format"   , G_TYPE_STRING, gst_video_format_to_string(qt_videoFormatLookup[index].gstFormat),
+                    NULL));
+        }
+    }
+#else
+    foreach (QVideoFrame::PixelFormat format, formats) {
+        int index = indexOfYuvColor(format);
+
+        if (index != -1) {
+            gst_caps_append_structure(caps, gst_structure_new(
+                    "video/x-raw-yuv",
+                    "format", GST_TYPE_FOURCC, qt_yuvColorLookup[index].fourcc,
+                    NULL));
+            continue;
+        }
+
+        const int count = sizeof(qt_rgbColorLookup) / sizeof(RgbFormat);
+
+        for (int i = 0; i < count; ++i) {
+            if (qt_rgbColorLookup[i].pixelFormat == format) {
+                GstStructure *structure = gst_structure_new(
+                        "video/x-raw-rgb",
+                        "bpp"       , G_TYPE_INT, qt_rgbColorLookup[i].bitsPerPixel,
+                        "depth"     , G_TYPE_INT, qt_rgbColorLookup[i].depth,
+                        "endianness", G_TYPE_INT, qt_rgbColorLookup[i].endianness,
+                        "red_mask"  , G_TYPE_INT, qt_rgbColorLookup[i].red,
+                        "green_mask", G_TYPE_INT, qt_rgbColorLookup[i].green,
+                        "blue_mask" , G_TYPE_INT, qt_rgbColorLookup[i].blue,
+                        NULL);
+
+                if (qt_rgbColorLookup[i].alpha != 0) {
+                    gst_structure_set(
+                            structure, "alpha_mask", G_TYPE_INT, qt_rgbColorLookup[i].alpha, NULL);
+                }
+                gst_caps_append_structure(caps, structure);
+            }
+        }
+    }
+#endif
+
+    gst_caps_set_simple(
+                caps,
+                "framerate", GST_TYPE_FRACTION_RANGE, 0, 1, INT_MAX, 1,
+                "width"    , GST_TYPE_INT_RANGE, 1, INT_MAX,
+                "height"   , GST_TYPE_INT_RANGE, 1, INT_MAX,
+                NULL);
+
+    return caps;
+}
+
+void QGstUtils::setFrameTimeStamps(QVideoFrame *frame, GstBuffer *buffer)
+{
+    // GStreamer uses nanoseconds, Qt uses microseconds
+    qint64 startTime = GST_BUFFER_TIMESTAMP(buffer);
+    if (startTime >= 0) {
+        frame->setStartTime(startTime/G_GINT64_CONSTANT (1000));
+
+        qint64 duration = GST_BUFFER_DURATION(buffer);
+        if (duration >= 0)
+            frame->setEndTime((startTime + duration)/G_GINT64_CONSTANT (1000));
+    }
+}
+
+void QGstUtils::setMetaData(GstElement *element, const QMap<QByteArray, QVariant> &data)
+{
+    if (!GST_IS_TAG_SETTER(element))
+        return;
+
+    gst_tag_setter_reset_tags(GST_TAG_SETTER(element));
+
+    QMapIterator<QByteArray, QVariant> it(data);
+    while (it.hasNext()) {
+        it.next();
+        const QString tagName = it.key();
+        const QVariant tagValue = it.value();
+
+        switch (tagValue.type()) {
+            case QVariant::String:
+                gst_tag_setter_add_tags(GST_TAG_SETTER(element),
+                    GST_TAG_MERGE_REPLACE,
+                    tagName.toUtf8().constData(),
+                    tagValue.toString().toUtf8().constData(),
+                    NULL);
+                break;
+            case QVariant::Int:
+            case QVariant::LongLong:
+                gst_tag_setter_add_tags(GST_TAG_SETTER(element),
+                    GST_TAG_MERGE_REPLACE,
+                    tagName.toUtf8().constData(),
+                    tagValue.toInt(),
+                    NULL);
+                break;
+            case QVariant::Double:
+                gst_tag_setter_add_tags(GST_TAG_SETTER(element),
+                    GST_TAG_MERGE_REPLACE,
+                    tagName.toUtf8().constData(),
+                    tagValue.toDouble(),
+                    NULL);
+                break;
+            case QVariant::DateTime: {
+                QDateTime date = tagValue.toDateTime().toLocalTime();
+                gst_tag_setter_add_tags(GST_TAG_SETTER(element),
+                    GST_TAG_MERGE_REPLACE,
+                    tagName.toUtf8().constData(),
+                    gst_date_time_new_local_time(
+                                date.date().year(), date.date().month(), date.date().day(),
+                                date.time().hour(), date.time().minute(), date.time().second()),
+                    NULL);
+                break;
+            }
+            default:
+                break;
+        }
+    }
+}
+
+void QGstUtils::setMetaData(GstBin *bin, const QMap<QByteArray, QVariant> &data)
+{
+    GstIterator *elements = gst_bin_iterate_all_by_interface(bin, GST_TYPE_TAG_SETTER);
+#if GST_CHECK_VERSION(1,0,0)
+    GValue item = G_VALUE_INIT;
+    while (gst_iterator_next(elements, &item) == GST_ITERATOR_OK) {
+        GstElement * const element = GST_ELEMENT(g_value_get_object(&item));
+#else
+    GstElement *element = 0;
+    while (gst_iterator_next(elements, (void**)&element) == GST_ITERATOR_OK) {
+#endif
+        setMetaData(element, data);
+    }
+    gst_iterator_free(elements);
+}
+
+
+GstCaps *QGstUtils::videoFilterCaps()
+{
+    static GstStaticCaps staticCaps = GST_STATIC_CAPS(
+#if GST_CHECK_VERSION(1,0,0)
+        "video/x-raw(ANY);"
+#else
+        "video/x-raw-yuv;"
+        "video/x-raw-rgb;"
+        "video/x-raw-data;"
+        "video/x-android-buffer;"
+#endif
+        "image/jpeg;"
+        "video/x-h264");
+
+    return gst_caps_make_writable(gst_static_caps_get(&staticCaps));
+}
+
 void qt_gst_object_ref_sink(gpointer object)
 {
-#if (GST_VERSION_MAJOR >= 0) && (GST_VERSION_MINOR >= 10) && (GST_VERSION_MICRO >= 24)
+#if GST_CHECK_VERSION(0,10,24)
     gst_object_ref_sink(object);
 #else
     g_return_if_fail (GST_IS_OBJECT(object));
@@ -419,4 +1303,50 @@ void qt_gst_object_ref_sink(gpointer object)
 #endif
 }
 
+GstCaps *qt_gst_pad_get_current_caps(GstPad *pad)
+{
+#if GST_CHECK_VERSION(1,0,0)
+    return gst_pad_get_current_caps(pad);
+#else
+    return gst_pad_get_negotiated_caps(pad);
+#endif
+}
+
+GstStructure *qt_gst_structure_new_empty(const char *name)
+{
+#if GST_CHECK_VERSION(1,0,0)
+    return gst_structure_new_empty(name);
+#else
+    return gst_structure_new(name, NULL);
+#endif
+}
+
+gboolean qt_gst_element_query_position(GstElement *element, GstFormat format, gint64 *cur)
+{
+#if GST_CHECK_VERSION(1,0,0)
+    return gst_element_query_position(element, format, cur);
+#else
+    return gst_element_query_position(element, &format, cur);
+#endif
+}
+
+gboolean qt_gst_element_query_duration(GstElement *element, GstFormat format, gint64 *cur)
+{
+#if GST_CHECK_VERSION(1,0,0)
+    return gst_element_query_duration(element, format, cur);
+#else
+    return gst_element_query_duration(element, &format, cur);
+#endif
+}
+
+QDebug operator <<(QDebug debug, GstCaps *caps)
+{
+    if (caps) {
+        gchar *string = gst_caps_to_string(caps);
+        debug = debug << string;
+        g_free(string);
+    }
+    return debug;
+}
+
 QT_END_NAMESPACE
diff --git a/src/gsttools/qgstvideobuffer.cpp b/src/gsttools/qgstvideobuffer.cpp
index 45556d1..b08e49a 100644
--- a/src/gsttools/qgstvideobuffer.cpp
+++ b/src/gsttools/qgstvideobuffer.cpp
@@ -43,21 +43,35 @@
 
 QT_BEGIN_NAMESPACE
 
+#if GST_CHECK_VERSION(1,0,0)
+QGstVideoBuffer::QGstVideoBuffer(GstBuffer *buffer, const GstVideoInfo &info)
+    : QAbstractPlanarVideoBuffer(NoHandle)
+    , m_videoInfo(info)
+#else
 QGstVideoBuffer::QGstVideoBuffer(GstBuffer *buffer, int bytesPerLine)
     : QAbstractVideoBuffer(NoHandle)
-    , m_buffer(buffer)
     , m_bytesPerLine(bytesPerLine)
+#endif
+    , m_buffer(buffer)
     , m_mode(NotMapped)
 {
     gst_buffer_ref(m_buffer);
 }
 
+#if GST_CHECK_VERSION(1,0,0)
+QGstVideoBuffer::QGstVideoBuffer(GstBuffer *buffer, const GstVideoInfo &info,
+                QGstVideoBuffer::HandleType handleType,
+                const QVariant &handle)
+    : QAbstractPlanarVideoBuffer(handleType)
+    , m_videoInfo(info)
+#else
 QGstVideoBuffer::QGstVideoBuffer(GstBuffer *buffer, int bytesPerLine,
                 QGstVideoBuffer::HandleType handleType,
                 const QVariant &handle)
     : QAbstractVideoBuffer(handleType)
-    , m_buffer(buffer)
     , m_bytesPerLine(bytesPerLine)
+#endif
+    , m_buffer(buffer)
     , m_mode(NotMapped)
     , m_handle(handle)
 {
@@ -66,6 +80,8 @@ QGstVideoBuffer::QGstVideoBuffer(GstBuffer *buffer, int bytesPerLine,
 
 QGstVideoBuffer::~QGstVideoBuffer()
 {
+    unmap();
+
     gst_buffer_unref(m_buffer);
 }
 
@@ -75,12 +91,49 @@ QAbstractVideoBuffer::MapMode QGstVideoBuffer::mapMode() const
     return m_mode;
 }
 
+#if GST_CHECK_VERSION(1,0,0)
+
+int QGstVideoBuffer::map(MapMode mode, int *numBytes, int bytesPerLine[4], uchar *data[4])
+{
+    const GstMapFlags flags = GstMapFlags(((mode & ReadOnly) ? GST_MAP_READ : 0)
+                | ((mode & WriteOnly) ? GST_MAP_WRITE : 0));
+
+    if (mode == NotMapped || m_mode != NotMapped) {
+        return 0;
+    } else if (m_videoInfo.finfo->n_planes == 0) {         // Encoded
+        if (gst_buffer_map(m_buffer, &m_frame.map[0], flags)) {
+            if (numBytes)
+                *numBytes = m_frame.map[0].size;
+            bytesPerLine[0] = -1;
+            data[0] = static_cast<uchar *>(m_frame.map[0].data);
+
+            m_mode = mode;
+
+            return 1;
+        }
+    } else if (gst_video_frame_map(&m_frame, &m_videoInfo, m_buffer, flags)) {
+        if (numBytes)
+            *numBytes = m_frame.info.size;
+
+        for (guint i = 0; i < m_frame.info.finfo->n_planes; ++i) {
+            bytesPerLine[i] = m_frame.info.stride[i];
+            data[i] = static_cast<uchar *>(m_frame.data[i]);
+        }
+
+        m_mode = mode;
+
+        return m_frame.info.finfo->n_planes;
+    }
+    return 0;
+}
+
+#else
+
 uchar *QGstVideoBuffer::map(MapMode mode, int *numBytes, int *bytesPerLine)
 {
     if (mode != NotMapped && m_mode == NotMapped) {
         if (numBytes)
             *numBytes = m_buffer->size;
-
         if (bytesPerLine)
             *bytesPerLine = m_bytesPerLine;
 
@@ -91,8 +144,19 @@ uchar *QGstVideoBuffer::map(MapMode mode, int *numBytes, int *bytesPerLine)
         return 0;
     }
 }
+
+#endif
+
 void QGstVideoBuffer::unmap()
 {
+#if GST_CHECK_VERSION(1,0,0)
+    if (m_mode != NotMapped) {
+        if (m_videoInfo.finfo->n_planes == 0)
+            gst_buffer_unmap(m_buffer, &m_frame.map[0]);
+        else
+            gst_video_frame_unmap(&m_frame);
+    }
+#endif
     m_mode = NotMapped;
 }
 
diff --git a/src/gsttools/qgstvideorendererplugin.cpp b/src/gsttools/qgstvideorendererplugin.cpp
new file mode 100644
index 0000000..5eda85a
--- /dev/null
+++ b/src/gsttools/qgstvideorendererplugin.cpp
@@ -0,0 +1,53 @@
+/****************************************************************************
+**
+** Copyright (C) 2014 Jolla Ltd.
+** Contact: http://www.qt-project.org/legal
+**
+** This file is part of the Qt Toolkit.
+**
+** $QT_BEGIN_LICENSE:LGPL$
+** Commercial License Usage
+** Licensees holding valid commercial Qt licenses may use this file in
+** accordance with the commercial license agreement provided with the
+** Software or, alternatively, in accordance with the terms contained in
+** a written agreement between you and Digia.  For licensing terms and
+** conditions see http://qt.digia.com/licensing.  For further information
+** use the contact form at http://qt.digia.com/contact-us.
+**
+** GNU Lesser General Public License Usage
+** Alternatively, this file may be used under the terms of the GNU Lesser
+** General Public License version 2.1 as published by the Free Software
+** Foundation and appearing in the file LICENSE.LGPL included in the
+** packaging of this file.  Please review the following information to
+** ensure the GNU Lesser General Public License version 2.1 requirements
+** will be met: http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html.
+**
+** In addition, as a special exception, Digia gives you certain additional
+** rights.  These rights are described in the Digia Qt LGPL Exception
+** version 1.1, included in the file LGPL_EXCEPTION.txt in this package.
+**
+** GNU General Public License Usage
+** Alternatively, this file may be used under the terms of the GNU
+** General Public License version 3.0 as published by the Free Software
+** Foundation and appearing in the file LICENSE.GPL included in the
+** packaging of this file.  Please review the following information to
+** ensure the GNU General Public License version 3.0 requirements will be
+** met: http://www.gnu.org/copyleft/gpl.html.
+**
+**
+** $QT_END_LICENSE$
+**
+****************************************************************************/
+
+#include "qgstvideorendererplugin_p.h"
+
+QT_BEGIN_NAMESPACE
+
+QGstVideoRendererPlugin::QGstVideoRendererPlugin(QObject *parent) :
+    QObject(parent)
+{
+}
+
+QT_END_NAMESPACE
+
+#include "moc_qgstvideorendererplugin_p.cpp"
diff --git a/src/gsttools/qgstvideorenderersink.cpp b/src/gsttools/qgstvideorenderersink.cpp
new file mode 100644
index 0000000..1102c2a
--- /dev/null
+++ b/src/gsttools/qgstvideorenderersink.cpp
@@ -0,0 +1,605 @@
+/****************************************************************************
+**
+** Copyright (C) 2014 Jolla Ltd.
+** Contact: http://www.qt-project.org/legal
+**
+** This file is part of the Qt Toolkit.
+**
+** $QT_BEGIN_LICENSE:LGPL$
+** Commercial License Usage
+** Licensees holding valid commercial Qt licenses may use this file in
+** accordance with the commercial license agreement provided with the
+** Software or, alternatively, in accordance with the terms contained in
+** a written agreement between you and Digia.  For licensing terms and
+** conditions see http://qt.digia.com/licensing.  For further information
+** use the contact form at http://qt.digia.com/contact-us.
+**
+** GNU Lesser General Public License Usage
+** Alternatively, this file may be used under the terms of the GNU Lesser
+** General Public License version 2.1 as published by the Free Software
+** Foundation and appearing in the file LICENSE.LGPL included in the
+** packaging of this file.  Please review the following information to
+** ensure the GNU Lesser General Public License version 2.1 requirements
+** will be met: http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html.
+**
+** In addition, as a special exception, Digia gives you certain additional
+** rights.  These rights are described in the Digia Qt LGPL Exception
+** version 1.1, included in the file LGPL_EXCEPTION.txt in this package.
+**
+** GNU General Public License Usage
+** Alternatively, this file may be used under the terms of the GNU
+** General Public License version 3.0 as published by the Free Software
+** Foundation and appearing in the file LICENSE.GPL included in the
+** packaging of this file.  Please review the following information to
+** ensure the GNU General Public License version 3.0 requirements will be
+** met: http://www.gnu.org/copyleft/gpl.html.
+**
+**
+** $QT_END_LICENSE$
+**
+****************************************************************************/
+
+#include <qabstractvideosurface.h>
+#include <qvideoframe.h>
+#include <QDebug>
+#include <QMap>
+#include <QThread>
+#include <QEvent>
+#include <QCoreApplication>
+
+#include <private/qmediapluginloader_p.h>
+#include "qgstvideobuffer_p.h"
+
+#include "qgstvideorenderersink_p.h"
+
+#include <gst/video/video.h>
+
+#include "qgstutils_p.h"
+
+//#define DEBUG_VIDEO_SURFACE_SINK
+
+QT_BEGIN_NAMESPACE
+
+QGstDefaultVideoRenderer::QGstDefaultVideoRenderer()
+    : m_flushed(true)
+{
+}
+
+QGstDefaultVideoRenderer::~QGstDefaultVideoRenderer()
+{
+}
+
+GstCaps *QGstDefaultVideoRenderer::getCaps(QAbstractVideoSurface *surface)
+{
+    return QGstUtils::capsForFormats(surface->supportedPixelFormats());
+}
+
+bool QGstDefaultVideoRenderer::start(QAbstractVideoSurface *surface, GstCaps *caps)
+{
+    m_flushed = true;
+    m_format = QGstUtils::formatForCaps(caps, &m_videoInfo);
+
+    return m_format.isValid() && surface->start(m_format);
+}
+
+void QGstDefaultVideoRenderer::stop(QAbstractVideoSurface *surface)
+{
+    m_flushed = true;
+    if (surface)
+        surface->stop();
+}
+
+bool QGstDefaultVideoRenderer::present(QAbstractVideoSurface *surface, GstBuffer *buffer)
+{
+    m_flushed = false;
+    QVideoFrame frame(
+                new QGstVideoBuffer(buffer, m_videoInfo),
+                m_format.frameSize(),
+                m_format.pixelFormat());
+    QGstUtils::setFrameTimeStamps(&frame, buffer);
+
+    return surface->present(frame);
+}
+
+void QGstDefaultVideoRenderer::flush(QAbstractVideoSurface *surface)
+{
+    if (surface && !m_flushed)
+        surface->present(QVideoFrame());
+    m_flushed = true;
+}
+
+bool QGstDefaultVideoRenderer::proposeAllocation(GstQuery *)
+{
+    return true;
+}
+
+Q_GLOBAL_STATIC_WITH_ARGS(QMediaPluginLoader, rendererLoader,
+        (QGstVideoRendererInterface_iid, QLatin1String("video/gstvideorenderer"), Qt::CaseInsensitive))
+
+QVideoSurfaceGstDelegate::QVideoSurfaceGstDelegate(QAbstractVideoSurface *surface)
+    : m_surface(surface)
+    , m_renderer(0)
+    , m_activeRenderer(0)
+    , m_surfaceCaps(0)
+    , m_startCaps(0)
+    , m_lastBuffer(0)
+    , m_notified(false)
+    , m_stop(false)
+    , m_render(false)
+    , m_flush(false)
+{
+    foreach (QObject *instance, rendererLoader()->instances(QGstVideoRendererPluginKey)) {
+        QGstVideoRendererInterface* plugin = qobject_cast<QGstVideoRendererInterface*>(instance);
+        if (QGstVideoRenderer *renderer = plugin ? plugin->createRenderer() : 0)
+            m_renderers.append(renderer);
+    }
+
+    m_renderers.append(new QGstDefaultVideoRenderer);
+    updateSupportedFormats();
+    connect(m_surface, SIGNAL(supportedFormatsChanged()), this, SLOT(updateSupportedFormats()));
+}
+
+QVideoSurfaceGstDelegate::~QVideoSurfaceGstDelegate()
+{
+    qDeleteAll(m_renderers);
+
+    if (m_surfaceCaps)
+        gst_caps_unref(m_surfaceCaps);
+}
+
+GstCaps *QVideoSurfaceGstDelegate::caps()
+{
+    QMutexLocker locker(&m_mutex);
+
+    gst_caps_ref(m_surfaceCaps);
+
+    return m_surfaceCaps;
+}
+
+bool QVideoSurfaceGstDelegate::start(GstCaps *caps)
+{
+    QMutexLocker locker(&m_mutex);
+
+    if (m_activeRenderer) {
+        m_flush = true;
+        m_stop = true;
+    }
+
+    m_render = false;
+
+    if (m_lastBuffer) {
+        gst_buffer_unref(m_lastBuffer);
+        m_lastBuffer = 0;
+    }
+
+    if (m_startCaps)
+        gst_caps_unref(m_startCaps);
+    m_startCaps = caps;
+    gst_caps_ref(m_startCaps);
+
+    /*
+    Waiting for start() to be invoked in the main thread may block
+    if gstreamer blocks the main thread until this call is finished.
+    This situation is rare and usually caused by setState(Null)
+    while pipeline is being prerolled.
+
+    The proper solution to this involves controlling gstreamer pipeline from
+    other thread than video surface.
+
+    Currently start() fails if wait() timed out.
+    */
+    if (!waitForAsyncEvent(&locker, &m_setupCondition, 1000) && m_startCaps) {
+        qWarning() << "Failed to start video surface due to main thread blocked.";
+        gst_caps_unref(m_startCaps);
+        m_startCaps = 0;
+    }
+
+    return m_activeRenderer != 0;
+}
+
+void QVideoSurfaceGstDelegate::stop()
+{
+    QMutexLocker locker(&m_mutex);
+
+    if (!m_activeRenderer)
+        return;
+
+    m_flush = true;
+    m_stop = true;
+
+    if (m_startCaps) {
+        gst_caps_unref(m_startCaps);
+        m_startCaps = 0;
+    }
+
+    if (m_lastBuffer) {
+        gst_buffer_unref(m_lastBuffer);
+        m_lastBuffer = 0;
+    }
+
+    waitForAsyncEvent(&locker, &m_setupCondition, 500);
+}
+
+bool QVideoSurfaceGstDelegate::proposeAllocation(GstQuery *query)
+{
+    QMutexLocker locker(&m_mutex);
+
+    if (QGstVideoRenderer *pool = m_activeRenderer) {
+        locker.unlock();
+
+        return pool->proposeAllocation(query);
+    } else {
+        return false;
+    }
+}
+
+void QVideoSurfaceGstDelegate::flush()
+{
+    QMutexLocker locker(&m_mutex);
+
+    m_flush = true;
+    m_render = false;
+
+    if (m_lastBuffer) {
+        gst_buffer_unref(m_lastBuffer);
+        m_lastBuffer = 0;
+    }
+
+    notify();
+}
+
+GstFlowReturn QVideoSurfaceGstDelegate::render(GstBuffer *buffer, bool show)
+{
+    QMutexLocker locker(&m_mutex);
+
+    if (m_lastBuffer)
+        gst_buffer_unref(m_lastBuffer);
+    m_lastBuffer = buffer;
+    gst_buffer_ref(m_lastBuffer);
+
+    if (show) {
+        m_render = true;
+
+        return waitForAsyncEvent(&locker, &m_renderCondition, 300)
+                ? m_renderReturn
+                : GST_FLOW_ERROR;
+    } else {
+        return GST_FLOW_OK;
+    }
+}
+
+void QVideoSurfaceGstDelegate::handleShowPrerollChange(GObject *object, GParamSpec *, gpointer d)
+{
+    QVideoSurfaceGstDelegate * const delegate = static_cast<QVideoSurfaceGstDelegate *>(d);
+
+    gboolean showPreroll = true; // "show-preroll-frame" property is true by default
+    g_object_get(object, "show-preroll-frame", &showPreroll, NULL);
+
+    GstState state = GST_STATE_NULL;
+    GstState pendingState = GST_STATE_NULL;
+    gst_element_get_state(GST_ELEMENT(object), &state, &pendingState, 0);
+
+    const bool paused
+                = (pendingState == GST_STATE_VOID_PENDING && state == GST_STATE_PAUSED)
+                || pendingState == GST_STATE_PAUSED;
+
+    if (paused) {
+        QMutexLocker locker(&delegate->m_mutex);
+
+        if (!showPreroll && delegate->m_lastBuffer) {
+            delegate->m_render = false;
+            delegate->m_flush = true;
+            delegate->notify();
+        } else if (delegate->m_lastBuffer) {
+            delegate->m_render = true;
+            delegate->notify();
+        }
+    }
+}
+
+bool QVideoSurfaceGstDelegate::event(QEvent *event)
+{
+    if (event->type() == QEvent::UpdateRequest) {
+        QMutexLocker locker(&m_mutex);
+
+        if (m_notified) {
+            while (handleEvent(&locker)) {}
+            m_notified = false;
+        }
+        return true;
+    } else {
+        return QObject::event(event);
+    }
+}
+
+bool QVideoSurfaceGstDelegate::handleEvent(QMutexLocker *locker)
+{
+    if (m_flush) {
+        m_flush = false;
+        if (m_activeRenderer) {
+            locker->unlock();
+
+            m_activeRenderer->flush(m_surface);
+        }
+    } else if (m_stop) {
+        m_stop = false;
+
+        if (QGstVideoRenderer * const activePool = m_activeRenderer) {
+            m_activeRenderer = 0;
+            locker->unlock();
+
+            activePool->stop(m_surface);
+
+            locker->relock();
+        }
+    } else if (m_startCaps) {
+        Q_ASSERT(!m_activeRenderer);
+
+        GstCaps * const startCaps = m_startCaps;
+        m_startCaps = 0;
+
+        if (m_renderer && m_surface) {
+            locker->unlock();
+
+            const bool started = m_renderer->start(m_surface, startCaps);
+
+            locker->relock();
+
+            m_activeRenderer = started
+                    ? m_renderer
+                    : 0;
+        } else if (QGstVideoRenderer * const activePool = m_activeRenderer) {
+            m_activeRenderer = 0;
+            locker->unlock();
+
+            activePool->stop(m_surface);
+
+            locker->relock();
+        }
+
+        gst_caps_unref(startCaps);
+    } else if (m_render) {
+        m_render = false;
+
+        if (m_activeRenderer && m_surface && m_lastBuffer) {
+            GstBuffer *buffer = m_lastBuffer;
+            gst_buffer_ref(buffer);
+
+            locker->unlock();
+
+            const bool rendered = m_activeRenderer->present(m_surface, buffer);
+
+            gst_buffer_unref(buffer);
+
+            locker->relock();
+
+            m_renderReturn = rendered
+                    ? GST_FLOW_OK
+                    : GST_FLOW_ERROR;
+
+            m_renderCondition.wakeAll();
+        } else {
+            m_renderReturn = GST_FLOW_ERROR;
+            m_renderCondition.wakeAll();
+        }
+    } else {
+        m_setupCondition.wakeAll();
+
+        return false;
+    }
+    return true;
+}
+
+void QVideoSurfaceGstDelegate::notify()
+{
+    if (!m_notified) {
+        m_notified = true;
+        QCoreApplication::postEvent(this, new QEvent(QEvent::UpdateRequest));
+    }
+}
+
+bool QVideoSurfaceGstDelegate::waitForAsyncEvent(
+        QMutexLocker *locker, QWaitCondition *condition, unsigned long time)
+{
+    if (QThread::currentThread() == thread()) {
+        while (handleEvent(locker)) {}
+        m_notified = false;
+
+        return true;
+    } else {
+        notify();
+
+        return condition->wait(&m_mutex, time);
+    }
+}
+
+void QVideoSurfaceGstDelegate::updateSupportedFormats()
+{
+    if (m_surfaceCaps) {
+        gst_caps_unref(m_surfaceCaps);
+        m_surfaceCaps = 0;
+    }
+
+    foreach (QGstVideoRenderer *pool, m_renderers) {
+        if (GstCaps *caps = pool->getCaps(m_surface)) {
+            if (gst_caps_is_empty(caps)) {
+                gst_caps_unref(caps);
+                continue;
+            }
+
+            if (m_surfaceCaps)
+                gst_caps_unref(m_surfaceCaps);
+
+            m_renderer = pool;
+            m_surfaceCaps = caps;
+            break;
+        } else {
+            gst_caps_unref(caps);
+        }
+    }
+}
+
+static GstVideoSinkClass *sink_parent_class;
+
+#define VO_SINK(s) QGstVideoRendererSink *sink(reinterpret_cast<QGstVideoRendererSink *>(s))
+
+QGstVideoRendererSink *QGstVideoRendererSink::createSink(QAbstractVideoSurface *surface)
+{
+    QGstVideoRendererSink *sink = reinterpret_cast<QGstVideoRendererSink *>(
+            g_object_new(QGstVideoRendererSink::get_type(), 0));
+
+    sink->delegate = new QVideoSurfaceGstDelegate(surface);
+
+    g_signal_connect(
+                G_OBJECT(sink),
+                "notify::show-preroll-frame",
+                G_CALLBACK(QVideoSurfaceGstDelegate::handleShowPrerollChange),
+                sink->delegate);
+
+    return sink;
+}
+
+GType QGstVideoRendererSink::get_type()
+{
+    static GType type = 0;
+
+    if (type == 0) {
+        static const GTypeInfo info =
+        {
+            sizeof(QGstVideoRendererSinkClass),                    // class_size
+            base_init,                                         // base_init
+            NULL,                                              // base_finalize
+            class_init,                                        // class_init
+            NULL,                                              // class_finalize
+            NULL,                                              // class_data
+            sizeof(QGstVideoRendererSink),                         // instance_size
+            0,                                                 // n_preallocs
+            instance_init,                                     // instance_init
+            0                                                  // value_table
+        };
+
+        type = g_type_register_static(
+                GST_TYPE_VIDEO_SINK, "QGstVideoRendererSink", &info, GTypeFlags(0));
+    }
+
+    return type;
+}
+
+void QGstVideoRendererSink::class_init(gpointer g_class, gpointer class_data)
+{
+    Q_UNUSED(class_data);
+
+    sink_parent_class = reinterpret_cast<GstVideoSinkClass *>(g_type_class_peek_parent(g_class));
+
+    GstBaseSinkClass *base_sink_class = reinterpret_cast<GstBaseSinkClass *>(g_class);
+    base_sink_class->get_caps = QGstVideoRendererSink::get_caps;
+    base_sink_class->set_caps = QGstVideoRendererSink::set_caps;
+    base_sink_class->propose_allocation = QGstVideoRendererSink::propose_allocation;
+    base_sink_class->preroll = QGstVideoRendererSink::preroll;
+    base_sink_class->render = QGstVideoRendererSink::render;
+
+    GstElementClass *element_class = reinterpret_cast<GstElementClass *>(g_class);
+    element_class->change_state = QGstVideoRendererSink::change_state;
+
+    GObjectClass *object_class = reinterpret_cast<GObjectClass *>(g_class);
+    object_class->finalize = QGstVideoRendererSink::finalize;
+}
+
+void QGstVideoRendererSink::base_init(gpointer g_class)
+{
+    static GstStaticPadTemplate sink_pad_template = GST_STATIC_PAD_TEMPLATE(
+            "sink", GST_PAD_SINK, GST_PAD_ALWAYS, GST_STATIC_CAPS(
+                    "video/x-raw, "
+                    "framerate = (fraction) [ 0, MAX ], "
+                    "width = (int) [ 1, MAX ], "
+                    "height = (int) [ 1, MAX ]"));
+
+    gst_element_class_add_pad_template(
+            GST_ELEMENT_CLASS(g_class), gst_static_pad_template_get(&sink_pad_template));
+}
+
+void QGstVideoRendererSink::instance_init(GTypeInstance *instance, gpointer g_class)
+{
+    VO_SINK(instance);
+
+    Q_UNUSED(g_class);
+
+    sink->delegate = 0;
+}
+
+void QGstVideoRendererSink::finalize(GObject *object)
+{
+    VO_SINK(object);
+
+    delete sink->delegate;
+
+    // Chain up
+    G_OBJECT_CLASS(sink_parent_class)->finalize(object);
+}
+
+GstStateChangeReturn QGstVideoRendererSink::change_state(
+        GstElement *element, GstStateChange transition)
+{
+    Q_UNUSED(element);
+
+    return GST_ELEMENT_CLASS(sink_parent_class)->change_state(
+            element, transition);
+}
+
+GstCaps *QGstVideoRendererSink::get_caps(GstBaseSink *base, GstCaps *filter)
+{
+    VO_SINK(base);
+
+    GstCaps *caps = sink->delegate->caps();
+    GstCaps *unfiltered = caps;
+    if (filter) {
+        caps = gst_caps_intersect(unfiltered, filter);
+        gst_caps_unref(unfiltered);
+    }
+
+    return caps;
+}
+
+gboolean QGstVideoRendererSink::set_caps(GstBaseSink *base, GstCaps *caps)
+{
+    VO_SINK(base);
+
+#ifdef DEBUG_VIDEO_SURFACE_SINK
+    qDebug() << "set_caps:";
+    qDebug() << caps;
+#endif
+
+    if (!caps) {
+        sink->delegate->stop();
+
+        return TRUE;
+    } else if (sink->delegate->start(caps)) {
+        return TRUE;
+    } else {
+        return FALSE;
+    }
+}
+
+gboolean QGstVideoRendererSink::propose_allocation(GstBaseSink *base, GstQuery *query)
+{
+    VO_SINK(base);
+    return sink->delegate->proposeAllocation(query);
+}
+
+GstFlowReturn QGstVideoRendererSink::preroll(GstBaseSink *base, GstBuffer *buffer)
+{
+    VO_SINK(base);
+
+    gboolean showPreroll = true; // "show-preroll-frame" property is true by default
+    g_object_get(G_OBJECT(base), "show-preroll-frame", &showPreroll, NULL);
+
+    return sink->delegate->render(buffer, showPreroll); // display frame
+}
+
+GstFlowReturn QGstVideoRendererSink::render(GstBaseSink *base, GstBuffer *buffer)
+{
+    VO_SINK(base);
+    return sink->delegate->render(buffer, true);
+}
+
+QT_END_NAMESPACE
diff --git a/src/gsttools/qvideosurfacegstsink.cpp b/src/gsttools/qvideosurfacegstsink.cpp
index 81d5f60..4260767 100644
--- a/src/gsttools/qvideosurfacegstsink.cpp
+++ b/src/gsttools/qvideosurfacegstsink.cpp
@@ -49,8 +49,13 @@
 #include <private/qmediapluginloader_p.h>
 #include "qgstvideobuffer_p.h"
 
+#include "qgstutils_p.h"
 #include "qvideosurfacegstsink_p.h"
 
+#if GST_VERSION_MAJOR >=1
+#include <gst/video/video.h>
+#endif
+
 //#define DEBUG_VIDEO_SURFACE_SINK
 
 QT_BEGIN_NAMESPACE
@@ -71,10 +76,12 @@ QVideoSurfaceGstDelegate::QVideoSurfaceGstDelegate(
     if (m_surface) {
         foreach (QObject *instance, bufferPoolLoader()->instances(QGstBufferPoolPluginKey)) {
             QGstBufferPoolInterface* plugin = qobject_cast<QGstBufferPoolInterface*>(instance);
+
             if (plugin) {
                 m_pools.append(plugin);
             }
         }
+
         updateSupportedFormats();
         connect(m_surface, SIGNAL(supportedFormatsChanged()), this, SLOT(updateSupportedFormats()));
     }
@@ -201,13 +208,15 @@ GstFlowReturn QVideoSurfaceGstDelegate::render(GstBuffer *buffer)
             m_format.frameSize(),
             m_format.pixelFormat());
 
-    QVideoSurfaceGstSink::setFrameTimeStamps(&m_frame, buffer);
+    QGstUtils::setFrameTimeStamps(&m_frame, buffer);
 
     m_renderReturn = GST_FLOW_OK;
 
     if (QThread::currentThread() == thread()) {
         if (!m_surface.isNull())
             m_surface->present(m_frame);
+        else
+            qWarning() << "m_surface.isNull().";
     } else {
         QMetaObject::invokeMethod(this, "queuedRender", Qt::QueuedConnection);
         m_renderCondition.wait(&m_mutex, 300);
@@ -310,90 +319,6 @@ void QVideoSurfaceGstDelegate::updateSupportedFormats()
     }
 }
 
-struct YuvFormat
-{
-    QVideoFrame::PixelFormat pixelFormat;
-    guint32 fourcc;
-    int bitsPerPixel;
-};
-
-static const YuvFormat qt_yuvColorLookup[] =
-{
-    { QVideoFrame::Format_YUV420P, GST_MAKE_FOURCC('I','4','2','0'), 8 },
-    { QVideoFrame::Format_YV12,    GST_MAKE_FOURCC('Y','V','1','2'), 8 },
-    { QVideoFrame::Format_UYVY,    GST_MAKE_FOURCC('U','Y','V','Y'), 16 },
-    { QVideoFrame::Format_YUYV,    GST_MAKE_FOURCC('Y','U','Y','2'), 16 },
-    { QVideoFrame::Format_NV12,    GST_MAKE_FOURCC('N','V','1','2'), 8 },
-    { QVideoFrame::Format_NV21,    GST_MAKE_FOURCC('N','V','2','1'), 8 },
-    { QVideoFrame::Format_AYUV444, GST_MAKE_FOURCC('A','Y','U','V'), 32 }
-};
-
-static int indexOfYuvColor(QVideoFrame::PixelFormat format)
-{
-    const int count = sizeof(qt_yuvColorLookup) / sizeof(YuvFormat);
-
-    for (int i = 0; i < count; ++i)
-        if (qt_yuvColorLookup[i].pixelFormat == format)
-            return i;
-
-    return -1;
-}
-
-static int indexOfYuvColor(guint32 fourcc)
-{
-    const int count = sizeof(qt_yuvColorLookup) / sizeof(YuvFormat);
-
-    for (int i = 0; i < count; ++i)
-        if (qt_yuvColorLookup[i].fourcc == fourcc)
-            return i;
-
-    return -1;
-}
-
-struct RgbFormat
-{
-    QVideoFrame::PixelFormat pixelFormat;
-    int bitsPerPixel;
-    int depth;
-    int endianness;
-    int red;
-    int green;
-    int blue;
-    int alpha;
-};
-
-static const RgbFormat qt_rgbColorLookup[] =
-{
-    { QVideoFrame::Format_RGB32 , 32, 24, 4321, 0x0000FF00, 0x00FF0000, int(0xFF000000), 0x00000000 },
-    { QVideoFrame::Format_RGB32 , 32, 24, 1234, 0x00FF0000, 0x0000FF00, 0x000000FF, 0x00000000 },
-    { QVideoFrame::Format_BGR32 , 32, 24, 4321, int(0xFF000000), 0x00FF0000, 0x0000FF00, 0x00000000 },
-    { QVideoFrame::Format_BGR32 , 32, 24, 1234, 0x000000FF, 0x0000FF00, 0x00FF0000, 0x00000000 },
-    { QVideoFrame::Format_ARGB32, 32, 24, 4321, 0x0000FF00, 0x00FF0000, int(0xFF000000), 0x000000FF },
-    { QVideoFrame::Format_ARGB32, 32, 24, 1234, 0x00FF0000, 0x0000FF00, 0x000000FF, int(0xFF000000) },
-    { QVideoFrame::Format_RGB24 , 24, 24, 4321, 0x00FF0000, 0x0000FF00, 0x000000FF, 0x00000000 },
-    { QVideoFrame::Format_BGR24 , 24, 24, 4321, 0x000000FF, 0x0000FF00, 0x00FF0000, 0x00000000 },
-    { QVideoFrame::Format_RGB565, 16, 16, 1234, 0x0000F800, 0x000007E0, 0x0000001F, 0x00000000 }
-};
-
-static int indexOfRgbColor(
-        int bits, int depth, int endianness, int red, int green, int blue, int alpha)
-{
-    const int count = sizeof(qt_rgbColorLookup) / sizeof(RgbFormat);
-
-    for (int i = 0; i < count; ++i) {
-        if (qt_rgbColorLookup[i].bitsPerPixel == bits
-            && qt_rgbColorLookup[i].depth == depth
-            && qt_rgbColorLookup[i].endianness == endianness
-            && qt_rgbColorLookup[i].red == red
-            && qt_rgbColorLookup[i].green == green
-            && qt_rgbColorLookup[i].blue == blue
-            && qt_rgbColorLookup[i].alpha == alpha) {
-            return i;
-        }
-    }
-    return -1;
-}
-
 static GstVideoSinkClass *sink_parent_class;
 
 #define VO_SINK(s) QVideoSurfaceGstSink *sink(reinterpret_cast<QVideoSurfaceGstSink *>(s))
@@ -417,13 +342,13 @@ GType QVideoSurfaceGstSink::get_type()
     if (type == 0) {
         static const GTypeInfo info =
         {
-            sizeof(QVideoSurfaceGstSinkClass),                    // class_size
+            sizeof(QVideoSurfaceGstSinkClass),                 // class_size
             base_init,                                         // base_init
             NULL,                                              // base_finalize
             class_init,                                        // class_init
             NULL,                                              // class_finalize
             NULL,                                              // class_data
-            sizeof(QVideoSurfaceGstSink),                         // instance_size
+            sizeof(QVideoSurfaceGstSink),                      // instance_size
             0,                                                 // n_preallocs
             instance_init,                                     // instance_init
             0                                                  // value_table
@@ -524,8 +449,6 @@ GstCaps *QVideoSurfaceGstSink::get_caps(GstBaseSink *base)
 {
     VO_SINK(base);
 
-    GstCaps *caps = gst_caps_new_empty();
-
     // Find the supported pixel formats
     // with buffer pool specific formats listed first
     QList<QVideoFrame::PixelFormat> supportedFormats;
@@ -533,6 +456,7 @@ GstCaps *QVideoSurfaceGstSink::get_caps(GstBaseSink *base)
     QList<QVideoFrame::PixelFormat> poolHandleFormats;
     sink->delegate->poolMutex()->lock();
     QGstBufferPoolInterface *pool = sink->delegate->pool();
+
     if (pool)
         poolHandleFormats = sink->delegate->supportedPixelFormats(pool->handleType());
     sink->delegate->poolMutex()->unlock();
@@ -543,47 +467,7 @@ GstCaps *QVideoSurfaceGstSink::get_caps(GstBaseSink *base)
             supportedFormats.append(format);
     }
 
-    foreach (QVideoFrame::PixelFormat format, supportedFormats) {
-        int index = indexOfYuvColor(format);
-
-        if (index != -1) {
-            gst_caps_append_structure(caps, gst_structure_new(
-                    "video/x-raw-yuv",
-                    "framerate", GST_TYPE_FRACTION_RANGE, 0, 1, INT_MAX, 1,
-                    "width"    , GST_TYPE_INT_RANGE, 1, INT_MAX,
-                    "height"   , GST_TYPE_INT_RANGE, 1, INT_MAX,
-                    "format"   , GST_TYPE_FOURCC, qt_yuvColorLookup[index].fourcc,
-                    NULL));
-            continue;
-        }
-
-        const int count = sizeof(qt_rgbColorLookup) / sizeof(RgbFormat);
-
-        for (int i = 0; i < count; ++i) {
-            if (qt_rgbColorLookup[i].pixelFormat == format) {
-                GstStructure *structure = gst_structure_new(
-                        "video/x-raw-rgb",
-                        "framerate" , GST_TYPE_FRACTION_RANGE, 0, 1, INT_MAX, 1,
-                        "width"     , GST_TYPE_INT_RANGE, 1, INT_MAX,
-                        "height"    , GST_TYPE_INT_RANGE, 1, INT_MAX,
-                        "bpp"       , G_TYPE_INT, qt_rgbColorLookup[i].bitsPerPixel,
-                        "depth"     , G_TYPE_INT, qt_rgbColorLookup[i].depth,
-                        "endianness", G_TYPE_INT, qt_rgbColorLookup[i].endianness,
-                        "red_mask"  , G_TYPE_INT, qt_rgbColorLookup[i].red,
-                        "green_mask", G_TYPE_INT, qt_rgbColorLookup[i].green,
-                        "blue_mask" , G_TYPE_INT, qt_rgbColorLookup[i].blue,
-                        NULL);
-
-                if (qt_rgbColorLookup[i].alpha != 0) {
-                    gst_structure_set(
-                            structure, "alpha_mask", G_TYPE_INT, qt_rgbColorLookup[i].alpha, NULL);
-                }
-                gst_caps_append_structure(caps, structure);
-            }
-        }
-    }
-
-    return caps;
+    return QGstUtils::capsForFormats(supportedFormats);
 }
 
 gboolean QVideoSurfaceGstSink::set_caps(GstBaseSink *base, GstCaps *caps)
@@ -605,7 +489,7 @@ gboolean QVideoSurfaceGstSink::set_caps(GstBaseSink *base, GstCaps *caps)
         QAbstractVideoBuffer::HandleType handleType =
                 pool ? pool->handleType() : QAbstractVideoBuffer::NoHandle;
 
-        QVideoSurfaceFormat format = formatForCaps(caps, &bytesPerLine, handleType);
+        QVideoSurfaceFormat format = QGstUtils::formatForCaps(caps, &bytesPerLine, handleType);
 
         if (sink->delegate->isActive()) {
             QVideoSurfaceFormat surfaceFormst = sink->delegate->surfaceFormat();
@@ -622,7 +506,7 @@ gboolean QVideoSurfaceGstSink::set_caps(GstBaseSink *base, GstCaps *caps)
         sink->lastRequestedCaps = 0;
 
 #ifdef DEBUG_VIDEO_SURFACE_SINK
-        qDebug() << "Staring video surface, format:";
+        qDebug() << "Starting video surface, format:";
         qDebug() << format;
         qDebug() << "bytesPerLine:" << bytesPerLine;
 #endif
@@ -636,87 +520,6 @@ gboolean QVideoSurfaceGstSink::set_caps(GstBaseSink *base, GstCaps *caps)
     return FALSE;
 }
 
-QVideoSurfaceFormat QVideoSurfaceGstSink::formatForCaps(GstCaps *caps, int *bytesPerLine, QAbstractVideoBuffer::HandleType handleType)
-{
-    const GstStructure *structure = gst_caps_get_structure(caps, 0);
-
-    QVideoFrame::PixelFormat pixelFormat = QVideoFrame::Format_Invalid;
-    int bitsPerPixel = 0;
-
-    QSize size;
-    gst_structure_get_int(structure, "width", &size.rwidth());
-    gst_structure_get_int(structure, "height", &size.rheight());
-
-    if (qstrcmp(gst_structure_get_name(structure), "video/x-raw-yuv") == 0) {
-        guint32 fourcc = 0;
-        gst_structure_get_fourcc(structure, "format", &fourcc);
-
-        int index = indexOfYuvColor(fourcc);
-        if (index != -1) {
-            pixelFormat = qt_yuvColorLookup[index].pixelFormat;
-            bitsPerPixel = qt_yuvColorLookup[index].bitsPerPixel;
-        }
-    } else if (qstrcmp(gst_structure_get_name(structure), "video/x-raw-rgb") == 0) {
-        int depth = 0;
-        int endianness = 0;
-        int red = 0;
-        int green = 0;
-        int blue = 0;
-        int alpha = 0;
-
-        gst_structure_get_int(structure, "bpp", &bitsPerPixel);
-        gst_structure_get_int(structure, "depth", &depth);
-        gst_structure_get_int(structure, "endianness", &endianness);
-        gst_structure_get_int(structure, "red_mask", &red);
-        gst_structure_get_int(structure, "green_mask", &green);
-        gst_structure_get_int(structure, "blue_mask", &blue);
-        gst_structure_get_int(structure, "alpha_mask", &alpha);
-
-        int index = indexOfRgbColor(bitsPerPixel, depth, endianness, red, green, blue, alpha);
-
-        if (index != -1)
-            pixelFormat = qt_rgbColorLookup[index].pixelFormat;
-    }
-
-    if (pixelFormat != QVideoFrame::Format_Invalid) {
-        QVideoSurfaceFormat format(size, pixelFormat, handleType);
-
-        QPair<int, int> rate;
-        gst_structure_get_fraction(structure, "framerate", &rate.first, &rate.second);
-
-        if (rate.second)
-            format.setFrameRate(qreal(rate.first)/rate.second);
-
-        gint aspectNum = 0;
-        gint aspectDenum = 0;
-        if (gst_structure_get_fraction(
-                structure, "pixel-aspect-ratio", &aspectNum, &aspectDenum)) {
-            if (aspectDenum > 0)
-                format.setPixelAspectRatio(aspectNum, aspectDenum);
-        }
-
-        if (bytesPerLine)
-            *bytesPerLine = ((size.width() * bitsPerPixel / 8) + 3) & ~3;
-
-        return format;
-    }
-
-    return QVideoSurfaceFormat();
-}
-
-void QVideoSurfaceGstSink::setFrameTimeStamps(QVideoFrame *frame, GstBuffer *buffer)
-{
-    // GStreamer uses nanoseconds, Qt uses microseconds
-    qint64 startTime = GST_BUFFER_TIMESTAMP(buffer);
-    if (startTime >= 0) {
-        frame->setStartTime(startTime/G_GINT64_CONSTANT (1000));
-
-        qint64 duration = GST_BUFFER_DURATION(buffer);
-        if (duration >= 0)
-            frame->setEndTime((startTime + duration)/G_GINT64_CONSTANT (1000));
-    }
-}
-
 void QVideoSurfaceGstSink::handleShowPrerollChange(GObject *o, GParamSpec *p, gpointer d)
 {
     Q_UNUSED(o);
@@ -782,7 +585,7 @@ GstFlowReturn QVideoSurfaceGstSink::buffer_alloc(
 
     if (sink->delegate->isActive()) {
         //if format was changed, restart the surface
-        QVideoSurfaceFormat format = formatForCaps(intersection);
+        QVideoSurfaceFormat format = QGstUtils::formatForCaps(intersection);
         QVideoSurfaceFormat surfaceFormat = sink->delegate->surfaceFormat();
 
         if (format.pixelFormat() != surfaceFormat.pixelFormat() ||
@@ -800,7 +603,7 @@ GstFlowReturn QVideoSurfaceGstSink::buffer_alloc(
         QAbstractVideoBuffer::HandleType handleType =
                 pool ? pool->handleType() : QAbstractVideoBuffer::NoHandle;
 
-        QVideoSurfaceFormat format = formatForCaps(intersection, &bytesPerLine, handleType);
+        QVideoSurfaceFormat format = QGstUtils::formatForCaps(intersection, &bytesPerLine, handleType);
 
         if (!sink->delegate->start(format, bytesPerLine)) {
             qWarning() << "failed to start video surface";
@@ -814,7 +617,7 @@ GstFlowReturn QVideoSurfaceGstSink::buffer_alloc(
     QVideoSurfaceFormat surfaceFormat = sink->delegate->surfaceFormat();
 
     if (!pool->isFormatSupported(surfaceFormat)) {
-        //qDebug() << "sink doesn't support native pool format, skip custom buffers allocation";
+        qDebug() << "sink doesn't support native pool format, skip custom buffers allocation";
         return GST_FLOW_OK;
     }
 
@@ -838,7 +641,6 @@ GstFlowReturn QVideoSurfaceGstSink::buffer_alloc(
 gboolean QVideoSurfaceGstSink::start(GstBaseSink *base)
 {
     Q_UNUSED(base);
-
     return TRUE;
 }
 
@@ -864,7 +666,6 @@ gboolean QVideoSurfaceGstSink::event(GstBaseSink *base, GstEvent *event)
         VO_SINK(base);
         sink->delegate->setLastPrerolledBuffer(0);
     }
-
     return TRUE;
 }
 
diff --git a/src/imports/multimedia/multimedia.cpp b/src/imports/multimedia/multimedia.cpp
index 5954db2..18c74e0 100644
--- a/src/imports/multimedia/multimedia.cpp
+++ b/src/imports/multimedia/multimedia.cpp
@@ -81,6 +81,7 @@ public:
         qmlRegisterType<QDeclarativeRadio>(uri, 5, 0, "Radio");
         qmlRegisterType<QDeclarativeRadioData>(uri, 5, 0, "RadioData");
         qmlRegisterType<QDeclarativeCamera>(uri, 5, 0, "Camera");
+        qmlRegisterRevision<QDeclarativeCamera, 1>(uri, 5, 4);
         qmlRegisterType<QDeclarativeTorch>(uri, 5, 0, "Torch");
         qmlRegisterUncreatableType<QDeclarativeCameraCapture>(uri, 5, 0, "CameraCapture",
                                 trUtf8("CameraCapture is provided by Camera"));
diff --git a/src/imports/multimedia/multimedia.pro b/src/imports/multimedia/multimedia.pro
index f6fdfe9..75974ec 100644
--- a/src/imports/multimedia/multimedia.pro
+++ b/src/imports/multimedia/multimedia.pro
@@ -13,7 +13,8 @@ HEADERS += \
         qdeclarativecamerafocus_p.h \
         qdeclarativecameraimageprocessing_p.h \
         qdeclarativecamerapreviewprovider_p.h \
-        qdeclarativetorch_p.h
+        qdeclarativetorch_p.h \
+        qdeclarativecameraviewfinder_p.h
 
 SOURCES += \
         multimedia.cpp \
@@ -28,7 +29,8 @@ SOURCES += \
         qdeclarativecamerafocus.cpp \
         qdeclarativecameraimageprocessing.cpp \
         qdeclarativecamerapreviewprovider.cpp \
-        qdeclarativetorch.cpp
+        qdeclarativetorch.cpp \
+        qdeclarativecameraviewfinder.cpp
 
 QML_FILES += \
     Video.qml
diff --git a/src/imports/multimedia/qdeclarativecamera.cpp b/src/imports/multimedia/qdeclarativecamera.cpp
index db5ba81..7e43875 100644
--- a/src/imports/multimedia/qdeclarativecamera.cpp
+++ b/src/imports/multimedia/qdeclarativecamera.cpp
@@ -46,6 +46,9 @@
 #include "qdeclarativecameraflash_p.h"
 #include "qdeclarativecamerafocus_p.h"
 #include "qdeclarativecameraimageprocessing_p.h"
+#include "qdeclarativecameraviewfinder_p.h"
+
+#include "qdeclarativemediametadata_p.h"
 
 #include <qmediaplayercontrol.h>
 #include <qmediaservice.h>
@@ -172,6 +175,7 @@ void QDeclarativeCamera::_q_availabilityChanged(QMultimedia::AvailabilityStatus
 QDeclarativeCamera::QDeclarativeCamera(QObject *parent) :
     QObject(parent),
     m_camera(0),
+    m_metaData(0),
     m_pendingState(ActiveState),
     m_componentComplete(false)
 {
@@ -200,6 +204,8 @@ QDeclarativeCamera::QDeclarativeCamera(QObject *parent) :
 /*! Destructor, clean up memory */
 QDeclarativeCamera::~QDeclarativeCamera()
 {
+    delete m_metaData;
+
     m_camera->unload();
 }
 
@@ -628,13 +634,13 @@ void QDeclarativeCamera::setDigitalZoom(qreal value)
 */
 
 /*!
-    \qmlsignal Camera::stateChanged(state)
+    \qmlsignal Camera::cameraStateChanged(state)
 
     This signal is emitted when the camera state has changed to \a state.  Since the
     state changes may take some time to occur this signal may arrive sometime
     after the state change has been requested.
 
-    The corresponding handler is \c onStateChanged.
+    The corresponding handler is \c onCameraStateChanged.
 */
 
 /*!
@@ -673,6 +679,156 @@ void QDeclarativeCamera::setDigitalZoom(qreal value)
     The corresponding handler is \c onMaximumDigitalZoomChanged.
 */
 
+/*!
+    \qmlproperty variant QtMultimedia::Camera::metaData.cameraManufacturer
+
+    This property holds the name of the manufacturer of the camera.
+
+    \sa {QMediaMetaData}
+    \since 5.4
+*/
+
+/*!
+    \qmlproperty variant QtMultimedia::Camera::metaData.cameraModel
+
+    This property holds the name of the model of the camera.
+
+    \sa {QMediaMetaData}
+    \since 5.4
+*/
+
+/*!
+    \qmlproperty variant QtMultimedia::Camera::metaData.event
+
+    This property holds the event during which the photo or video is to be captured.
+
+    \sa {QMediaMetaData}
+    \since 5.4
+*/
+
+/*!
+    \qmlproperty variant QtMultimedia::Camera::metaData.subject
+
+    This property holds the name of the subject of the capture or recording.
+
+    \sa {QMediaMetaData}
+    \since 5.4
+*/
+
+/*!
+    \qmlproperty variant QtMultimedia::Camera::metaData.orientation
+
+    This property holds the clockwise rotation of the camera at time of capture.
+
+    \sa {QMediaMetaData}
+    \since 5.4
+*/
+
+/*!
+    \qmlproperty variant QtMultimedia::Camera::metaData.dateTimeOriginal
+
+    This property holds the initial time at which the photo or video is
+    captured.
+
+    \sa {QMediaMetaData}
+    \since 5.4
+*/
+
+/*!
+    \qmlproperty variant QtMultimedia::Camera::metaData.gpsLatitude
+    \qmlproperty variant QtMultimedia::Camera::metaData.gpsLongitude
+    \qmlproperty variant QtMultimedia::Camera::metaData.gpsAltitude
+
+    These properties hold the the geographic position in decimal degrees of the
+    camera at time of capture.
+
+    \sa {QMediaMetaData}
+    \since 5.4
+*/
+
+/*!
+    \qmlproperty variant QtMultimedia::Camera::metaData.gpsTimestamp
+
+    This property holds the timestamp of the GPS position data.
+
+    \sa {QMediaMetaData}
+    \since 5.4
+*/
+
+/*!
+    \qmlproperty variant QtMultimedia::Camera::metaData.gpsTrack
+
+    This property holds direction of movement of the camera at the time of
+    capture. It is measured in degrees clockwise from north.
+
+    \sa {QMediaMetaData}
+    \since 5.4
+*/
+
+/*!
+    \qmlproperty variant QtMultimedia::Camera::metaData.gpsSpeed
+
+    This property holds the velocity in kilometers per hour of the camera at
+    time of capture.
+
+    \sa {QMediaMetaData}
+    \since 5.4
+*/
+
+/*!
+    \qmlproperty variant QtMultimedia::Camera::metaData.gpsImgDirection
+
+    This property holds direction the camera is facing at the time of capture.
+    It is measured in degrees clockwise from north.
+
+    \sa {QMediaMetaData}
+    \since 5.4
+*/
+
+/*!
+    \qmlproperty variant QtMultimedia::Camera::metaData.gpsProcessingMethod
+
+    This property holds the name of the method for determining the GPS position
+    data.
+
+    \sa {QMediaMetaData}
+    \since 5.4
+*/
+
+QDeclarativeMediaMetaData *QDeclarativeCamera::metaData()
+{
+    if (!m_metaData)
+        m_metaData = new QDeclarativeMediaMetaData(m_camera, this);
+    return m_metaData;
+}
+
+/*!
+    \qmlproperty size QtMultimedia::Camera::viewfinder.resolution
+
+    This property holds the resolution of the camera viewfinder. If no
+    resolution is given the backend will use a default value.
+
+    \since 5.4
+*/
+
+/*!
+    \qmlproperty real QtMultimedia::Camera::viewfinder.minimumFrameRate
+    \qmlproperty real QtMultimedia::Camera::viewfinder.maximumFrameRate
+
+    These properties hold the limits of the preferred frame rate for the
+    viewfinder in frames per second.
+
+    \since 5.4
+ */
+
+QDeclarativeCameraViewfinder *QDeclarativeCamera::viewfinder()
+{
+    if (!m_viewfinder)
+        m_viewfinder = new QDeclarativeCameraViewfinder(m_camera, this);
+
+    return m_viewfinder;
+}
+
 QT_END_NAMESPACE
 
 #include "moc_qdeclarativecamera_p.cpp"
diff --git a/src/imports/multimedia/qdeclarativecamera_p.h b/src/imports/multimedia/qdeclarativecamera_p.h
index 8638c42..e7745ab 100644
--- a/src/imports/multimedia/qdeclarativecamera_p.h
+++ b/src/imports/multimedia/qdeclarativecamera_p.h
@@ -71,6 +71,8 @@ class QDeclarativeCameraExposure;
 class QDeclarativeCameraFocus;
 class QDeclarativeCameraFlash;
 class QDeclarativeCameraImageProcessing;
+class QDeclarativeMediaMetaData;
+class QDeclarativeCameraViewfinder;
 
 class QDeclarativeCamera : public QObject, public QQmlParserStatus
 {
@@ -98,6 +100,8 @@ class QDeclarativeCamera : public QObject, public QQmlParserStatus
     Q_PROPERTY(QDeclarativeCameraFlash* flash READ flash CONSTANT)
     Q_PROPERTY(QDeclarativeCameraFocus* focus READ focus CONSTANT)
     Q_PROPERTY(QDeclarativeCameraImageProcessing* imageProcessing READ imageProcessing CONSTANT)
+    Q_PROPERTY(QDeclarativeMediaMetaData *metaData READ metaData CONSTANT REVISION 1)
+    Q_PROPERTY(QDeclarativeCameraViewfinder *viewfinder READ viewfinder CONSTANT REVISION 1)
 
     Q_ENUMS(CaptureMode)
     Q_ENUMS(State)
@@ -231,6 +235,9 @@ public:
     QDeclarativeCameraFlash *flash() { return m_flash; }
     QDeclarativeCameraFocus *focus() { return m_focus; }
     QDeclarativeCameraImageProcessing *imageProcessing() { return m_imageProcessing; }
+    QDeclarativeCameraViewfinder *viewfinder();
+
+    QDeclarativeMediaMetaData *metaData();
 
     CaptureMode captureMode() const;
     State cameraState() const;
@@ -301,6 +308,8 @@ private:
     QDeclarativeCameraFlash *m_flash;
     QDeclarativeCameraFocus *m_focus;
     QDeclarativeCameraImageProcessing *m_imageProcessing;
+    QDeclarativeMediaMetaData *m_metaData;
+    QDeclarativeCameraViewfinder *m_viewfinder;
 
     State m_pendingState;
     bool m_componentComplete;
diff --git a/src/imports/multimedia/qdeclarativecameraviewfinder.cpp b/src/imports/multimedia/qdeclarativecameraviewfinder.cpp
new file mode 100644
index 0000000..5fa9dad
--- /dev/null
+++ b/src/imports/multimedia/qdeclarativecameraviewfinder.cpp
@@ -0,0 +1,117 @@
+/****************************************************************************
+**
+** Copyright (C) 2014 Jolla Ltd.
+** Contact: http://www.qt-project.org/legal
+**
+** This file is part of the plugins of the Qt Toolkit.
+**
+** $QT_BEGIN_LICENSE:LGPL$
+** Commercial License Usage
+** Licensees holding valid commercial Qt licenses may use this file in
+** accordance with the commercial license agreement provided with the
+** Software or, alternatively, in accordance with the terms contained in
+** a written agreement between you and Digia.  For licensing terms and
+** conditions see http://qt.digia.com/licensing.  For further information
+** use the contact form at http://qt.digia.com/contact-us.
+**
+** GNU Lesser General Public License Usage
+** Alternatively, this file may be used under the terms of the GNU Lesser
+** General Public License version 2.1 as published by the Free Software
+** Foundation and appearing in the file LICENSE.LGPL included in the
+** packaging of this file.  Please review the following information to
+** ensure the GNU Lesser General Public License version 2.1 requirements
+** will be met: http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html.
+**
+** In addition, as a special exception, Digia gives you certain additional
+** rights.  These rights are described in the Digia Qt LGPL Exception
+** version 1.1, included in the file LGPL_EXCEPTION.txt in this package.
+**
+** GNU General Public License Usage
+** Alternatively, this file may be used under the terms of the GNU
+** General Public License version 3.0 as published by the Free Software
+** Foundation and appearing in the file LICENSE.GPL included in the
+** packaging of this file.  Please review the following information to
+** ensure the GNU General Public License version 3.0 requirements will be
+** met: http://www.gnu.org/copyleft/gpl.html.
+**
+**
+** $QT_END_LICENSE$
+**
+****************************************************************************/
+
+#include "qdeclarativecamera_p.h"
+#include "qdeclarativecameraviewfinder_p.h"
+
+#include <QtMultimedia/qcameraviewfindersettingscontrol.h>
+
+
+QT_BEGIN_NAMESPACE
+
+QDeclarativeCameraViewfinder::QDeclarativeCameraViewfinder(QCamera *camera, QObject *parent)
+    : QObject(parent)
+    , m_camera(camera)
+    , m_control(0)
+{
+    if (QMediaService *service = m_camera->service())
+        m_control = service->requestControl<QCameraViewfinderSettingsControl *>();
+}
+
+QDeclarativeCameraViewfinder::~QDeclarativeCameraViewfinder()
+{
+    if (m_control) {
+        if (QMediaService *service = m_camera->service())
+            service->releaseControl(m_control);
+    }
+}
+
+QSize QDeclarativeCameraViewfinder::resolution() const
+{
+    return m_control
+            ? m_control->viewfinderParameter(QCameraViewfinderSettingsControl::Resolution).value<QSize>()
+            : QSize();
+}
+
+void QDeclarativeCameraViewfinder::setResolution(const QSize &resolution)
+{
+    if (m_control) {
+        m_control->setViewfinderParameter(
+                    QCameraViewfinderSettingsControl::Resolution, resolution);
+        emit resolutionChanged();
+    }
+}
+
+qreal QDeclarativeCameraViewfinder::minimumFrameRate() const
+{
+    return m_control
+            ? m_control->viewfinderParameter(QCameraViewfinderSettingsControl::MinimumFrameRate).value<qreal>()
+            : 0.0;
+}
+
+void QDeclarativeCameraViewfinder::setMinimumFrameRate(qreal frameRate)
+{
+    if (m_control) {
+        m_control->setViewfinderParameter(
+                    QCameraViewfinderSettingsControl::MinimumFrameRate, frameRate);
+        emit minimumFrameRateChanged();
+    }
+}
+
+qreal QDeclarativeCameraViewfinder::maximumFrameRate() const
+{
+    return m_control
+            ? m_control->viewfinderParameter(QCameraViewfinderSettingsControl::MaximumFrameRate).value<qreal>()
+            : 0.0;
+}
+
+void QDeclarativeCameraViewfinder::setMaximumFrameRate(qreal frameRate)
+{
+    if (m_control) {
+        m_control->setViewfinderParameter(
+                    QCameraViewfinderSettingsControl::MaximumFrameRate, frameRate);
+        emit maximumFrameRateChanged();
+    }
+}
+
+QT_END_NAMESPACE
+
+#include "moc_qdeclarativecameraviewfinder_p.cpp"
diff --git a/src/imports/multimedia/qdeclarativecameraviewfinder_p.h b/src/imports/multimedia/qdeclarativecameraviewfinder_p.h
new file mode 100644
index 0000000..e28eb79
--- /dev/null
+++ b/src/imports/multimedia/qdeclarativecameraviewfinder_p.h
@@ -0,0 +1,96 @@
+/****************************************************************************
+**
+** Copyright (C) 2014 Jolla Ltd.
+** Contact: http://www.qt-project.org/legal
+**
+** This file is part of the plugins of the Qt Toolkit.
+**
+** $QT_BEGIN_LICENSE:LGPL$
+** Commercial License Usage
+** Licensees holding valid commercial Qt licenses may use this file in
+** accordance with the commercial license agreement provided with the
+** Software or, alternatively, in accordance with the terms contained in
+** a written agreement between you and Digia.  For licensing terms and
+** conditions see http://qt.digia.com/licensing.  For further information
+** use the contact form at http://qt.digia.com/contact-us.
+**
+** GNU Lesser General Public License Usage
+** Alternatively, this file may be used under the terms of the GNU Lesser
+** General Public License version 2.1 as published by the Free Software
+** Foundation and appearing in the file LICENSE.LGPL included in the
+** packaging of this file.  Please review the following information to
+** ensure the GNU Lesser General Public License version 2.1 requirements
+** will be met: http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html.
+**
+** In addition, as a special exception, Digia gives you certain additional
+** rights.  These rights are described in the Digia Qt LGPL Exception
+** version 1.1, included in the file LGPL_EXCEPTION.txt in this package.
+**
+** GNU General Public License Usage
+** Alternatively, this file may be used under the terms of the GNU
+** General Public License version 3.0 as published by the Free Software
+** Foundation and appearing in the file LICENSE.GPL included in the
+** packaging of this file.  Please review the following information to
+** ensure the GNU General Public License version 3.0 requirements will be
+** met: http://www.gnu.org/copyleft/gpl.html.
+**
+**
+** $QT_END_LICENSE$
+**
+****************************************************************************/
+
+#ifndef QDECLARATIVECAMERAVIEWFINDER_P_H
+#define QDECLARATIVECAMERAVIEWFINDER_P_H
+
+//
+//  W A R N I N G
+//  -------------
+//
+// This file is not part of the Qt API.  It exists for the convenience
+// of other Qt classes.  This header file may change from version to
+// version without notice, or even be removed.
+//
+// We mean it.
+//
+
+#include <qcamera.h>
+#include <qmediarecorder.h>
+#include <qmediaencodersettings.h>
+
+QT_BEGIN_NAMESPACE
+
+class QDeclarativeCamera;
+class QCameraViewfinderSettingsControl;
+
+class QDeclarativeCameraViewfinder : public QObject
+{
+    Q_OBJECT
+    Q_PROPERTY(QSize resolution READ resolution WRITE setResolution NOTIFY resolutionChanged)
+    Q_PROPERTY(qreal minimumFrameRate READ minimumFrameRate WRITE setMinimumFrameRate NOTIFY minimumFrameRateChanged)
+    Q_PROPERTY(qreal maximumFrameRate READ maximumFrameRate WRITE setMaximumFrameRate NOTIFY maximumFrameRateChanged)
+public:
+    QDeclarativeCameraViewfinder(QCamera *camera, QObject *parent = 0);
+    ~QDeclarativeCameraViewfinder();
+
+    QSize resolution() const;
+    void setResolution(const QSize &resolution);
+
+    qreal minimumFrameRate() const;
+    void setMinimumFrameRate(qreal frameRate);
+
+    qreal maximumFrameRate() const;
+    void setMaximumFrameRate(qreal frameRate);
+
+Q_SIGNALS:
+    void resolutionChanged();
+    void minimumFrameRateChanged();
+    void maximumFrameRateChanged();
+
+private:
+    QCamera *m_camera;
+    QCameraViewfinderSettingsControl *m_control;
+};
+
+QT_END_NAMESPACE
+
+#endif
diff --git a/src/imports/multimedia/qdeclarativemediametadata_p.h b/src/imports/multimedia/qdeclarativemediametadata_p.h
index 1983eff..090528c 100644
--- a/src/imports/multimedia/qdeclarativemediametadata_p.h
+++ b/src/imports/multimedia/qdeclarativemediametadata_p.h
@@ -55,6 +55,8 @@
 
 #include <QtQml/qqml.h>
 #include <QtMultimedia/qmediametadata.h>
+#include <QtMultimedia/qmediaservice.h>
+#include <QtMultimedia/qmetadatawritercontrol.h>
 #include "qmediaobject.h"
 
 QT_BEGIN_NAMESPACE
@@ -62,116 +64,381 @@ QT_BEGIN_NAMESPACE
 class QDeclarativeMediaMetaData : public QObject
 {
     Q_OBJECT
-    Q_PROPERTY(QVariant title READ title NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant subTitle READ subTitle NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant author READ author NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant comment READ comment NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant description READ description NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant category READ category NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant genre READ genre NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant year READ year NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant date READ date NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant userRating READ userRating NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant keywords READ keywords NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant language READ language NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant publisher READ publisher NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant copyright READ copyright NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant parentalRating READ parentalRating NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant ratingOrganization READ ratingOrganization NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant size READ size NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant mediaType READ mediaType NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant duration READ duration NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant audioBitRate READ audioBitRate NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant audioCodec READ audioCodec NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant averageLevel READ averageLevel NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant channelCount READ channelCount NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant peakValue READ peakValue NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant sampleRate READ sampleRate NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant albumTitle READ albumTitle NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant albumArtist READ albumArtist NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant contributingArtist READ contributingArtist NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant composer READ composer NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant conductor READ conductor NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant lyrics READ lyrics NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant mood READ mood NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant trackNumber READ trackNumber NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant trackCount READ trackCount NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant coverArtUrlSmall READ coverArtUrlSmall NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant coverArtUrlLarge READ coverArtUrlLarge NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant resolution READ resolution NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant pixelAspectRatio READ pixelAspectRatio NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant videoFrameRate READ videoFrameRate NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant videoBitRate READ videoBitRate NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant videoCodec READ videoCodec NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant posterUrl READ posterUrl NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant chapterNumber READ chapterNumber NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant director READ director NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant leadPerformer READ leadPerformer NOTIFY metaDataChanged)
-    Q_PROPERTY(QVariant writer READ writer NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant title READ title WRITE setTitle NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant subTitle READ subTitle WRITE setSubTitle NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant author READ author WRITE setAuthor NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant comment READ comment WRITE setComment NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant description READ description WRITE setDescription NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant category READ category WRITE setCategory NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant genre READ genre WRITE setGenre NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant year READ year WRITE setYear NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant date READ date WRITE setDate NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant userRating READ userRating WRITE setUserRating NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant keywords READ keywords WRITE setKeywords NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant language READ language WRITE setLanguage NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant publisher READ publisher WRITE setPublisher NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant copyright READ copyright WRITE setCopyright NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant parentalRating READ parentalRating WRITE setParentalRating NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant ratingOrganization READ ratingOrganization WRITE setRatingOrganization NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant size READ size WRITE setSize NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant mediaType READ mediaType WRITE setMediaType NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant duration READ duration WRITE setDuration NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant audioBitRate READ audioBitRate WRITE setAudioBitRate NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant audioCodec READ audioCodec WRITE setAudioCodec NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant averageLevel READ averageLevel WRITE setAverageLevel NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant channelCount READ channelCount WRITE setChannelCount NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant peakValue READ peakValue WRITE setPeakValue NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant sampleRate READ sampleRate WRITE setSampleRate NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant albumTitle READ albumTitle WRITE setAlbumTitle NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant albumArtist READ albumArtist WRITE setAlbumArtist NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant contributingArtist READ contributingArtist WRITE setContributingArtist NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant composer READ composer WRITE setComposer NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant conductor READ conductor WRITE setConductor NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant lyrics READ lyrics WRITE setLyrics NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant mood READ mood WRITE setMood NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant trackNumber READ trackNumber WRITE setTrackNumber NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant trackCount READ trackCount WRITE setTrackCount NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant coverArtUrlSmall READ coverArtUrlSmall WRITE setCoverArtUrlSmall NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant coverArtUrlLarge READ coverArtUrlLarge WRITE setCoverArtUrlLarge NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant resolution READ resolution WRITE setResolution NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant pixelAspectRatio READ pixelAspectRatio WRITE setPixelAspectRatio NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant videoFrameRate READ videoFrameRate WRITE setVideoFrameRate NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant videoBitRate READ videoBitRate WRITE setVideoBitRate NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant videoCodec READ videoCodec WRITE setVideoCodec NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant posterUrl READ posterUrl WRITE setPosterUrl NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant chapterNumber READ chapterNumber WRITE setChapterNumber NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant director READ director WRITE setDirector NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant leadPerformer READ leadPerformer WRITE setLeadPerformer NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant writer READ writer WRITE setWriter NOTIFY metaDataChanged)
+
+    Q_PROPERTY(QVariant cameraManufacturer READ cameraManufacturer WRITE setCameraManufacturer NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant cameraModel READ cameraModel WRITE setCameraModel NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant event READ event WRITE setEvent NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant subject READ subject WRITE setSubject NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant orientation READ orientation WRITE setOrientation NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant exposureTime READ exposureTime WRITE setExposureTime NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant fNumber READ fNumber WRITE setFNumber NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant exposureProgram READ exposureProgram WRITE setExposureProgram NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant isoSpeedRatings READ isoSpeedRatings WRITE setISOSpeedRatings NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant exposureBiasValue READ exposureBiasValue WRITE setExposureBiasValue NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant dateTimeOriginal READ dateTimeOriginal WRITE setDateTimeOriginal NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant dateTimeDigitized READ dateTimeDigitized WRITE setDateTimeDigitized NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant subjectDistance READ subjectDistance WRITE setSubjectDistance NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant meteringMode READ meteringMode WRITE setMeteringMode NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant lightSource READ lightSource WRITE setLightSource NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant flash READ flash WRITE setFlash NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant focalLength READ focalLength WRITE setFocalLength NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant exposureMode READ exposureMode WRITE setExposureMode NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant whiteBalance READ whiteBalance WRITE setWhiteBalance NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant digitalZoomRatio READ digitalZoomRatio WRITE setDigitalZoomRatio NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant focalLengthIn35mmFilm READ focalLengthIn35mmFilm WRITE setFocalLengthIn35mmFilm NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant sceneCaptureType READ sceneCaptureType WRITE setSceneCaptureType NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant gainControl READ gainControl WRITE setGainControl NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant contrast READ contrast WRITE setContrast NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant saturation READ saturation WRITE setSaturation NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant sharpness READ sharpness WRITE setSharpness NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant deviceSettingDescription READ deviceSettingDescription WRITE setDeviceSettingDescription NOTIFY metaDataChanged)
+
+    Q_PROPERTY(QVariant gpsLatitude READ gpsLatitude WRITE setGPSLatitude NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant gpsLongitude READ gpsLongitude WRITE setGPSLongitude NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant gpsAltitude READ gpsAltitude WRITE setGPSAltitude NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant gpsTimeStamp READ gpsTimeStamp WRITE setGPSTimeStamp NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant gpsSatellites READ gpsSatellites WRITE setGPSSatellites NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant gpsStatus READ gpsStatus WRITE setGPSStatus NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant gpsDOP READ gpsDOP WRITE setGPSDOP NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant gpsSpeed READ gpsSpeed WRITE setGPSSpeed NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant gpsTrack READ gpsTrack WRITE setGPSTrack NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant gpsTrackRef READ gpsTrackRef WRITE setGPSTrackRef NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant gpsImgDirection READ gpsImgDirection WRITE setGPSImgDirection NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant gpsImgDirectionRef READ gpsImgDirectionRef WRITE setGPSImgDirectionRef NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant gpsMapDatum READ gpsMapDatum WRITE setGPSMapDatum NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant gpsProcessingMethod READ gpsProcessingMethod WRITE setGPSProcessingMethod NOTIFY metaDataChanged)
+    Q_PROPERTY(QVariant gpsAreaInformation READ gpsAreaInformation WRITE setGPSAreaInformation NOTIFY metaDataChanged)
+
 public:
     QDeclarativeMediaMetaData(QMediaObject *player, QObject *parent = 0)
         : QObject(parent)
         , m_mediaObject(player)
+        , m_writerControl(0)
+        , m_requestedWriterControl(false)
+    {
+    }
+
+    ~QDeclarativeMediaMetaData()
     {
+        if (m_writerControl) {
+            if (QMediaService *service = m_mediaObject->service())
+                service->releaseControl(m_writerControl);
+        }
     }
 
     QVariant title() const { return m_mediaObject->metaData(QMediaMetaData::Title); }
+    void setTitle(const QVariant &title) { setMetaData(QMediaMetaData::Title, title); }
     QVariant subTitle() const { return m_mediaObject->metaData(QMediaMetaData::SubTitle); }
+    void setSubTitle(const QVariant &title) {
+        setMetaData(QMediaMetaData::SubTitle, title); }
     QVariant author() const { return m_mediaObject->metaData(QMediaMetaData::Author); }
+    void setAuthor(const QVariant &author) { setMetaData(QMediaMetaData::Author, author); }
     QVariant comment() const { return m_mediaObject->metaData(QMediaMetaData::Comment); }
+    void setComment(const QVariant &comment) { setMetaData(QMediaMetaData::Comment, comment); }
     QVariant description() const { return m_mediaObject->metaData(QMediaMetaData::Description); }
+    void setDescription(const QVariant &description) {
+        setMetaData(QMediaMetaData::Description, description); }
     QVariant category() const { return m_mediaObject->metaData(QMediaMetaData::Category); }
+    void setCategory(const QVariant &category) { setMetaData(QMediaMetaData::Category, category); }
     QVariant genre() const { return m_mediaObject->metaData(QMediaMetaData::Genre); }
+    void setGenre(const QVariant &genre) { setMetaData(QMediaMetaData::Genre, genre); }
     QVariant year() const { return m_mediaObject->metaData(QMediaMetaData::Year); }
+    void setYear(const QVariant &year) { setMetaData(QMediaMetaData::Year, year); }
     QVariant date() const { return m_mediaObject->metaData(QMediaMetaData::Date); }
+    void setDate(const QVariant &date) { setMetaData(QMediaMetaData::Date, date); }
     QVariant userRating() const { return m_mediaObject->metaData(QMediaMetaData::UserRating); }
+    void setUserRating(const QVariant &rating) { setMetaData(QMediaMetaData::UserRating, rating); }
     QVariant keywords() const { return m_mediaObject->metaData(QMediaMetaData::Keywords); }
+    void setKeywords(const QVariant &keywords) { setMetaData(QMediaMetaData::Keywords, keywords); }
     QVariant language() const { return m_mediaObject->metaData(QMediaMetaData::Language); }
+    void setLanguage(const QVariant &language) { setMetaData(QMediaMetaData::Language, language); }
     QVariant publisher() const { return m_mediaObject->metaData(QMediaMetaData::Publisher); }
+    void setPublisher(const QVariant &publisher) {
+        setMetaData(QMediaMetaData::Publisher, publisher); }
     QVariant copyright() const { return m_mediaObject->metaData(QMediaMetaData::Copyright); }
+    void setCopyright(const QVariant &copyright) {
+        setMetaData(QMediaMetaData::Copyright, copyright); }
     QVariant parentalRating() const { return m_mediaObject->metaData(QMediaMetaData::ParentalRating); }
+    void setParentalRating(const QVariant &rating) {
+        setMetaData(QMediaMetaData::ParentalRating, rating); }
     QVariant ratingOrganization() const {
         return m_mediaObject->metaData(QMediaMetaData::RatingOrganization); }
+    void setRatingOrganization(const QVariant &organization) {
+        setMetaData(QMediaMetaData::RatingOrganization, organization); }
     QVariant size() const { return m_mediaObject->metaData(QMediaMetaData::Size); }
+    void setSize(const QVariant &size) { setMetaData(QMediaMetaData::Size, size); }
     QVariant mediaType() const { return m_mediaObject->metaData(QMediaMetaData::MediaType); }
+    void setMediaType(const QVariant &type) { setMetaData(QMediaMetaData::MediaType, type); }
     QVariant duration() const { return m_mediaObject->metaData(QMediaMetaData::Duration); }
+    void setDuration(const QVariant &duration) { setMetaData(QMediaMetaData::Duration, duration); }
     QVariant audioBitRate() const { return m_mediaObject->metaData(QMediaMetaData::AudioBitRate); }
+    void setAudioBitRate(const QVariant &rate) { setMetaData(QMediaMetaData::AudioBitRate, rate); }
     QVariant audioCodec() const { return m_mediaObject->metaData(QMediaMetaData::AudioCodec); }
+    void setAudioCodec(const QVariant &codec) { setMetaData(QMediaMetaData::AudioCodec, codec); }
     QVariant averageLevel() const { return m_mediaObject->metaData(QMediaMetaData::AverageLevel); }
+    void setAverageLevel(const QVariant &level) {
+        setMetaData(QMediaMetaData::AverageLevel, level); }
     QVariant channelCount() const { return m_mediaObject->metaData(QMediaMetaData::ChannelCount); }
+    void setChannelCount(const QVariant &count) {
+        setMetaData(QMediaMetaData::ChannelCount, count); }
     QVariant peakValue() const { return m_mediaObject->metaData(QMediaMetaData::PeakValue); }
+    void setPeakValue(const QVariant &value) { setMetaData(QMediaMetaData::PeakValue, value); }
     QVariant sampleRate() const { return m_mediaObject->metaData(QMediaMetaData::SampleRate); }
+    void setSampleRate(const QVariant &rate) { setMetaData(QMediaMetaData::SampleRate, rate); }
     QVariant albumTitle() const { return m_mediaObject->metaData(QMediaMetaData::AlbumTitle); }
+    void setAlbumTitle(const QVariant &title) { setMetaData(QMediaMetaData::AlbumTitle, title); }
     QVariant albumArtist() const { return m_mediaObject->metaData(QMediaMetaData::AlbumArtist); }
+    void setAlbumArtist(const QVariant &artist) {
+        setMetaData(QMediaMetaData::AlbumArtist, artist); }
     QVariant contributingArtist() const {
         return m_mediaObject->metaData(QMediaMetaData::ContributingArtist); }
+    void setContributingArtist(const QVariant &artist) {
+        setMetaData(QMediaMetaData::ContributingArtist, artist); }
     QVariant composer() const { return m_mediaObject->metaData(QMediaMetaData::Composer); }
+    void setComposer(const QVariant &composer) { setMetaData(QMediaMetaData::Composer, composer); }
     QVariant conductor() const { return m_mediaObject->metaData(QMediaMetaData::Conductor); }
+    void setConductor(const QVariant &conductor) {
+        setMetaData(QMediaMetaData::Conductor, conductor); }
     QVariant lyrics() const { return m_mediaObject->metaData(QMediaMetaData::Lyrics); }
+    void setLyrics(const QVariant &lyrics) { setMetaData(QMediaMetaData::Lyrics, lyrics); }
     QVariant mood() const { return m_mediaObject->metaData(QMediaMetaData::Mood); }
+    void setMood(const QVariant &mood) { setMetaData(QMediaMetaData::Mood, mood); }
     QVariant trackNumber() const { return m_mediaObject->metaData(QMediaMetaData::TrackNumber); }
+    void setTrackNumber(const QVariant &track) { setMetaData(QMediaMetaData::TrackNumber, track); }
     QVariant trackCount() const { return m_mediaObject->metaData(QMediaMetaData::TrackCount); }
+    void setTrackCount(const QVariant &count) { setMetaData(QMediaMetaData::TrackCount, count); }
     QVariant coverArtUrlSmall() const {
         return m_mediaObject->metaData(QMediaMetaData::CoverArtUrlSmall); }
+    void setCoverArtUrlSmall(const QVariant &url) {
+        setMetaData(QMediaMetaData::CoverArtUrlSmall, url); }
     QVariant coverArtUrlLarge() const {
         return m_mediaObject->metaData(QMediaMetaData::CoverArtUrlLarge); }
+    void setCoverArtUrlLarge(const QVariant &url) {
+        setMetaData(QMediaMetaData::CoverArtUrlLarge, url); }
     QVariant resolution() const { return m_mediaObject->metaData(QMediaMetaData::Resolution); }
+    void setResolution(const QVariant &resolution) {
+        setMetaData(QMediaMetaData::Resolution, resolution); }
     QVariant pixelAspectRatio() const {
         return m_mediaObject->metaData(QMediaMetaData::PixelAspectRatio); }
+    void setPixelAspectRatio(const QVariant &ratio) {
+        setMetaData(QMediaMetaData::PixelAspectRatio, ratio); }
     QVariant videoFrameRate() const { return m_mediaObject->metaData(QMediaMetaData::VideoFrameRate); }
+    void setVideoFrameRate(const QVariant &rate) {
+        setMetaData(QMediaMetaData::VideoFrameRate, rate); }
     QVariant videoBitRate() const { return m_mediaObject->metaData(QMediaMetaData::VideoBitRate); }
+    void setVideoBitRate(const QVariant &rate) {
+        setMetaData(QMediaMetaData::VideoBitRate, rate); }
     QVariant videoCodec() const { return m_mediaObject->metaData(QMediaMetaData::VideoCodec); }
+    void setVideoCodec(const QVariant &codec) {
+        setMetaData(QMediaMetaData::VideoCodec, codec); }
     QVariant posterUrl() const { return m_mediaObject->metaData(QMediaMetaData::PosterUrl); }
+    void setPosterUrl(const QVariant &url) {
+        setMetaData(QMediaMetaData::PosterUrl, url); }
     QVariant chapterNumber() const { return m_mediaObject->metaData(QMediaMetaData::ChapterNumber); }
+    void setChapterNumber(const QVariant &chapter) {
+        setMetaData(QMediaMetaData::ChapterNumber, chapter); }
     QVariant director() const { return m_mediaObject->metaData(QMediaMetaData::Director); }
+    void setDirector(const QVariant &director) { setMetaData(QMediaMetaData::Director, director); }
     QVariant leadPerformer() const { return m_mediaObject->metaData(QMediaMetaData::LeadPerformer); }
+    void setLeadPerformer(const QVariant &performer) {
+        setMetaData(QMediaMetaData::LeadPerformer, performer); }
     QVariant writer() const { return m_mediaObject->metaData(QMediaMetaData::Writer); }
+    void setWriter(const QVariant &writer) { setMetaData(QMediaMetaData::Writer, writer); }
+
+    QVariant cameraManufacturer() const {
+        return m_mediaObject->metaData(QMediaMetaData::CameraManufacturer); }
+    void setCameraManufacturer(const QVariant &manufacturer) {
+        setMetaData(QMediaMetaData::CameraManufacturer, manufacturer); }
+    QVariant cameraModel() const { return m_mediaObject->metaData(QMediaMetaData::CameraModel); }
+    void setCameraModel(const QVariant &model) { setMetaData(QMediaMetaData::CameraModel, model); }
+    QVariant event() const { return m_mediaObject->metaData(QMediaMetaData::Event); }
+    void setEvent(const QVariant &event) { setMetaData(QMediaMetaData::Event, event); }
+    QVariant subject() const { return m_mediaObject->metaData(QMediaMetaData::Subject); }
+    void setSubject(const QVariant &subject) { setMetaData(QMediaMetaData::Subject, subject); }
+    QVariant orientation() const { return m_mediaObject->metaData(QMediaMetaData::Orientation); }
+    void setOrientation(const QVariant &orientation) {
+        setMetaData(QMediaMetaData::Orientation, orientation); }
+    QVariant exposureTime() const { return m_mediaObject->metaData(QMediaMetaData::ExposureTime); }
+    void setExposureTime(const QVariant &time) { setMetaData(QMediaMetaData::ExposureTime, time); }
+    QVariant fNumber() const { return m_mediaObject->metaData(QMediaMetaData::FNumber); }
+    void setFNumber(const QVariant &number) { setMetaData(QMediaMetaData::FNumber, number); }
+    QVariant exposureProgram() const {
+        return m_mediaObject->metaData(QMediaMetaData::ExposureProgram); }
+    void setExposureProgram(const QVariant &program) {
+        setMetaData(QMediaMetaData::ExposureProgram, program); }
+    QVariant isoSpeedRatings() const {
+        return m_mediaObject->metaData(QMediaMetaData::ISOSpeedRatings); }
+    void setISOSpeedRatings(const QVariant &ratings) {
+        setMetaData(QMediaMetaData::ISOSpeedRatings, ratings); }
+    QVariant exposureBiasValue() const {
+        return m_mediaObject->metaData(QMediaMetaData::ExposureBiasValue); }
+    void setExposureBiasValue(const QVariant &bias) {
+        setMetaData(QMediaMetaData::ExposureBiasValue, bias); }
+    QVariant dateTimeOriginal() const {
+        return m_mediaObject->metaData(QMediaMetaData::DateTimeOriginal); }
+    void setDateTimeOriginal(const QVariant &dateTime) {
+        setMetaData(QMediaMetaData::DateTimeOriginal, dateTime); }
+    QVariant dateTimeDigitized() const {
+        return m_mediaObject->metaData(QMediaMetaData::DateTimeDigitized); }
+    void setDateTimeDigitized(const QVariant &dateTime) {
+        setMetaData(QMediaMetaData::DateTimeDigitized, dateTime); }
+    QVariant subjectDistance() const {
+        return m_mediaObject->metaData(QMediaMetaData::SubjectDistance); }
+    void setSubjectDistance(const QVariant &distance) {
+        setMetaData(QMediaMetaData::SubjectDistance, distance); }
+    QVariant meteringMode() const { return m_mediaObject->metaData(QMediaMetaData::MeteringMode); }
+    void setMeteringMode(const QVariant &mode) { setMetaData(QMediaMetaData::MeteringMode, mode); }
+    QVariant lightSource() const { return m_mediaObject->metaData(QMediaMetaData::LightSource); }
+    void setLightSource(const QVariant &source) {
+        setMetaData(QMediaMetaData::LightSource, source); }
+    QVariant flash() const { return m_mediaObject->metaData(QMediaMetaData::Flash); }
+    void setFlash(const QVariant &flash) { setMetaData(QMediaMetaData::Flash, flash); }
+    QVariant focalLength() const { return m_mediaObject->metaData(QMediaMetaData::FocalLength); }
+    void setFocalLength(const QVariant &length) {
+        setMetaData(QMediaMetaData::FocalLength, length); }
+    QVariant exposureMode() const { return m_mediaObject->metaData(QMediaMetaData::ExposureMode); }
+    void setExposureMode(const QVariant &mode) {
+        setMetaData(QMediaMetaData::ExposureMode, mode); }
+    QVariant whiteBalance() const { return m_mediaObject->metaData(QMediaMetaData::WhiteBalance); }
+    void setWhiteBalance(const QVariant &balance) {
+        setMetaData(QMediaMetaData::WhiteBalance, balance); }
+    QVariant digitalZoomRatio() const {
+        return m_mediaObject->metaData(QMediaMetaData::DigitalZoomRatio); }
+    void setDigitalZoomRatio(const QVariant &ratio) {
+        setMetaData(QMediaMetaData::DigitalZoomRatio, ratio); }
+    QVariant focalLengthIn35mmFilm() const {
+        return m_mediaObject->metaData(QMediaMetaData::FocalLengthIn35mmFilm); }
+    void setFocalLengthIn35mmFilm(const QVariant &length) {
+        setMetaData(QMediaMetaData::FocalLengthIn35mmFilm, length); }
+    QVariant sceneCaptureType() const {
+        return m_mediaObject->metaData(QMediaMetaData::SceneCaptureType); }
+    void setSceneCaptureType(const QVariant &type) {
+        setMetaData(QMediaMetaData::SceneCaptureType, type); }
+    QVariant gainControl() const { return m_mediaObject->metaData(QMediaMetaData::GainControl); }
+    void setGainControl(const QVariant &gain) { setMetaData(QMediaMetaData::GainControl, gain); }
+    QVariant contrast() const { return m_mediaObject->metaData(QMediaMetaData::Contrast); }
+    void setContrast(const QVariant &contrast) { setMetaData(QMediaMetaData::Contrast, contrast); }
+    QVariant saturation() const { return m_mediaObject->metaData(QMediaMetaData::Saturation); }
+    void setSaturation(const QVariant &saturation) {
+        setMetaData(QMediaMetaData::Saturation, saturation); }
+    QVariant sharpness() const { return m_mediaObject->metaData(QMediaMetaData::Sharpness); }
+    void setSharpness(const QVariant &sharpness) {
+        setMetaData(QMediaMetaData::Sharpness, sharpness); }
+    QVariant deviceSettingDescription() const {
+        return m_mediaObject->metaData(QMediaMetaData::DeviceSettingDescription); }
+    void setDeviceSettingDescription(const QVariant &description) {
+        setMetaData(QMediaMetaData::DeviceSettingDescription, description); }
+
+    QVariant gpsLatitude() const { return m_mediaObject->metaData(QMediaMetaData::GPSLatitude); }
+    void setGPSLatitude(const QVariant &latitude) {
+        setMetaData(QMediaMetaData::GPSLatitude, latitude); }
+    QVariant gpsLongitude() const { return m_mediaObject->metaData(QMediaMetaData::GPSLongitude); }
+    void setGPSLongitude(const QVariant &longitude) {
+        setMetaData(QMediaMetaData::GPSLongitude, longitude); }
+    QVariant gpsAltitude() const { return m_mediaObject->metaData(QMediaMetaData::GPSAltitude); }
+    void setGPSAltitude(const QVariant &altitude) {
+        setMetaData(QMediaMetaData::GPSAltitude, altitude); }
+    QVariant gpsTimeStamp() const { return m_mediaObject->metaData(QMediaMetaData::GPSTimeStamp); }
+    void setGPSTimeStamp(const QVariant &timestamp) {
+        setMetaData(QMediaMetaData::GPSTimeStamp, timestamp); }
+    QVariant gpsSatellites() const {
+        return m_mediaObject->metaData(QMediaMetaData::GPSSatellites); }
+    void setGPSSatellites(const QVariant &satellites) {
+        setMetaData(QMediaMetaData::GPSSatellites, satellites); }
+    QVariant gpsStatus() const { return m_mediaObject->metaData(QMediaMetaData::GPSStatus); }
+    void setGPSStatus(const QVariant &status) { setMetaData(QMediaMetaData::GPSStatus, status); }
+    QVariant gpsDOP() const { return m_mediaObject->metaData(QMediaMetaData::GPSDOP); }
+    void setGPSDOP(const QVariant &dop) { setMetaData(QMediaMetaData::GPSDOP, dop); }
+    QVariant gpsSpeed() const { return m_mediaObject->metaData(QMediaMetaData::GPSSpeed); }
+    void setGPSSpeed(const QVariant &speed) { setMetaData(QMediaMetaData::GPSSpeed, speed); }
+    QVariant gpsTrack() const { return m_mediaObject->metaData(QMediaMetaData::GPSTrack); }
+    void setGPSTrack(const QVariant &track) { setMetaData(QMediaMetaData::GPSTrack, track); }
+    QVariant gpsTrackRef() const { return m_mediaObject->metaData(QMediaMetaData::GPSTrackRef); }
+    void setGPSTrackRef(const QVariant &ref) { setMetaData(QMediaMetaData::GPSTrackRef, ref); }
+    QVariant gpsImgDirection() const {
+        return m_mediaObject->metaData(QMediaMetaData::GPSImgDirection); }
+    void setGPSImgDirection(const QVariant &direction) {
+        setMetaData(QMediaMetaData::GPSImgDirection, direction); }
+    QVariant gpsImgDirectionRef() const {
+        return m_mediaObject->metaData(QMediaMetaData::GPSImgDirectionRef); }
+    void setGPSImgDirectionRef(const QVariant &ref) {
+        setMetaData(QMediaMetaData::GPSImgDirectionRef, ref); }
+    QVariant gpsMapDatum() const { return m_mediaObject->metaData(QMediaMetaData::GPSMapDatum); }
+    void setGPSMapDatum(const QVariant &datum) {
+        setMetaData(QMediaMetaData::GPSMapDatum, datum); }
+    QVariant gpsProcessingMethod() const {
+        return m_mediaObject->metaData(QMediaMetaData::GPSProcessingMethod); }
+    void setGPSProcessingMethod(const QVariant &method) {
+        setMetaData(QMediaMetaData::GPSProcessingMethod, method); }
+    QVariant gpsAreaInformation() const {
+        return m_mediaObject->metaData(QMediaMetaData::GPSAreaInformation); }
+    void setGPSAreaInformation(const QVariant &information) {
+        setMetaData(QMediaMetaData::GPSAreaInformation, information); }
 
 Q_SIGNALS:
     void metaDataChanged();
 
 private:
+    void setMetaData(const QString &key, const QVariant &value)
+    {
+        if (!m_requestedWriterControl) {
+            m_requestedWriterControl = true;
+            if (QMediaService *service = m_mediaObject->service())
+                m_writerControl = service->requestControl<QMetaDataWriterControl *>();
+        }
+        if (m_writerControl)
+            m_writerControl->setMetaData(key, value);
+    }
+
     QMediaObject *m_mediaObject;
+    QMetaDataWriterControl *m_writerControl;
+    bool m_requestedWriterControl;
 };
 
 QT_END_NAMESPACE
diff --git a/src/multimedia/doc/qtmultimedia.qdocconf b/src/multimedia/doc/qtmultimedia.qdocconf
index d6ff682..d917062 100644
--- a/src/multimedia/doc/qtmultimedia.qdocconf
+++ b/src/multimedia/doc/qtmultimedia.qdocconf
@@ -2,7 +2,6 @@ include($QT_INSTALL_DOCS/global/qt-module-defaults.qdocconf)
 
 project                 = QtMultimedia
 description             = Qt Multimedia Documentation
-url                     = http://qt-project.org/doc/qt-$QT_VER
 version                 = $QT_VERSION
 
 # The following parameters are for creating a qhp file, the qhelpgenerator
@@ -26,7 +25,7 @@ qhp.QtMultimedia.subprojects.classes.selectors = class fake:headerfile
 qhp.QtMultimedia.subprojects.classes.sortPages = true
 qhp.QtMultimedia.subprojects.qmltypes.title = QML Types
 qhp.QtMultimedia.subprojects.qmltypes.indexTitle = Qt Multimedia QML Types
-qhp.QtMultimedia.subprojects.qmltypes.selectors = fake:qmlclass
+qhp.QtMultimedia.subprojects.qmltypes.selectors = qmlclass
 qhp.QtMultimedia.subprojects.qmltypes.sortPages = true
 
 exampledirs += ../../../examples/multimedia \
diff --git a/src/multimedia/doc/src/multimediabackend.qdoc b/src/multimedia/doc/src/multimediabackend.qdoc
index 68159d3..ff35090 100644
--- a/src/multimedia/doc/src/multimediabackend.qdoc
+++ b/src/multimedia/doc/src/multimediabackend.qdoc
@@ -71,7 +71,7 @@ classes derived from them.
 
 Consider a developer creating, for example, a media player class called MyPlayer.
 It may have special requirements beyond ordinary media players and so may
-need a custom service and a custom control. We can subclass \l QMediaServiceProvider
+need a custom service and a custom control. We can subclass QMediaServiceProvider
 to create our MyServiceProvider class. Also we will create a
 MyMediaService, and the MyMediaControl to manipulate the media service.
 
diff --git a/src/multimedia/doc/src/qtmultimedia-cpp.qdoc b/src/multimedia/doc/src/qtmultimedia-cpp.qdoc
index b67163e..06f9e77 100644
--- a/src/multimedia/doc/src/qtmultimedia-cpp.qdoc
+++ b/src/multimedia/doc/src/qtmultimedia-cpp.qdoc
@@ -38,5 +38,5 @@
     QML alternatives. If your application is serving complex use cases such as
     decoding media files, accessing video or audio buffers, use the C++
     alternative. For more details about the complex audio, video, and camera use
-    cases supported by the C++ classes, refer to \l {Qt Multimedia Overview}.
+    cases supported by the C++ classes, refer to \l {Multimedia}{Multimedia Overview}.
 */
diff --git a/src/multimedia/gsttools_headers/qgstappsrc_p.h b/src/multimedia/gsttools_headers/qgstappsrc_p.h
index bfb038e..a188e18 100644
--- a/src/multimedia/gsttools_headers/qgstappsrc_p.h
+++ b/src/multimedia/gsttools_headers/qgstappsrc_p.h
@@ -47,7 +47,10 @@
 
 #include <gst/gst.h>
 #include <gst/app/gstappsrc.h>
+
+#if GST_VERSION_MAJOR < 1
 #include <gst/app/gstappbuffer.h>
+#endif
 
 QT_BEGIN_NAMESPACE
 
diff --git a/src/multimedia/gsttools_headers/qgstreameraudioprobecontrol_p.h b/src/multimedia/gsttools_headers/qgstreameraudioprobecontrol_p.h
index 71ea2ff..be31f86 100644
--- a/src/multimedia/gsttools_headers/qgstreameraudioprobecontrol_p.h
+++ b/src/multimedia/gsttools_headers/qgstreameraudioprobecontrol_p.h
@@ -46,23 +46,32 @@
 #include <qmediaaudioprobecontrol.h>
 #include <QtCore/qmutex.h>
 #include <qaudiobuffer.h>
+#include <qshareddata.h>
+
+#include <private/qgstreamerbufferprobe_p.h>
 
 QT_BEGIN_NAMESPACE
 
-class QGstreamerAudioProbeControl : public QMediaAudioProbeControl
+class QGstreamerAudioProbeControl
+    : public QMediaAudioProbeControl
+    , public QGstreamerBufferProbe
+    , public QSharedData
 {
     Q_OBJECT
 public:
     explicit QGstreamerAudioProbeControl(QObject *parent);
     virtual ~QGstreamerAudioProbeControl();
 
-    void bufferProbed(GstBuffer* buffer);
+protected:
+    void probeCaps(GstCaps *caps);
+    bool probeBuffer(GstBuffer *buffer);
 
 private slots:
     void bufferProbed();
 
 private:
     QAudioBuffer m_pendingBuffer;
+    QAudioFormat m_format;
     QMutex m_bufferMutex;
 };
 
diff --git a/src/multimedia/gsttools_headers/qgstreamerbufferprobe_p.h b/src/multimedia/gsttools_headers/qgstreamerbufferprobe_p.h
new file mode 100644
index 0000000..9240742
--- /dev/null
+++ b/src/multimedia/gsttools_headers/qgstreamerbufferprobe_p.h
@@ -0,0 +1,86 @@
+/****************************************************************************
+**
+** Copyright (C) 2014 Jolla Ltd.
+** Contact: http://www.qt-project.org/legal
+**
+** This file is part of the Qt Toolkit.
+**
+** $QT_BEGIN_LICENSE:LGPL$
+** Commercial License Usage
+** Licensees holding valid commercial Qt licenses may use this file in
+** accordance with the commercial license agreement provided with the
+** Software or, alternatively, in accordance with the terms contained in
+** a written agreement between you and Digia.  For licensing terms and
+** conditions see http://qt.digia.com/licensing.  For further information
+** use the contact form at http://qt.digia.com/contact-us.
+**
+** GNU Lesser General Public License Usage
+** Alternatively, this file may be used under the terms of the GNU Lesser
+** General Public License version 2.1 as published by the Free Software
+** Foundation and appearing in the file LICENSE.LGPL included in the
+** packaging of this file.  Please review the following information to
+** ensure the GNU Lesser General Public License version 2.1 requirements
+** will be met: http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html.
+**
+** In addition, as a special exception, Digia gives you certain additional
+** rights.  These rights are described in the Digia Qt LGPL Exception
+** version 1.1, included in the file LGPL_EXCEPTION.txt in this package.
+**
+** GNU General Public License Usage
+** Alternatively, this file may be used under the terms of the GNU
+** General Public License version 3.0 as published by the Free Software
+** Foundation and appearing in the file LICENSE.GPL included in the
+** packaging of this file.  Please review the following information to
+** ensure the GNU General Public License version 3.0 requirements will be
+** met: http://www.gnu.org/copyleft/gpl.html.
+**
+**
+** $QT_END_LICENSE$
+**
+****************************************************************************/
+
+#ifndef QGSTREAMERBUFFERPROBE_H
+#define QGSTREAMERBUFFERPROBE_H
+
+#include <gst/gst.h>
+
+#include <QtCore/qglobal.h>
+
+QT_BEGIN_NAMESPACE
+
+class QGstreamerBufferProbe
+{
+public:
+    enum Flags
+    {
+        ProbeCaps       = 0x01,
+        ProbeBuffers    = 0x02,
+        ProbeAll    = ProbeCaps | ProbeBuffers
+    };
+
+    explicit QGstreamerBufferProbe(Flags flags = ProbeAll);
+    virtual ~QGstreamerBufferProbe();
+
+    void addProbeToPad(GstPad *pad, bool downstream = true);
+    void removeProbeFromPad(GstPad *pad);
+
+protected:
+    virtual void probeCaps(GstCaps *caps);
+    virtual bool probeBuffer(GstBuffer *buffer);
+
+private:
+#if GST_CHECK_VERSION(1,0,0)
+    static GstPadProbeReturn capsProbe(GstPad *pad, GstPadProbeInfo *info, gpointer user_data);
+    static GstPadProbeReturn bufferProbe(GstPad *pad, GstPadProbeInfo *info, gpointer user_data);
+    int m_capsProbeId;
+#else
+    static gboolean bufferProbe(GstElement *element, GstBuffer *buffer, gpointer user_data);
+    GstCaps *m_caps;
+#endif
+    int m_bufferProbeId;
+    const Flags m_flags;
+};
+
+QT_END_NAMESPACE
+
+#endif // QGSTREAMERAUDIOPROBECONTROL_H
diff --git a/src/multimedia/gsttools_headers/qgstreamermirtexturerenderer_p.h b/src/multimedia/gsttools_headers/qgstreamermirtexturerenderer_p.h
new file mode 100644
index 0000000..86b7ac1
--- /dev/null
+++ b/src/multimedia/gsttools_headers/qgstreamermirtexturerenderer_p.h
@@ -0,0 +1,111 @@
+/****************************************************************************
+**
+** Copyright (C) 2013 Canonical Ltd
+** Contact: jim.hodapp@canonical.com
+**
+** This file is part of the Qt Toolkit.
+**
+// TODO: Fix this license
+** $QT_BEGIN_LICENSE:LGPL$
+** Commercial License Usage
+** Licensees holding valid commercial Qt licenses may use this file in
+** accordance with the commercial license agreement provided with the
+** Software or, alternatively, in accordance with the terms contained in
+** a written agreement between you and Digia.  For licensing terms and
+** conditions see http://qt.digia.com/licensing.  For further information
+** use the contact form at http://qt.digia.com/contact-us.
+**
+** GNU Lesser General Public License Usage
+** Alternatively, this file may be used under the terms of the GNU Lesser
+** General Public License version 2.1 as published by the Free Software
+** Foundation and appearing in the file LICENSE.LGPL included in the
+** packaging of this file.  Please review the following information to
+** ensure the GNU Lesser General Public License version 2.1 requirements
+** will be met: http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html.
+**
+** In addition, as a special exception, Digia gives you certain additional
+** rights.  These rights are described in the Digia Qt LGPL Exception
+** version 1.1, included in the file LGPL_EXCEPTION.txt in this package.
+**
+** GNU General Public License Usage
+** Alternatively, this file may be used under the terms of the GNU
+** General Public License version 3.0 as published by the Free Software
+** Foundation and appearing in the file LICENSE.GPL included in the
+** packaging of this file.  Please review the following information to
+** ensure the GNU General Public License version 3.0 requirements will be
+** met: http://www.gnu.org/copyleft/gpl.html.
+**
+**
+** $QT_END_LICENSE$
+**
+****************************************************************************/
+
+#ifndef QGSTREAMERMIRTEXTURERENDERER_H
+#define QGSTREAMERMIRTEXTURERENDERER_H
+
+#include <qmediaplayer.h>
+#include <qvideorenderercontrol.h>
+#include <private/qvideosurfacegstsink_p.h>
+#include <qabstractvideosurface.h>
+
+#include "qgstreamervideorendererinterface_p.h"
+
+QT_BEGIN_NAMESPACE
+
+class QGstreamerMirTextureBuffer;
+class QGstreamerPlayerSession;
+class QGLContext;
+class QOpenGLContext;
+class QSurfaceFormat;
+
+class QGstreamerMirTextureRenderer : public QVideoRendererControl, public QGstreamerVideoRendererInterface
+{
+    Q_OBJECT
+    Q_INTERFACES(QGstreamerVideoRendererInterface)
+public:
+    QGstreamerMirTextureRenderer(QObject *parent = 0, const QGstreamerPlayerSession *playerSession = 0);
+    virtual ~QGstreamerMirTextureRenderer();
+
+    QAbstractVideoSurface *surface() const;
+    void setSurface(QAbstractVideoSurface *surface);
+
+    void setPlayerSession(const QGstreamerPlayerSession *playerSession);
+
+    GstElement *videoSink();
+
+    void stopRenderer();
+    bool isReady() const { return m_surface != 0; }
+
+signals:
+    void sinkChanged();
+    void readyChanged(bool);
+    void nativeSizeChanged();
+
+private slots:
+    void handleFormatChange();
+    void updateNativeVideoSize();
+    void handleFocusWindowChanged(QWindow *window);
+    void renderFrame();
+
+private:
+    QWindow *createOffscreenWindow(const QSurfaceFormat &format);
+    static void handleFrameReady(gpointer userData);
+    static GstPadProbeReturn padBufferProbe(GstPad *pad, GstPadProbeInfo *info, gpointer userData);
+
+    GstElement *m_videoSink;
+    QPointer<QAbstractVideoSurface> m_surface;
+    QPointer<QAbstractVideoSurface> m_glSurface;
+    QGLContext *m_context;
+    QOpenGLContext *m_glContext;
+    unsigned int m_textureId;
+    QWindow *m_offscreenSurface;
+    QGstreamerPlayerSession *m_playerSession;
+    QGstreamerMirTextureBuffer *m_textureBuffer;
+    QSize m_nativeSize;
+
+    QMutex m_mutex;
+};
+
+QT_END_NAMESPACE
+
+#endif // QGSTREAMERMIRTEXTURERENDRER_H
diff --git a/src/multimedia/gsttools_headers/qgstreamervideoinputdevicecontrol_p.h b/src/multimedia/gsttools_headers/qgstreamervideoinputdevicecontrol_p.h
index eeb576e..c4fe83f 100644
--- a/src/multimedia/gsttools_headers/qgstreamervideoinputdevicecontrol_p.h
+++ b/src/multimedia/gsttools_headers/qgstreamervideoinputdevicecontrol_p.h
@@ -46,6 +46,7 @@
 #include <QtCore/qstringlist.h>
 
 #include <gst/gst.h>
+#include <qcamera.h>
 
 QT_BEGIN_NAMESPACE
 
@@ -54,7 +55,7 @@ class QGstreamerVideoInputDeviceControl : public QVideoDeviceSelectorControl
 Q_OBJECT
 public:
     QGstreamerVideoInputDeviceControl(QObject *parent);
-    QGstreamerVideoInputDeviceControl(GstElement *source, QObject *parent);
+    QGstreamerVideoInputDeviceControl(GstElementFactory *factory, QObject *parent);
     ~QGstreamerVideoInputDeviceControl();
 
     int deviceCount() const;
@@ -65,17 +66,16 @@ public:
     int defaultDevice() const;
     int selectedDevice() const;
 
+    static QString primaryCamera() { return tr("Main camera"); }
+    static QString secondaryCamera() { return tr("Front camera"); }
+
 public Q_SLOTS:
     void setSelectedDevice(int index);
 
 private:
-    void update();
-
-    GstElement *m_source;
+    GstElementFactory *m_factory;
 
     int m_selectedDevice;
-    QStringList m_names;
-    QStringList m_descriptions;
 };
 
 QT_END_NAMESPACE
diff --git a/src/multimedia/gsttools_headers/qgstreamervideoprobecontrol_p.h b/src/multimedia/gsttools_headers/qgstreamervideoprobecontrol_p.h
index c512b48..dca0981 100644
--- a/src/multimedia/gsttools_headers/qgstreamervideoprobecontrol_p.h
+++ b/src/multimedia/gsttools_headers/qgstreamervideoprobecontrol_p.h
@@ -43,20 +43,29 @@
 #define QGSTREAMERVIDEOPROBECONTROL_H
 
 #include <gst/gst.h>
+#include <gst/video/video.h>
 #include <qmediavideoprobecontrol.h>
 #include <QtCore/qmutex.h>
 #include <qvideoframe.h>
+#include <qvideosurfaceformat.h>
+
+#include <private/qgstreamerbufferprobe_p.h>
 
 QT_BEGIN_NAMESPACE
 
-class QGstreamerVideoProbeControl : public QMediaVideoProbeControl
+class QGstreamerVideoProbeControl
+    : public QMediaVideoProbeControl
+    , public QGstreamerBufferProbe
+    , public QSharedData
 {
     Q_OBJECT
 public:
     explicit QGstreamerVideoProbeControl(QObject *parent);
     virtual ~QGstreamerVideoProbeControl();
 
-    void bufferProbed(GstBuffer* buffer);
+    void probeCaps(GstCaps *caps);
+    bool probeBuffer(GstBuffer *buffer);
+
     void startFlushing();
     void stopFlushing();
 
@@ -64,10 +73,16 @@ private slots:
     void frameProbed();
 
 private:
-    bool m_flushing;
-    bool m_frameProbed; // true if at least one frame was probed
+    QVideoSurfaceFormat m_format;
     QVideoFrame m_pendingFrame;
     QMutex m_frameMutex;
+#if GST_CHECK_VERSION(1,0,0)
+    GstVideoInfo m_videoInfo;
+#else
+    int m_bytesPerLine;
+#endif
+    bool m_flushing;
+    bool m_frameProbed; // true if at least one frame was probed
 };
 
 QT_END_NAMESPACE
diff --git a/src/multimedia/gsttools_headers/qgstreamervideowindow_p.h b/src/multimedia/gsttools_headers/qgstreamervideowindow_p.h
index 45582d6..70d4f36 100644
--- a/src/multimedia/gsttools_headers/qgstreamervideowindow_p.h
+++ b/src/multimedia/gsttools_headers/qgstreamervideowindow_p.h
@@ -46,6 +46,7 @@
 
 #include "qgstreamervideorendererinterface_p.h"
 #include <private/qgstreamerbushelper_p.h>
+#include <private/qgstreamerbufferprobe_p.h>
 #include <QtGui/qcolor.h>
 
 QT_BEGIN_NAMESPACE
@@ -53,7 +54,8 @@ class QAbstractVideoSurface;
 
 class QGstreamerVideoWindow : public QVideoWindowControl,
         public QGstreamerVideoRendererInterface,
-        public QGstreamerSyncMessageFilter
+        public QGstreamerSyncMessageFilter,
+        private QGstreamerBufferProbe
 {
     Q_OBJECT
     Q_INTERFACES(QGstreamerVideoRendererInterface QGstreamerSyncMessageFilter)
@@ -109,10 +111,10 @@ signals:
     void readyChanged(bool);
 
 private slots:
-    void updateNativeVideoSize();
+    void updateNativeVideoSize(const QSize &size);
 
 private:
-    static void padBufferProbe(GstPad *pad, GstBuffer *buffer, gpointer user_data);
+    void probeCaps(GstCaps *caps);
 
     GstElement *m_videoSink;
     WId m_windowId;
@@ -121,7 +123,6 @@ private:
     bool m_fullScreen;
     QSize m_nativeSize;
     mutable QColor m_colorKey;
-    int m_bufferProbeId;
 };
 
 QT_END_NAMESPACE
diff --git a/src/multimedia/gsttools_headers/qgstutils_p.h b/src/multimedia/gsttools_headers/qgstutils_p.h
index eea1e15..b670892 100644
--- a/src/multimedia/gsttools_headers/qgstutils_p.h
+++ b/src/multimedia/gsttools_headers/qgstutils_p.h
@@ -55,30 +55,99 @@
 
 #include <QtCore/qmap.h>
 #include <QtCore/qset.h>
+#include <QtCore/qvector.h>
 #include <gst/gst.h>
+#include <gst/video/video.h>
 #include <qaudioformat.h>
+#include <qcamera.h>
+#include <qabstractvideobuffer.h>
+#include <qvideoframe.h>
+#include <QDebug>
+
+#if GST_CHECK_VERSION(1,0,0)
+# define QT_GSTREAMER_PLAYBIN_ELEMENT_NAME "playbin"
+# define QT_GSTREAMER_CAMERABIN_ELEMENT_NAME "camerabin"
+# define QT_GSTREAMER_COLORCONVERSION_ELEMENT_NAME "videoconvert"
+# define QT_GSTREAMER_RAW_AUDIO_MIME "audio/x-raw"
+#else
+# define QT_GSTREAMER_PLAYBIN_ELEMENT_NAME "playbin2"
+# define QT_GSTREAMER_CAMERABIN_ELEMENT_NAME "camerabin2"
+# define QT_GSTREAMER_COLORCONVERSION_ELEMENT_NAME "ffmpegcolorspace"
+# define QT_GSTREAMER_RAW_AUDIO_MIME "audio/x-raw-int"
+#endif
 
 QT_BEGIN_NAMESPACE
 
 class QSize;
 class QVariant;
 class QByteArray;
+class QImage;
+class QVideoSurfaceFormat;
 
 namespace QGstUtils {
+    struct CameraInfo
+    {
+        QString name;
+        QString description;
+        int orientation;
+        QCamera::Position position;
+    };
+
     QMap<QByteArray, QVariant> gstTagListToMap(const GstTagList *list);
 
     QSize capsResolution(const GstCaps *caps);
     QSize capsCorrectedResolution(const GstCaps *caps);
     QAudioFormat audioFormatForCaps(const GstCaps *caps);
+#if GST_CHECK_VERSION(1,0,0)
+    QAudioFormat audioFormatForSample(GstSample *sample);
+#else
     QAudioFormat audioFormatForBuffer(GstBuffer *buffer);
-    GstCaps *capsForAudioFormat(QAudioFormat format);
+#endif
+    GstCaps *capsForAudioFormat(const QAudioFormat &format);
     void initializeGst();
     QMultimedia::SupportEstimate hasSupport(const QString &mimeType,
                                              const QStringList &codecs,
                                              const QSet<QString> &supportedMimeTypeSet);
+
+    QVector<CameraInfo> enumerateCameras(GstElementFactory *factory = 0);
+    QList<QByteArray> cameraDevices(GstElementFactory * factory = 0);
+    QString cameraDescription(const QString &device, GstElementFactory * factory = 0);
+    QCamera::Position cameraPosition(const QString &device, GstElementFactory * factory = 0);
+    int cameraOrientation(const QString &device, GstElementFactory * factory = 0);
+
+    QSet<QString> supportedMimeTypes(bool (*isValidFactory)(GstElementFactory *factory));
+
+#if GST_CHECK_VERSION(1,0,0)
+    QImage bufferToImage(GstBuffer *buffer, const GstVideoInfo &info);
+    QVideoSurfaceFormat formatForCaps(
+            GstCaps *caps,
+            GstVideoInfo *info,
+            QAbstractVideoBuffer::HandleType handleType = QAbstractVideoBuffer::NoHandle);
+#else
+    QImage bufferToImage(GstBuffer *buffer);
+    QVideoSurfaceFormat formatForCaps(
+            GstCaps *caps,
+            int *bytesPerLine = 0,
+            QAbstractVideoBuffer::HandleType handleType = QAbstractVideoBuffer::NoHandle);
+#endif
+
+    GstCaps *capsForFormats(const QList<QVideoFrame::PixelFormat> &formats);
+    void setFrameTimeStamps(QVideoFrame *frame, GstBuffer *buffer);
+
+    void setMetaData(GstElement *element, const QMap<QByteArray, QVariant> &data);
+    void setMetaData(GstBin *bin, const QMap<QByteArray, QVariant> &data);
+
+    GstCaps *videoFilterCaps();
+
 }
 
 void qt_gst_object_ref_sink(gpointer object);
+GstCaps *qt_gst_pad_get_current_caps(GstPad *pad);
+GstStructure *qt_gst_structure_new_empty(const char *name);
+gboolean qt_gst_element_query_position(GstElement *element, GstFormat format, gint64 *cur);
+gboolean qt_gst_element_query_duration(GstElement *element, GstFormat format, gint64 *cur);
+
+QDebug operator <<(QDebug debug, GstCaps *caps);
 
 QT_END_NAMESPACE
 
diff --git a/src/multimedia/gsttools_headers/qgstvideobuffer_p.h b/src/multimedia/gsttools_headers/qgstvideobuffer_p.h
index 505a6c6..fb82784 100644
--- a/src/multimedia/gsttools_headers/qgstvideobuffer_p.h
+++ b/src/multimedia/gsttools_headers/qgstvideobuffer_p.h
@@ -57,26 +57,47 @@
 #include <QtCore/qvariant.h>
 
 #include <gst/gst.h>
+#include <gst/video/video.h>
 
 QT_BEGIN_NAMESPACE
 
+#if GST_CHECK_VERSION(1,0,0)
+class QGstVideoBuffer : public QAbstractPlanarVideoBuffer
+{
+public:
+    QGstVideoBuffer(GstBuffer *buffer, const GstVideoInfo &info);
+    QGstVideoBuffer(GstBuffer *buffer, const GstVideoInfo &info,
+                    HandleType handleType, const QVariant &handle);
+#else
 class QGstVideoBuffer : public QAbstractVideoBuffer
 {
 public:
     QGstVideoBuffer(GstBuffer *buffer, int bytesPerLine);
     QGstVideoBuffer(GstBuffer *buffer, int bytesPerLine,
                     HandleType handleType, const QVariant &handle);
+#endif
+
     ~QGstVideoBuffer();
 
     MapMode mapMode() const;
 
+#if GST_CHECK_VERSION(1,0,0)
+    int map(MapMode mode, int *numBytes, int bytesPerLine[4], uchar *data[4]);
+#else
     uchar *map(MapMode mode, int *numBytes, int *bytesPerLine);
+#endif
+
     void unmap();
 
     QVariant handle() const { return m_handle; }
 private:
-    GstBuffer *m_buffer;
+#if GST_CHECK_VERSION(1,0,0)
+    GstVideoInfo m_videoInfo;
+    GstVideoFrame m_frame;
+#else
     int m_bytesPerLine;
+#endif
+    GstBuffer *m_buffer;
     MapMode m_mode;
     QVariant m_handle;
 };
diff --git a/src/multimedia/gsttools_headers/qgstvideorendererplugin_p.h b/src/multimedia/gsttools_headers/qgstvideorendererplugin_p.h
new file mode 100644
index 0000000..0ed2af4
--- /dev/null
+++ b/src/multimedia/gsttools_headers/qgstvideorendererplugin_p.h
@@ -0,0 +1,111 @@
+/****************************************************************************
+**
+** Copyright (C) 2014 Jolla Ltd.
+** Contact: http://www.qt-project.org/legal
+**
+** This file is part of the Qt Toolkit.
+**
+** $QT_BEGIN_LICENSE:LGPL$
+** Commercial License Usage
+** Licensees holding valid commercial Qt licenses may use this file in
+** accordance with the commercial license agreement provided with the
+** Software or, alternatively, in accordance with the terms contained in
+** a written agreement between you and Digia.  For licensing terms and
+** conditions see http://qt.digia.com/licensing.  For further information
+** use the contact form at http://qt.digia.com/contact-us.
+**
+** GNU Lesser General Public License Usage
+** Alternatively, this file may be used under the terms of the GNU Lesser
+** General Public License version 2.1 as published by the Free Software
+** Foundation and appearing in the file LICENSE.LGPL included in the
+** packaging of this file.  Please review the following information to
+** ensure the GNU Lesser General Public License version 2.1 requirements
+** will be met: http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html.
+**
+** In addition, as a special exception, Digia gives you certain additional
+** rights.  These rights are described in the Digia Qt LGPL Exception
+** version 1.1, included in the file LGPL_EXCEPTION.txt in this package.
+**
+** GNU General Public License Usage
+** Alternatively, this file may be used under the terms of the GNU
+** General Public License version 3.0 as published by the Free Software
+** Foundation and appearing in the file LICENSE.GPL included in the
+** packaging of this file.  Please review the following information to
+** ensure the GNU General Public License version 3.0 requirements will be
+** met: http://www.gnu.org/copyleft/gpl.html.
+**
+**
+** $QT_END_LICENSE$
+**
+****************************************************************************/
+
+#ifndef QGSTVIDEORENDERERPLUGIN_P_H
+#define QGSTVIDEORENDERERPLUGIN_P_H
+
+//
+//  W A R N I N G
+//  -------------
+//
+// This file is not part of the Qt API. It exists purely as an
+// implementation detail. This header file may change from version to
+// version without notice, or even be removed.
+//
+// We mean it.
+//
+
+#include <qabstractvideobuffer.h>
+#include <qvideosurfaceformat.h>
+#include <QtCore/qobject.h>
+#include <QtCore/qplugin.h>
+
+#include <gst/gst.h>
+
+QT_BEGIN_NAMESPACE
+
+class QAbstractVideoSurface;
+
+const QLatin1String QGstVideoRendererPluginKey("bufferpool");
+
+class QGstVideoRenderer
+{
+public:
+    virtual ~QGstVideoRenderer() {}
+
+    virtual GstCaps *getCaps(QAbstractVideoSurface *surface) = 0;
+    virtual bool start(QAbstractVideoSurface *surface, GstCaps *caps) = 0;
+    virtual void stop(QAbstractVideoSurface *surface) = 0;  // surface may be null if unexpectedly deleted.
+    virtual bool proposeAllocation(GstQuery *query) = 0;    // may be called from a thread.
+
+    virtual bool present(QAbstractVideoSurface *surface, GstBuffer *buffer) = 0;
+    virtual void flush(QAbstractVideoSurface *surface) = 0; // surface may be null if unexpectedly deleted.
+};
+
+/*
+    Abstract interface for video buffers allocation.
+*/
+class QGstVideoRendererInterface
+{
+public:
+    virtual ~QGstVideoRendererInterface() {}
+
+    virtual QGstVideoRenderer *createRenderer() = 0;
+};
+
+#define QGstVideoRendererInterface_iid "org.qt-project.qt.gstvideorenderer/5.4"
+Q_DECLARE_INTERFACE(QGstVideoRendererInterface, QGstVideoRendererInterface_iid)
+
+class QGstVideoRendererPlugin : public QObject, public QGstVideoRendererInterface
+{
+    Q_OBJECT
+    Q_INTERFACES(QGstVideoRendererInterface)
+public:
+    explicit QGstVideoRendererPlugin(QObject *parent = 0);
+    virtual ~QGstVideoRendererPlugin() {}
+
+    virtual QGstVideoRenderer *createRenderer() = 0;
+
+};
+
+QT_END_NAMESPACE
+
+#endif
diff --git a/src/multimedia/gsttools_headers/qgstvideorenderersink_p.h b/src/multimedia/gsttools_headers/qgstvideorenderersink_p.h
new file mode 100644
index 0000000..6feb371
--- /dev/null
+++ b/src/multimedia/gsttools_headers/qgstvideorenderersink_p.h
@@ -0,0 +1,183 @@
+/****************************************************************************
+**
+** Copyright (C) 2014 Jolla Ltd.
+** Contact: http://www.qt-project.org/legal
+**
+** This file is part of the Qt Toolkit.
+**
+** $QT_BEGIN_LICENSE:LGPL$
+** Commercial License Usage
+** Licensees holding valid commercial Qt licenses may use this file in
+** accordance with the commercial license agreement provided with the
+** Software or, alternatively, in accordance with the terms contained in
+** a written agreement between you and Digia.  For licensing terms and
+** conditions see http://qt.digia.com/licensing.  For further information
+** use the contact form at http://qt.digia.com/contact-us.
+**
+** GNU Lesser General Public License Usage
+** Alternatively, this file may be used under the terms of the GNU Lesser
+** General Public License version 2.1 as published by the Free Software
+** Foundation and appearing in the file LICENSE.LGPL included in the
+** packaging of this file.  Please review the following information to
+** ensure the GNU Lesser General Public License version 2.1 requirements
+** will be met: http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html.
+**
+** In addition, as a special exception, Digia gives you certain additional
+** rights.  These rights are described in the Digia Qt LGPL Exception
+** version 1.1, included in the file LGPL_EXCEPTION.txt in this package.
+**
+** GNU General Public License Usage
+** Alternatively, this file may be used under the terms of the GNU
+** General Public License version 3.0 as published by the Free Software
+** Foundation and appearing in the file LICENSE.GPL included in the
+** packaging of this file.  Please review the following information to
+** ensure the GNU General Public License version 3.0 requirements will be
+** met: http://www.gnu.org/copyleft/gpl.html.
+**
+**
+** $QT_END_LICENSE$
+**
+****************************************************************************/
+
+#ifndef QGSTVIDEORENDERERSINK_P_H
+#define QGSTVIDEORENDERERSINK_P_H
+
+//
+//  W A R N I N G
+//  -------------
+//
+// This file is not part of the Qt API. It exists purely as an
+// implementation detail. This header file may change from version to
+// version without notice, or even be removed.
+//
+// We mean it.
+//
+
+#include <gst/video/gstvideosink.h>
+#include <gst/video/video.h>
+
+#include <QtCore/qlist.h>
+#include <QtCore/qmutex.h>
+#include <QtCore/qqueue.h>
+#include <QtCore/qpointer.h>
+#include <QtCore/qwaitcondition.h>
+#include <qvideosurfaceformat.h>
+#include <qvideoframe.h>
+#include <qabstractvideobuffer.h>
+
+#include "qgstvideorendererplugin_p.h"
+
+#include "qgstvideorendererplugin_p.h"
+
+QT_BEGIN_NAMESPACE
+class QAbstractVideoSurface;
+
+class QGstDefaultVideoRenderer : public QGstVideoRenderer
+{
+public:
+    QGstDefaultVideoRenderer();
+    ~QGstDefaultVideoRenderer();
+
+    GstCaps *getCaps(QAbstractVideoSurface *surface);
+    bool start(QAbstractVideoSurface *surface, GstCaps *caps);
+    void stop(QAbstractVideoSurface *surface);
+
+    bool proposeAllocation(GstQuery *query);
+
+    bool present(QAbstractVideoSurface *surface, GstBuffer *buffer);
+    void flush(QAbstractVideoSurface *surface);
+
+private:
+    QVideoSurfaceFormat m_format;
+    GstVideoInfo m_videoInfo;
+    bool m_flushed;
+};
+
+class QVideoSurfaceGstDelegate : public QObject
+{
+    Q_OBJECT
+public:
+    QVideoSurfaceGstDelegate(QAbstractVideoSurface *surface);
+    ~QVideoSurfaceGstDelegate();
+
+    GstCaps *caps();
+
+    bool start(GstCaps *caps);
+    void stop();
+    bool proposeAllocation(GstQuery *query);
+
+    void flush();
+
+    GstFlowReturn render(GstBuffer *buffer, bool show);
+
+    bool event(QEvent *event);
+
+    static void handleShowPrerollChange(GObject *o, GParamSpec *p, gpointer d);
+
+private slots:
+    bool handleEvent(QMutexLocker *locker);
+    void updateSupportedFormats();
+
+private:
+    void notify();
+    bool waitForAsyncEvent(QMutexLocker *locker, QWaitCondition *condition, unsigned long time);
+
+    QPointer<QAbstractVideoSurface> m_surface;
+
+    QMutex m_mutex;
+    QWaitCondition m_setupCondition;
+    QWaitCondition m_renderCondition;
+    GstFlowReturn m_renderReturn;
+    QList<QGstVideoRenderer *> m_renderers;
+    QGstVideoRenderer *m_renderer;
+    QGstVideoRenderer *m_activeRenderer;
+
+    GstCaps *m_surfaceCaps;
+    GstCaps *m_startCaps;
+    GstBuffer *m_lastBuffer;
+
+    bool m_notified;
+    bool m_stop;
+    bool m_render;
+    bool m_flush;
+};
+
+class QGstVideoRendererSink
+{
+public:
+    GstVideoSink parent;
+
+    static QGstVideoRendererSink *createSink(QAbstractVideoSurface *surface);
+
+private:
+    static GType get_type();
+    static void class_init(gpointer g_class, gpointer class_data);
+    static void base_init(gpointer g_class);
+    static void instance_init(GTypeInstance *instance, gpointer g_class);
+
+    static void finalize(GObject *object);
+
+    static GstStateChangeReturn change_state(GstElement *element, GstStateChange transition);
+
+    static GstCaps *get_caps(GstBaseSink *sink, GstCaps *filter);
+    static gboolean set_caps(GstBaseSink *sink, GstCaps *caps);
+
+    static gboolean propose_allocation(GstBaseSink *sink, GstQuery *query);
+
+    static GstFlowReturn preroll(GstBaseSink *sink, GstBuffer *buffer);
+    static GstFlowReturn render(GstBaseSink *sink, GstBuffer *buffer);
+
+private:
+    QVideoSurfaceGstDelegate *delegate;
+};
+
+
+class QGstVideoRendererSinkClass
+{
+public:
+    GstVideoSinkClass parent_class;
+};
+
+QT_END_NAMESPACE
+
+#endif
diff --git a/src/multimedia/gsttools_headers/qvideosurfacegstsink_p.h b/src/multimedia/gsttools_headers/qvideosurfacegstsink_p.h
index 7563f06..57aa52f 100644
--- a/src/multimedia/gsttools_headers/qvideosurfacegstsink_p.h
+++ b/src/multimedia/gsttools_headers/qvideosurfacegstsink_p.h
@@ -53,6 +53,18 @@
 // We mean it.
 //
 
+#include <gst/gst.h>
+
+#if GST_CHECK_VERSION(1,0,0)
+
+#include "qgstvideorenderersink_p.h"
+
+QT_BEGIN_NAMESPACE
+typedef QGstVideoRendererSink QVideoSurfaceGstSink;
+QT_END_NAMESPACE
+
+#else
+
 #include <gst/video/gstvideosink.h>
 
 #include <QtCore/qlist.h>
@@ -129,10 +141,6 @@ public:
     GstVideoSink parent;
 
     static QVideoSurfaceGstSink *createSink(QAbstractVideoSurface *surface);
-    static QVideoSurfaceFormat formatForCaps(GstCaps *caps,
-                                             int *bytesPerLine = 0,
-                                             QAbstractVideoBuffer::HandleType handleType = QAbstractVideoBuffer::NoHandle);
-    static void setFrameTimeStamps(QVideoFrame *frame, GstBuffer *buffer);
 
     static void handleShowPrerollChange(GObject *o, GParamSpec *p, gpointer d);
 
@@ -169,7 +177,6 @@ private:
     QVideoSurfaceFormat *lastSurfaceFormat;
 };
 
-
 class QVideoSurfaceGstSinkClass
 {
 public:
@@ -179,3 +186,5 @@ public:
 QT_END_NAMESPACE
 
 #endif
+
+#endif
diff --git a/src/multimedia/video/qabstractvideobuffer.cpp b/src/multimedia/video/qabstractvideobuffer.cpp
index 79da6f9..5f29a01 100644
--- a/src/multimedia/video/qabstractvideobuffer.cpp
+++ b/src/multimedia/video/qabstractvideobuffer.cpp
@@ -56,6 +56,15 @@ static void qRegisterAbstractVideoBufferMetaTypes()
 
 Q_CONSTRUCTOR_FUNCTION(qRegisterAbstractVideoBufferMetaTypes)
 
+int QAbstractVideoBufferPrivate::map(
+            QAbstractVideoBuffer::MapMode mode,
+            int *numBytes,
+            int bytesPerLine[4],
+            uchar *data[4])
+{
+    data[0] = q_ptr->map(mode, numBytes, bytesPerLine);
+    return data[0] ? 1 : 0;
+}
 
 /*!
     \class QAbstractVideoBuffer
@@ -130,6 +139,7 @@ QAbstractVideoBuffer::QAbstractVideoBuffer(QAbstractVideoBufferPrivate &dd, Hand
     : d_ptr(&dd)
     , m_type(type)
 {
+    d_ptr->q_ptr = this;
 }
 
 /*!
@@ -199,6 +209,44 @@ QAbstractVideoBuffer::HandleType QAbstractVideoBuffer::handleType() const
     \sa unmap(), mapMode()
 */
 
+
+/*!
+    Independently maps the planes of a video buffer to memory.
+
+    The map \a mode indicates whether the contents of the mapped memory should be read from and/or
+    written to the buffer.  If the map mode includes the \c QAbstractVideoBuffer::ReadOnly flag the
+    mapped memory will be populated with the content of the buffer when initially mapped.  If the map
+    mode includes the \c QAbstractVideoBuffer::WriteOnly flag the content of the possibly modified
+    mapped memory will be written back to the buffer when unmapped.
+
+    When access to the data is no longer needed be sure to call the unmap() function to release the
+    mapped memory and possibly update the buffer contents.
+
+    Returns the number of planes in the mapped video data.  For each plane the line stride of that
+    plane will be returned in \a bytesPerLine, and a pointer to the plane data will be returned in
+    \a data.  The accumulative size of the mapped data is returned in \a numBytes.
+
+    Not all buffer implementations will map more than the first plane, if this returns a single
+    plane for a planar format the additional planes will have to be calculated from the line stride
+    of the first plane and the frame height.  Mapping a buffer with QVideoFrame will do this for
+    you.
+
+    To implement this function create a derivative of QAbstractPlanarVideoBuffer and implement
+    its map function instance instead.
+
+    \since 5.4
+*/
+int QAbstractVideoBuffer::mapPlanes(MapMode mode, int *numBytes, int bytesPerLine[4], uchar *data[4])
+{
+    if (d_ptr) {
+        return d_ptr->map(mode, numBytes, bytesPerLine, data);
+    } else {
+        data[0] = map(mode, numBytes, bytesPerLine);
+
+        return data[0] ? 1 : 0;
+    }
+}
+
 /*!
     \fn QAbstractVideoBuffer::unmap()
 
@@ -222,6 +270,90 @@ QVariant QAbstractVideoBuffer::handle() const
     return QVariant();
 }
 
+
+int QAbstractPlanarVideoBufferPrivate::map(
+        QAbstractVideoBuffer::MapMode mode, int *numBytes, int bytesPerLine[4], uchar *data[4])
+{
+    return q_func()->map(mode, numBytes, bytesPerLine, data);
+}
+
+/*!
+    \class QAbstractPlanarVideoBuffer
+    \brief The QAbstractPlanarVideoBuffer class is an abstraction for planar video data.
+    \inmodule QtMultimedia
+    \ingroup QtMultimedia
+    \ingroup multimedia
+    \ingroup multimedia_video
+
+    QAbstractPlanarVideoBuffer extends QAbstractVideoBuffer to support mapping
+    non-continuous planar video data.  Implement this instead of QAbstractVideoBuffer when the
+    abstracted video data stores planes in separate buffers or includes padding between planes
+    which would interfere with calculating offsets from the bytes per line and frame height.
+
+    \sa QAbstractVideoBuffer::mapPlanes()
+    \since 5.4
+*/
+
+/*!
+    Constructs an abstract planar video buffer of the given \a type.
+*/
+QAbstractPlanarVideoBuffer::QAbstractPlanarVideoBuffer(HandleType type)
+    : QAbstractVideoBuffer(*new QAbstractPlanarVideoBufferPrivate, type)
+{
+}
+
+/*!
+    \internal
+*/
+QAbstractPlanarVideoBuffer::QAbstractPlanarVideoBuffer(
+        QAbstractPlanarVideoBufferPrivate &dd, HandleType type)
+    : QAbstractVideoBuffer(dd, type)
+{
+}
+/*!
+    Destroys an abstract planar video buffer.
+*/
+QAbstractPlanarVideoBuffer::~QAbstractPlanarVideoBuffer()
+{
+}
+
+/*!
+    \internal
+*/
+uchar *QAbstractPlanarVideoBuffer::map(MapMode mode, int *numBytes, int *bytesPerLine)
+{
+    uchar *data[4];
+    int strides[4];
+    if (map(mode, numBytes, strides, data) > 0) {
+        if (bytesPerLine)
+            *bytesPerLine = strides[0];
+        return data[0];
+    } else {
+        return 0;
+    }
+}
+
+/*!
+    \fn int QAbstractPlanarVideoBuffer::map(MapMode mode, int *numBytes, int bytesPerLine[4], uchar *data[4])
+
+    Maps the contents of a video buffer to memory.
+
+    The map \a mode indicates whether the contents of the mapped memory should be read from and/or
+    written to the buffer.  If the map mode includes the \c QAbstractVideoBuffer::ReadOnly flag the
+    mapped memory will be populated with the content of the buffer when initially mapped.  If the map
+    mode includes the \c QAbstractVideoBuffer::WriteOnly flag the content of the possibly modified
+    mapped memory will be written back to the buffer when unmapped.
+
+    When access to the data is no longer needed be sure to call the unmap() function to release the
+    mapped memory and possibly update the buffer contents.
+
+    Returns the number of planes in the mapped video data.  For each plane the line stride of that
+    plane will be returned in \a bytesPerLine, and a pointer to the plane data will be returned in
+    \a data.  The accumulative size of the mapped data is returned in \a numBytes.
+
+    \sa QAbstractVideoBuffer::map(), QAbstractVideoBuffer::unmap(), QAbstractVideoBuffer::mapMode()
+*/
+
 #ifndef QT_NO_DEBUG_STREAM
 QDebug operator<<(QDebug dbg, QAbstractVideoBuffer::HandleType type)
 {
diff --git a/src/multimedia/video/qabstractvideobuffer.h b/src/multimedia/video/qabstractvideobuffer.h
index 1be90ff..7f3edf5 100644
--- a/src/multimedia/video/qabstractvideobuffer.h
+++ b/src/multimedia/video/qabstractvideobuffer.h
@@ -85,6 +85,7 @@ public:
     virtual MapMode mapMode() const = 0;
 
     virtual uchar *map(MapMode mode, int *numBytes, int *bytesPerLine) = 0;
+    int mapPlanes(MapMode mode, int *numBytes, int bytesPerLine[4], uchar *data[4]);
     virtual void unmap() = 0;
 
     virtual QVariant handle() const;
@@ -100,6 +101,23 @@ private:
     Q_DISABLE_COPY(QAbstractVideoBuffer)
 };
 
+class QAbstractPlanarVideoBufferPrivate;
+class Q_MULTIMEDIA_EXPORT QAbstractPlanarVideoBuffer : public QAbstractVideoBuffer
+{
+public:
+    QAbstractPlanarVideoBuffer(HandleType type);
+    virtual ~QAbstractPlanarVideoBuffer();
+
+    uchar *map(MapMode mode, int *numBytes, int *bytesPerLine);
+    virtual int map(MapMode mode, int *numBytes, int bytesPerLine[4], uchar *data[4]) = 0;
+
+protected:
+    QAbstractPlanarVideoBuffer(QAbstractPlanarVideoBufferPrivate &dd, HandleType type);
+
+private:
+    Q_DISABLE_COPY(QAbstractPlanarVideoBuffer)
+};
+
 #ifndef QT_NO_DEBUG_STREAM
 Q_MULTIMEDIA_EXPORT QDebug operator<<(QDebug, QAbstractVideoBuffer::HandleType);
 Q_MULTIMEDIA_EXPORT QDebug operator<<(QDebug, QAbstractVideoBuffer::MapMode);
diff --git a/src/multimedia/video/qabstractvideobuffer_p.h b/src/multimedia/video/qabstractvideobuffer_p.h
index 8841f75..dfb1df6 100644
--- a/src/multimedia/video/qabstractvideobuffer_p.h
+++ b/src/multimedia/video/qabstractvideobuffer_p.h
@@ -66,10 +66,31 @@ class QAbstractVideoBufferPrivate
 {
 public:
     QAbstractVideoBufferPrivate()
+        : q_ptr(0)
     {}
 
     virtual ~QAbstractVideoBufferPrivate()
     {}
+
+    virtual int map(
+            QAbstractVideoBuffer::MapMode mode,
+            int *numBytes,
+            int bytesPerLine[4],
+            uchar *data[4]);
+
+    QAbstractVideoBuffer *q_ptr;
+};
+
+class QAbstractPlanarVideoBufferPrivate : QAbstractVideoBufferPrivate
+{
+public:
+    QAbstractPlanarVideoBufferPrivate()
+    {}
+
+    int map(QAbstractVideoBuffer::MapMode mode, int *numBytes, int bytesPerLine[4], uchar *data[4]);
+
+private:
+    Q_DECLARE_PUBLIC(QAbstractPlanarVideoBuffer)
 };
 
 QT_END_NAMESPACE
diff --git a/src/multimedia/video/qvideoframe.cpp b/src/multimedia/video/qvideoframe.cpp
index ad81c80..7a9e3e1 100644
--- a/src/multimedia/video/qvideoframe.cpp
+++ b/src/multimedia/video/qvideoframe.cpp
@@ -71,28 +71,30 @@ public:
     QVideoFramePrivate()
         : startTime(-1)
         , endTime(-1)
-        , data(0)
         , mappedBytes(0)
-        , bytesPerLine(0)
+        , planeCount(0)
         , pixelFormat(QVideoFrame::Format_Invalid)
         , fieldType(QVideoFrame::ProgressiveFrame)
         , buffer(0)
         , mappedCount(0)
     {
+        memset(data, 0, sizeof(data));
+        memset(bytesPerLine, 0, sizeof(bytesPerLine));
     }
 
     QVideoFramePrivate(const QSize &size, QVideoFrame::PixelFormat format)
         : size(size)
         , startTime(-1)
         , endTime(-1)
-        , data(0)
         , mappedBytes(0)
-        , bytesPerLine(0)
+        , planeCount(0)
         , pixelFormat(format)
         , fieldType(QVideoFrame::ProgressiveFrame)
         , buffer(0)
         , mappedCount(0)
     {
+        memset(data, 0, sizeof(data));
+        memset(bytesPerLine, 0, sizeof(bytesPerLine));
     }
 
     ~QVideoFramePrivate()
@@ -104,9 +106,10 @@ public:
     QSize size;
     qint64 startTime;
     qint64 endTime;
-    uchar *data;
+    uchar *data[4];
+    int bytesPerLine[4];
     int mappedBytes;
-    int bytesPerLine;
+    int planeCount;
     QVideoFrame::PixelFormat pixelFormat;
     QVideoFrame::FieldType fieldType;
     QAbstractVideoBuffer *buffer;
@@ -564,18 +567,88 @@ bool QVideoFrame::map(QAbstractVideoBuffer::MapMode mode)
         }
     }
 
-    Q_ASSERT(d->data == 0);
-    Q_ASSERT(d->bytesPerLine == 0);
+    Q_ASSERT(d->data[0] == 0);
+    Q_ASSERT(d->bytesPerLine[0] == 0);
+    Q_ASSERT(d->planeCount == 0);
     Q_ASSERT(d->mappedBytes == 0);
 
-    d->data = d->buffer->map(mode, &d->mappedBytes, &d->bytesPerLine);
+    d->planeCount = d->buffer->mapPlanes(mode, &d->mappedBytes, d->bytesPerLine, d->data);
+    if (d->planeCount == 0)
+        return false;
 
-    if (d->data) {
-        d->mappedCount++;
-        return true;
+    if (d->planeCount > 1) {
+        // If the plane count is derive the additional planes for planar formats.
+    } else switch (d->pixelFormat) {
+    case Format_Invalid:
+    case Format_ARGB32:
+    case Format_ARGB32_Premultiplied:
+    case Format_RGB32:
+    case Format_RGB24:
+    case Format_RGB565:
+    case Format_RGB555:
+    case Format_ARGB8565_Premultiplied:
+    case Format_BGRA32:
+    case Format_BGRA32_Premultiplied:
+    case Format_BGR32:
+    case Format_BGR24:
+    case Format_BGR565:
+    case Format_BGR555:
+    case Format_BGRA5658_Premultiplied:
+    case Format_AYUV444:
+    case Format_AYUV444_Premultiplied:
+    case Format_YUV444:
+    case Format_UYVY:
+    case Format_YUYV:
+    case Format_Y8:
+    case Format_Y16:
+    case Format_Jpeg:
+    case Format_CameraRaw:
+    case Format_AdobeDng:
+    case Format_User:
+        // Single plane or opaque format.
+        break;
+    case Format_YUV420P:
+    case Format_YV12: {
+        // The UV stride is usually half the Y stride and is 32-bit aligned.
+        // However it's not always the case, at least on Windows where the
+        // UV planes are sometimes not aligned.
+        // We calculate the stride using the UV byte count to always
+        // have a correct stride.
+        const int height = d->size.height();
+        const int yStride = d->bytesPerLine[0];
+        const int uvStride = (d->mappedBytes - (yStride * height)) / height;
+
+        // Three planes, the second and third vertically and horizontally subsampled.
+        d->planeCount = 3;
+        d->bytesPerLine[2] = d->bytesPerLine[1] = uvStride;
+        d->data[1] = d->data[0] + (yStride * height);
+        d->data[2] = d->data[1] + (uvStride * height / 2);
+        break;
+    }
+    case Format_NV12:
+    case Format_NV21:
+    case Format_IMC2:
+    case Format_IMC4: {
+        // Semi planar, Full resolution Y plane with interleaved subsampled U and V planes.
+        d->planeCount = 2;
+        d->bytesPerLine[1] = d->bytesPerLine[0];
+        d->data[1] = d->data[0] + (d->bytesPerLine[0] * d->size.height());
+        break;
+    }
+    case Format_IMC1:
+    case Format_IMC3: {
+        // Three planes, the second and third vertically and horizontally subsumpled,
+        // but with lines padded to the width of the first plane.
+        d->planeCount = 3;
+        d->bytesPerLine[2] = d->bytesPerLine[1] = d->bytesPerLine[0];
+        d->data[1] = d->data[0] + (d->bytesPerLine[0] * d->size.height());
+        d->data[2] = d->data[1] + (d->bytesPerLine[1] * d->size.height() / 2);
+        break;
+    }
     }
 
-    return false;
+    d->mappedCount++;
+    return true;
 }
 
 /*!
@@ -604,8 +677,9 @@ void QVideoFrame::unmap()
 
     if (d->mappedCount == 0) {
         d->mappedBytes = 0;
-        d->bytesPerLine = 0;
-        d->data = 0;
+        d->planeCount = 0;
+        memset(d->bytesPerLine, 0, sizeof(d->bytesPerLine));
+        memset(d->data, 0, sizeof(d->data));
 
         d->buffer->unmap();
     }
@@ -623,7 +697,21 @@ void QVideoFrame::unmap()
 */
 int QVideoFrame::bytesPerLine() const
 {
-    return d->bytesPerLine;
+    return d->bytesPerLine[0];
+}
+
+/*!
+    Returns the number of bytes in a scan line of a \a plane.
+
+    This value is only valid while the frame data is \l {map()}{mapped}.
+
+    \sa bits(), map(), mappedBytes(), planeCount()
+    \since 5.4
+*/
+
+int QVideoFrame::bytesPerLine(int plane) const
+{
+    return plane >= 0 && plane < d->planeCount ? d->bytesPerLine[plane] : 0;
 }
 
 /*!
@@ -639,7 +727,24 @@ int QVideoFrame::bytesPerLine() const
 */
 uchar *QVideoFrame::bits()
 {
-    return d->data;
+    return d->data[0];
+}
+
+/*!
+    Returns a pointer to the start of the frame data buffer for a \a plane.
+
+    This value is only valid while the frame data is \l {map()}{mapped}.
+
+    Changes made to data accessed via this pointer (when mapped with write access)
+    are only guaranteed to have been persisted when unmap() is called and when the
+    buffer has been mapped for writing.
+
+    \sa map(), mappedBytes(), bytesPerLine(), planeCount()
+    \since 5.4
+*/
+uchar *QVideoFrame::bits(int plane)
+{
+    return plane >= 0 && plane < d->planeCount ? d->data[plane] : 0;
 }
 
 /*!
@@ -654,7 +759,23 @@ uchar *QVideoFrame::bits()
 */
 const uchar *QVideoFrame::bits() const
 {
-    return d->data;
+    return d->data[0];
+}
+
+/*!
+    Returns a pointer to the start of the frame data buffer for a \a plane.
+
+    This value is only valid while the frame data is \l {map()}{mapped}.
+
+    If the buffer was not mapped with read access, the contents of this
+    buffer will initially be uninitialized.
+
+    \sa map(), mappedBytes(), bytesPerLine(), planeCount()
+    \since 5.4
+*/
+const uchar *QVideoFrame::bits(int plane) const
+{
+    return plane >= 0 && plane < d->planeCount ?  d->data[plane] : 0;
 }
 
 /*!
@@ -670,6 +791,20 @@ int QVideoFrame::mappedBytes() const
 }
 
 /*!
+    Returns the number of planes in the video frame.
+
+    This value is only valid while the frame data is \l {map()}{mapped}.
+
+    \sa map()
+    \since 5.4
+*/
+
+int QVideoFrame::planeCount() const
+{
+    return d->planeCount;
+}
+
+/*!
     Returns a type specific handle to a video frame's buffer.
 
     For an OpenGL texture this would be the texture ID.
@@ -852,9 +987,6 @@ QImage::Format QVideoFrame::imageFormatFromPixelFormat(PixelFormat format)
     return QImage::Format_Invalid;
 }
 
-
-
-
 #ifndef QT_NO_DEBUG_STREAM
 QDebug operator<<(QDebug dbg, QVideoFrame::PixelFormat pf)
 {
@@ -1017,7 +1149,7 @@ static QString qFormatTimeStamps(qint64 start, qint64 end)
 
 QDebug operator<<(QDebug dbg, const QVideoFrame& f)
 {
-    dbg.nospace() << "QVideoFrame(" << f.size() << ","
+    dbg.nospace() << "QVideoFrame(" << f.size() << ", "
                << f.pixelFormat() << ", "
                << f.handleType() << ", "
                << f.mapMode() << ", "
diff --git a/src/multimedia/video/qvideoframe.h b/src/multimedia/video/qvideoframe.h
index 504a0d5..0ca13d8 100644
--- a/src/multimedia/video/qvideoframe.h
+++ b/src/multimedia/video/qvideoframe.h
@@ -139,10 +139,14 @@ public:
     void unmap();
 
     int bytesPerLine() const;
+    int bytesPerLine(int plane) const;
 
     uchar *bits();
+    uchar *bits(int plane);
     const uchar *bits() const;
+    const uchar *bits(int plane) const;
     int mappedBytes() const;
+    int planeCount() const;
 
     QVariant handle() const;
 
diff --git a/src/multimediawidgets/doc/qtmultimediawidgets.qdocconf b/src/multimediawidgets/doc/qtmultimediawidgets.qdocconf
index 92d4dc0..19e956a 100644
--- a/src/multimediawidgets/doc/qtmultimediawidgets.qdocconf
+++ b/src/multimediawidgets/doc/qtmultimediawidgets.qdocconf
@@ -2,7 +2,6 @@ include($QT_INSTALL_DOCS/global/qt-module-defaults.qdocconf)
 
 project                 = QtMultimediaWidgets
 description             = Qt Multimedia Widgets Documentation
-url                     = http://qt-project.org/doc/qt-$QT_VER
 version                 = $QT_VERSION
 
 # The following parameters are for creating a qhp file, the qhelpgenerator
diff --git a/src/plugins/alsa/qalsaaudioinput.cpp b/src/plugins/alsa/qalsaaudioinput.cpp
index 902dd57..e01f2d7 100644
--- a/src/plugins/alsa/qalsaaudioinput.cpp
+++ b/src/plugins/alsa/qalsaaudioinput.cpp
@@ -63,7 +63,6 @@ QAlsaAudioInput::QAlsaAudioInput(const QByteArray &device)
 {
     bytesAvailable = 0;
     handle = 0;
-    ahandler = 0;
     access = SND_PCM_ACCESS_RW_INTERLEAVED;
     pcmformat = SND_PCM_FORMAT_S16;
     buffer_size = 0;
diff --git a/src/plugins/alsa/qalsaaudioinput.h b/src/plugins/alsa/qalsaaudioinput.h
index 6af566c..7047583 100644
--- a/src/plugins/alsa/qalsaaudioinput.h
+++ b/src/plugins/alsa/qalsaaudioinput.h
@@ -159,7 +159,6 @@ private:
     unsigned int period_time;
     snd_pcm_uframes_t buffer_frames;
     snd_pcm_uframes_t period_frames;
-    snd_async_handler_t* ahandler;
     snd_pcm_access_t access;
     snd_pcm_format_t pcmformat;
     snd_timestamp_t* timestamp;
diff --git a/src/plugins/alsa/qalsaaudiooutput.cpp b/src/plugins/alsa/qalsaaudiooutput.cpp
index 192b635..c8d709c 100644
--- a/src/plugins/alsa/qalsaaudiooutput.cpp
+++ b/src/plugins/alsa/qalsaaudiooutput.cpp
@@ -63,7 +63,6 @@ QAlsaAudioOutput::QAlsaAudioOutput(const QByteArray &device)
 {
     bytesAvailable = 0;
     handle = 0;
-    ahandler = 0;
     access = SND_PCM_ACCESS_RW_INTERLEAVED;
     pcmformat = SND_PCM_FORMAT_S16;
     buffer_frames = 0;
@@ -118,17 +117,6 @@ QAudio::State QAlsaAudioOutput::state() const
     return deviceState;
 }
 
-void QAlsaAudioOutput::async_callback(snd_async_handler_t *ahandler)
-{
-    QAlsaAudioOutput* audioOut;
-
-    audioOut = static_cast<QAlsaAudioOutput*>
-        (snd_async_handler_get_callback_private(ahandler));
-
-    if (audioOut && (audioOut->deviceState == QAudio::ActiveState || audioOut->resuming))
-        audioOut->feedback();
-}
-
 int QAlsaAudioOutput::xrun_recovery(int err)
 {
     int  count = 0;
@@ -512,8 +500,7 @@ bool QAlsaAudioOutput::open()
     snd_pcm_prepare( handle );
     snd_pcm_start(handle);
 
-    // Step 5: Setup callback and timer fallback
-    snd_async_add_pcm_handler(&ahandler, handle, async_callback, this);
+    // Step 5: Setup timer
     bytesAvailable = bytesFree();
 
     // Step 6: Start audio processing
@@ -715,21 +702,6 @@ void QAlsaAudioOutput::userFeed()
     deviceReady();
 }
 
-void QAlsaAudioOutput::feedback()
-{
-    updateAvailable();
-}
-
-
-void QAlsaAudioOutput::updateAvailable()
-{
-#ifdef DEBUG_AUDIO
-    QTime now(QTime::currentTime());
-    qDebug()<<now.second()<<"s "<<now.msec()<<"ms :updateAvailable()";
-#endif
-    bytesAvailable = bytesFree();
-}
-
 bool QAlsaAudioOutput::deviceReady()
 {
     if(pullMode) {
diff --git a/src/plugins/alsa/qalsaaudiooutput.h b/src/plugins/alsa/qalsaaudiooutput.h
index 67976a5..274878d 100644
--- a/src/plugins/alsa/qalsaaudiooutput.h
+++ b/src/plugins/alsa/qalsaaudiooutput.h
@@ -107,8 +107,6 @@ public:
 
 private slots:
     void userFeed();
-    void feedback();
-    void updateAvailable();
     bool deviceReady();
 
 signals:
@@ -126,7 +124,6 @@ private:
     unsigned int period_time;
     snd_pcm_uframes_t buffer_frames;
     snd_pcm_uframes_t period_frames;
-    static void async_callback(snd_async_handler_t *ahandler);
     int xrun_recovery(int err);
 
     int setFormat();
@@ -141,7 +138,6 @@ private:
     qint64 elapsedTimeOffset;
     char* audioBuffer;
     snd_pcm_t* handle;
-    snd_async_handler_t* ahandler;
     snd_pcm_access_t access;
     snd_pcm_format_t pcmformat;
     snd_timestamp_t* timestamp;
diff --git a/src/plugins/android/src/mediacapture/qandroidcamerafocuscontrol.cpp b/src/plugins/android/src/mediacapture/qandroidcamerafocuscontrol.cpp
index 0b6ab80..c4e0ea1 100644
--- a/src/plugins/android/src/mediacapture/qandroidcamerafocuscontrol.cpp
+++ b/src/plugins/android/src/mediacapture/qandroidcamerafocuscontrol.cpp
@@ -234,25 +234,24 @@ void QAndroidCameraFocusControl::updateFocusZones(QCameraFocusZone::FocusZoneSta
     // create a focus zone (50x50 pixel) around the focus point
     m_focusZones.clear();
 
-    if (m_actualFocusPoint.isNull())
-        return;
-
-    QSize viewportSize = m_session->camera()->previewSize();
+    if (!m_actualFocusPoint.isNull()) {
+        QSize viewportSize = m_session->camera()->previewSize();
 
-    if (!viewportSize.isValid())
-        return;
+        if (!viewportSize.isValid())
+            return;
 
-    QSizeF focusSize(50.f / viewportSize.width(), 50.f / viewportSize.height());
-    float x = qBound(qreal(0),
-                     m_actualFocusPoint.x() - (focusSize.width() / 2),
-                     1.f - focusSize.width());
-    float y = qBound(qreal(0),
-                     m_actualFocusPoint.y() - (focusSize.height() / 2),
-                     1.f - focusSize.height());
+        QSizeF focusSize(50.f / viewportSize.width(), 50.f / viewportSize.height());
+        float x = qBound(qreal(0),
+                         m_actualFocusPoint.x() - (focusSize.width() / 2),
+                         1.f - focusSize.width());
+        float y = qBound(qreal(0),
+                         m_actualFocusPoint.y() - (focusSize.height() / 2),
+                         1.f - focusSize.height());
 
-    QRectF area(QPointF(x, y), focusSize);
+        QRectF area(QPointF(x, y), focusSize);
 
-    m_focusZones.append(QCameraFocusZone(area, status));
+        m_focusZones.append(QCameraFocusZone(area, status));
+    }
 
     emit focusZonesChanged();
 }
diff --git a/src/plugins/android/src/mediacapture/qandroidcapturesession.cpp b/src/plugins/android/src/mediacapture/qandroidcapturesession.cpp
index 383af81..c053c8e 100644
--- a/src/plugins/android/src/mediacapture/qandroidcapturesession.cpp
+++ b/src/plugins/android/src/mediacapture/qandroidcapturesession.cpp
@@ -269,7 +269,7 @@ void QAndroidCaptureSession::stop(bool error)
     delete m_mediaRecorder;
     m_mediaRecorder = 0;
 
-    if (m_cameraSession) {
+    if (m_cameraSession && m_cameraSession->status() == QCamera::ActiveStatus) {
         // Viewport needs to be restarted after recording
         restartViewfinder();
     }
@@ -278,7 +278,7 @@ void QAndroidCaptureSession::stop(bool error)
         // if the media is saved into the standard media location, register it
         // with the Android media scanner so it appears immediately in apps
         // such as the gallery.
-        QString mediaPath = m_actualOutputLocation.toLocalFile();
+        QString mediaPath = m_usedOutputLocation.toLocalFile();
         QString standardLoc = m_cameraSession ? AndroidMultimediaUtils::getDefaultMediaDirectory(AndroidMultimediaUtils::DCIM)
                                               : AndroidMultimediaUtils::getDefaultMediaDirectory(AndroidMultimediaUtils::Sounds);
         if (mediaPath.startsWith(standardLoc))
@@ -516,6 +516,7 @@ void QAndroidCaptureSession::updateStatus()
         if (m_cameraSession->status() == QCamera::StoppingStatus
                 || !m_cameraSession->captureMode().testFlag(QCamera::CaptureVideo)) {
             setState(QMediaRecorder::StoppedState);
+            return;
         }
 
         if (m_state == QMediaRecorder::RecordingState) {
diff --git a/src/plugins/avfoundation/mediaplayer/mediaplayer.pro b/src/plugins/avfoundation/mediaplayer/mediaplayer.pro
index b5193b7..2670ece 100644
--- a/src/plugins/avfoundation/mediaplayer/mediaplayer.pro
+++ b/src/plugins/avfoundation/mediaplayer/mediaplayer.pro
@@ -49,12 +49,17 @@ OBJECTIVE_SOURCES += \
 
     HEADERS += \
         avfvideorenderercontrol.h \
-        avfdisplaylink.h \
-        avfvideoframerenderer.h
+        avfdisplaylink.h
     OBJECTIVE_SOURCES += \
         avfvideorenderercontrol.mm \
-        avfdisplaylink.mm \
-        avfvideoframerenderer.mm
+        avfdisplaylink.mm
+
+    contains(QT_CONFIG, opengl.*) {
+        HEADERS += \
+            avfvideoframerenderer.h
+        OBJECTIVE_SOURCES += \
+            avfvideoframerenderer.mm
+    }
 }
 
 OTHER_FILES += \
diff --git a/src/plugins/gstreamer/audiodecoder/qgstreameraudiodecoderserviceplugin.cpp b/src/plugins/gstreamer/audiodecoder/qgstreameraudiodecoderserviceplugin.cpp
index e6d2421..534b4f1 100644
--- a/src/plugins/gstreamer/audiodecoder/qgstreameraudiodecoderserviceplugin.cpp
+++ b/src/plugins/gstreamer/audiodecoder/qgstreameraudiodecoderserviceplugin.cpp
@@ -76,89 +76,16 @@ QMultimedia::SupportEstimate QGstreamerAudioDecoderServicePlugin::hasSupport(con
     return QGstUtils::hasSupport(mimeType, codecs, m_supportedMimeTypeSet);
 }
 
-void QGstreamerAudioDecoderServicePlugin::updateSupportedMimeTypes() const
+static bool isDecoderOrDemuxer(GstElementFactory *factory)
 {
-    //enumerate supported mime types
-    gst_init(NULL, NULL);
-
-    GList *plugins, *orig_plugins;
-    orig_plugins = plugins = gst_default_registry_get_plugin_list ();
-
-    while (plugins) {
-        GList *features, *orig_features;
-
-        GstPlugin *plugin = (GstPlugin *) (plugins->data);
-        plugins = g_list_next (plugins);
-
-        if (plugin->flags & (1<<1)) //GST_PLUGIN_FLAG_BLACKLISTED
-            continue;
-
-        orig_features = features = gst_registry_get_feature_list_by_plugin(gst_registry_get_default (),
-                                                                        plugin->desc.name);
-        while (features) {
-            if (!G_UNLIKELY(features->data == NULL)) {
-                GstPluginFeature *feature = GST_PLUGIN_FEATURE(features->data);
-                if (GST_IS_ELEMENT_FACTORY (feature)) {
-                    GstElementFactory *factory = GST_ELEMENT_FACTORY(gst_plugin_feature_load(feature));
-                    if (factory
-                       && factory->numpadtemplates > 0
-                       && (qstrcmp(factory->details.klass, "Codec/Decoder/Audio") == 0
-                          || qstrcmp(factory->details.klass, "Codec/Demux") == 0 )) {
-                        const GList *pads = factory->staticpadtemplates;
-                        while (pads) {
-                            GstStaticPadTemplate *padtemplate = (GstStaticPadTemplate*)(pads->data);
-                            pads = g_list_next (pads);
-                            if (padtemplate->direction != GST_PAD_SINK)
-                                continue;
-                            if (padtemplate->static_caps.string) {
-                                GstCaps *caps = gst_static_caps_get(&padtemplate->static_caps);
-                                if (!gst_caps_is_any (caps) && ! gst_caps_is_empty (caps)) {
-                                    for (guint i = 0; i < gst_caps_get_size(caps); i++) {
-                                        GstStructure *structure = gst_caps_get_structure(caps, i);
-                                        QString nameLowcase = QString(gst_structure_get_name (structure)).toLower();
-
-                                        m_supportedMimeTypeSet.insert(nameLowcase);
-                                        if (nameLowcase.contains("mpeg")) {
-                                            //Because mpeg version number is only included in the detail
-                                            //description,  it is necessary to manually extract this information
-                                            //in order to match the mime type of mpeg4.
-                                            const GValue *value = gst_structure_get_value(structure, "mpegversion");
-                                            if (value) {
-                                                gchar *str = gst_value_serialize (value);
-                                                QString versions(str);
-                                                QStringList elements = versions.split(QRegExp("\\D+"), QString::SkipEmptyParts);
-                                                foreach (const QString &e, elements)
-                                                    m_supportedMimeTypeSet.insert(nameLowcase + e);
-                                                g_free (str);
-                                            }
-                                        }
-                                    }
-                                }
-                                gst_caps_unref(caps);
-                            }
-                        }
-                        gst_object_unref (factory);
-                    }
-                } else if (GST_IS_TYPE_FIND_FACTORY(feature)) {
-                    QString name(gst_plugin_feature_get_name(feature));
-                    if (name.contains('/')) //filter out any string without '/' which is obviously not a mime type
-                        m_supportedMimeTypeSet.insert(name.toLower());
-                }
-            }
-            features = g_list_next (features);
-        }
-        gst_plugin_feature_list_free (orig_features);
-    }
-    gst_plugin_list_free (orig_plugins);
+    return gst_element_factory_list_is_type(factory, GST_ELEMENT_FACTORY_TYPE_DEMUXER)
+                || gst_element_factory_list_is_type(factory, GST_ELEMENT_FACTORY_TYPE_DECODER
+                            | GST_ELEMENT_FACTORY_TYPE_MEDIA_AUDIO);
+}
 
-#if defined QT_SUPPORTEDMIMETYPES_DEBUG
-    QStringList list = m_supportedMimeTypeSet.toList();
-    list.sort();
-    if (qgetenv("QT_DEBUG_PLUGINS").toInt() > 0) {
-        foreach (const QString &type, list)
-            qDebug() << type;
-    }
-#endif
+void QGstreamerAudioDecoderServicePlugin::updateSupportedMimeTypes() const
+{
+    m_supportedMimeTypeSet = QGstUtils::supportedMimeTypes(isDecoderOrDemuxer);
 }
 
 QStringList QGstreamerAudioDecoderServicePlugin::supportedMimeTypes() const
diff --git a/src/plugins/gstreamer/audiodecoder/qgstreameraudiodecodersession.cpp b/src/plugins/gstreamer/audiodecoder/qgstreameraudiodecodersession.cpp
index 9f1a765..321f550 100644
--- a/src/plugins/gstreamer/audiodecoder/qgstreameraudiodecodersession.cpp
+++ b/src/plugins/gstreamer/audiodecoder/qgstreameraudiodecodersession.cpp
@@ -93,7 +93,7 @@ QGstreamerAudioDecoderSession::QGstreamerAudioDecoderSession(QObject *parent)
      m_durationQueries(0)
 {
     // Create pipeline here
-    m_playbin = gst_element_factory_make("playbin2", NULL);
+    m_playbin = gst_element_factory_make(QT_GSTREAMER_PLAYBIN_ELEMENT_NAME, NULL);
 
     if (m_playbin != 0) {
         // Sort out messages
@@ -454,21 +454,40 @@ QAudioBuffer QGstreamerAudioDecoderSession::read()
         if (buffersAvailable == 1)
             emit bufferAvailableChanged(false);
 
+        const char* bufferData = 0;
+        int bufferSize = 0;
+
+#if GST_CHECK_VERSION(1,0,0)
+        GstSample *sample = gst_app_sink_pull_sample(m_appSink);
+        GstBuffer *buffer = gst_sample_get_buffer(sample);
+        GstMapInfo mapInfo;
+        gst_buffer_map(buffer, &mapInfo, GST_MAP_READ);
+        bufferData = (const char*)mapInfo.data;
+        bufferSize = mapInfo.size;
+        QAudioFormat format = QGstUtils::audioFormatForSample(sample);
+#else
         GstBuffer *buffer = gst_app_sink_pull_buffer(m_appSink);
-
+        bufferData = (const char*)buffer->data;
+        bufferSize = buffer->size;
         QAudioFormat format = QGstUtils::audioFormatForBuffer(buffer);
+#endif
+
         if (format.isValid()) {
             // XXX At the moment we have to copy data from GstBuffer into QAudioBuffer.
             // We could improve performance by implementing QAbstractAudioBuffer for GstBuffer.
             qint64 position = getPositionFromBuffer(buffer);
-            audioBuffer = QAudioBuffer(QByteArray((const char*)buffer->data, buffer->size), format, position);
+            audioBuffer = QAudioBuffer(QByteArray((const char*)bufferData, bufferSize), format, position);
             position /= 1000; // convert to milliseconds
             if (position != m_position) {
                 m_position = position;
                 emit positionChanged(m_position);
             }
         }
+#if GST_CHECK_VERSION(1,0,0)
+        gst_sample_unref(sample);
+#else
         gst_buffer_unref(buffer);
+#endif
     }
 
     return audioBuffer;
@@ -496,7 +515,7 @@ void QGstreamerAudioDecoderSession::processInvalidMedia(QAudioDecoder::Error err
     emit error(int(errorCode), errorString);
 }
 
-GstFlowReturn QGstreamerAudioDecoderSession::new_buffer(GstAppSink *, gpointer user_data)
+GstFlowReturn QGstreamerAudioDecoderSession::new_sample(GstAppSink *, gpointer user_data)
 {
     // "Note that the preroll buffer will also be returned as the first buffer when calling gst_app_sink_pull_buffer()."
     QGstreamerAudioDecoderSession *session = reinterpret_cast<QGstreamerAudioDecoderSession*>(user_data);
@@ -539,7 +558,11 @@ void QGstreamerAudioDecoderSession::addAppSink()
 
     GstAppSinkCallbacks callbacks;
     memset(&callbacks, 0, sizeof(callbacks));
-    callbacks.new_buffer = &new_buffer;
+#if GST_CHECK_VERSION(1,0,0)
+    callbacks.new_sample = &new_sample;
+#else
+    callbacks.new_buffer = &new_sample;
+#endif
     gst_app_sink_set_callbacks(m_appSink, &callbacks, this, NULL);
     gst_app_sink_set_max_buffers(m_appSink, MAX_BUFFERS_IN_QUEUE);
     gst_base_sink_set_sync(GST_BASE_SINK(m_appSink), FALSE);
@@ -561,11 +584,10 @@ void QGstreamerAudioDecoderSession::removeAppSink()
 
 void QGstreamerAudioDecoderSession::updateDuration()
 {
-    GstFormat format = GST_FORMAT_TIME;
     gint64 gstDuration = 0;
     int duration = -1;
 
-    if (m_playbin && gst_element_query_duration(m_playbin, &format, &gstDuration))
+    if (m_playbin && qt_gst_element_query_duration(m_playbin, GST_FORMAT_TIME, &gstDuration))
         duration = gstDuration / 1000000;
 
     if (m_duration != duration) {
diff --git a/src/plugins/gstreamer/audiodecoder/qgstreameraudiodecodersession.h b/src/plugins/gstreamer/audiodecoder/qgstreameraudiodecodersession.h
index 5ee76a0..cc42f4d 100644
--- a/src/plugins/gstreamer/audiodecoder/qgstreameraudiodecodersession.h
+++ b/src/plugins/gstreamer/audiodecoder/qgstreameraudiodecodersession.h
@@ -100,7 +100,7 @@ public:
     qint64 position() const;
     qint64 duration() const;
 
-    static GstFlowReturn new_buffer(GstAppSink *sink, gpointer user_data);
+    static GstFlowReturn new_sample(GstAppSink *sink, gpointer user_data);
 
 signals:
     void stateChanged(QAudioDecoder::State newState);
diff --git a/src/plugins/gstreamer/camerabin/camerabin.pro b/src/plugins/gstreamer/camerabin/camerabin.pro
index 9efa081..64fee3e 100644
--- a/src/plugins/gstreamer/camerabin/camerabin.pro
+++ b/src/plugins/gstreamer/camerabin/camerabin.pro
@@ -30,7 +30,8 @@ HEADERS += \
     $$PWD/camerabinresourcepolicy.h \
     $$PWD/camerabincapturedestination.h \
     $$PWD/camerabincapturebufferformat.h \
-    $$PWD/camerabinviewfindersettings.h
+    $$PWD/camerabinviewfindersettings.h \
+    $$PWD/camerabininfocontrol.h
 
 SOURCES += \
     $$PWD/camerabinserviceplugin.cpp \
@@ -48,7 +49,8 @@ SOURCES += \
     $$PWD/camerabinresourcepolicy.cpp \
     $$PWD/camerabincapturedestination.cpp \
     $$PWD/camerabinviewfindersettings.cpp \
-    $$PWD/camerabincapturebufferformat.cpp
+    $$PWD/camerabincapturebufferformat.cpp \
+    $$PWD/camerabininfocontrol.cpp
 
 maemo6 {
     HEADERS += \
@@ -77,7 +79,7 @@ config_gstreamer_photography {
         $$PWD/camerabinlocks.cpp \
         $$PWD/camerabinzoom.cpp
 
-    LIBS += -lgstphotography-0.10
+    LIBS += -lgstphotography-$$GST_VERSION
     DEFINES += GST_USE_UNSTABLE_API #prevents warnings because of unstable photography API
 }
 
diff --git a/src/plugins/gstreamer/camerabin/camerabincontainer.cpp b/src/plugins/gstreamer/camerabin/camerabincontainer.cpp
index 44eb368..401b7d9 100644
--- a/src/plugins/gstreamer/camerabin/camerabincontainer.cpp
+++ b/src/plugins/gstreamer/camerabin/camerabincontainer.cpp
@@ -104,7 +104,7 @@ GstEncodingContainerProfile *CameraBinContainer::createProfile()
     GstCaps *caps;
 
     if (m_actualFormat.isEmpty()) {
-        caps = gst_caps_new_any();
+        return 0;
     } else {
         QString format = m_actualFormat;
         QStringList supportedFormats = m_supportedContainers.supportedCodecs();
diff --git a/src/plugins/gstreamer/camerabin/camerabincontrol.cpp b/src/plugins/gstreamer/camerabin/camerabincontrol.cpp
index 2ba9b07..7814165 100644
--- a/src/plugins/gstreamer/camerabin/camerabincontrol.cpp
+++ b/src/plugins/gstreamer/camerabin/camerabincontrol.cpp
@@ -103,7 +103,7 @@ void CameraBinControl::setCaptureMode(QCamera::CaptureModes mode)
                         captureMode() == QCamera::CaptureStillImage ?
                             CamerabinResourcePolicy::ImageCaptureResources :
                             CamerabinResourcePolicy::VideoCaptureResources);
-#if (GST_VERSION_MAJOR == 0) && ((GST_VERSION_MINOR < 10) || (GST_VERSION_MICRO < 23))
+#if !GST_CHECK_VERSION(0,10,23)
             //due to bug in v4l2src, it's necessary to reload camera on video caps changes
             //https://bugzilla.gnome.org/show_bug.cgi?id=649832
             reloadLater();
diff --git a/src/plugins/gstreamer/camerabin/camerabinexposure.cpp b/src/plugins/gstreamer/camerabin/camerabinexposure.cpp
index cb9d10a..3e8da27 100644
--- a/src/plugins/gstreamer/camerabin/camerabinexposure.cpp
+++ b/src/plugins/gstreamer/camerabin/camerabinexposure.cpp
@@ -45,6 +45,10 @@
 
 #include <QDebug>
 
+#if !GST_CHECK_VERSION(1,0,0)
+typedef GstSceneMode GstPhotographySceneMode;
+#endif
+
 QT_BEGIN_NAMESPACE
 
 CameraBinExposure::CameraBinExposure(CameraBinSession *session)
@@ -127,7 +131,7 @@ QVariant CameraBinExposure::actualValue(ExposureParameter parameter) const
     }
     case QCameraExposureControl::ExposureMode:
     {
-        GstSceneMode sceneMode;
+        GstPhotographySceneMode sceneMode;
         gst_photography_get_scene_mode(m_session->photography(), &sceneMode);
 
         switch (sceneMode) {
@@ -175,7 +179,7 @@ bool CameraBinExposure::setValue(ExposureParameter parameter, const QVariant& va
     case QCameraExposureControl::ExposureMode:
     {
         QCameraExposure::ExposureMode mode = QCameraExposure::ExposureMode(value.toInt());
-        GstSceneMode sceneMode;
+        GstPhotographySceneMode sceneMode;
         gst_photography_get_scene_mode(m_session->photography(), &sceneMode);
 
         switch (mode) {
diff --git a/src/plugins/gstreamer/camerabin/camerabinflash.cpp b/src/plugins/gstreamer/camerabin/camerabinflash.cpp
index 9c1fb88..3da206c 100644
--- a/src/plugins/gstreamer/camerabin/camerabinflash.cpp
+++ b/src/plugins/gstreamer/camerabin/camerabinflash.cpp
@@ -45,6 +45,10 @@
 
 #include <QDebug>
 
+#if !GST_CHECK_VERSION(1,0,0)
+typedef GstFlashMode GstPhotographyFlashMode;
+#endif
+
 QT_BEGIN_NAMESPACE
 
 CameraBinFlash::CameraBinFlash(CameraBinSession *session)
@@ -59,7 +63,7 @@ CameraBinFlash::~CameraBinFlash()
 
 QCameraExposure::FlashModes CameraBinFlash::flashMode() const
 {
-    GstFlashMode flashMode;
+    GstPhotographyFlashMode flashMode;
     gst_photography_get_flash_mode(m_session->photography(), &flashMode);
 
     QCameraExposure::FlashModes modes;
@@ -78,7 +82,7 @@ QCameraExposure::FlashModes CameraBinFlash::flashMode() const
 
 void CameraBinFlash::setFlashMode(QCameraExposure::FlashModes mode)
 {
-    GstFlashMode flashMode;
+    GstPhotographyFlashMode flashMode;
     gst_photography_get_flash_mode(m_session->photography(), &flashMode);
 
     if (mode.testFlag(QCameraExposure::FlashAuto)) flashMode = GST_PHOTOGRAPHY_FLASH_MODE_AUTO;
diff --git a/src/plugins/gstreamer/camerabin/camerabinfocus.cpp b/src/plugins/gstreamer/camerabin/camerabinfocus.cpp
index ed5b483..949bfb8 100644
--- a/src/plugins/gstreamer/camerabin/camerabinfocus.cpp
+++ b/src/plugins/gstreamer/camerabin/camerabinfocus.cpp
@@ -47,6 +47,12 @@
 #include <QDebug>
 #include <QtCore/qmetaobject.h>
 
+#include <private/qgstutils_p.h>
+
+#if !GST_CHECK_VERSION(1,0,0)
+typedef GstFocusMode GstPhotographyFocusMode;
+#endif
+
 //#define CAMERABIN_DEBUG 1
 
 QT_BEGIN_NAMESPACE
@@ -54,10 +60,16 @@ QT_BEGIN_NAMESPACE
 CameraBinFocus::CameraBinFocus(CameraBinSession *session)
     :QCameraFocusControl(session),
      m_session(session),
+     m_cameraState(QCamera::UnloadedState),
      m_focusMode(QCameraFocus::AutoFocus),
+     m_focusPointMode(QCameraFocus::FocusPointAuto),
      m_focusStatus(QCamera::Unlocked),
-     m_focusZoneStatus(QCameraFocusZone::Selected)
+     m_focusZoneStatus(QCameraFocusZone::Selected),
+     m_focusPoint(0.5, 0.5),
+     m_focusRect(0, 0, 0.3, 0.3)
 {
+    m_focusRect.moveCenter(m_focusPoint);
+
     gst_photography_set_focus_mode(m_session->photography(), GST_PHOTOGRAPHY_FOCUS_MODE_AUTO);
 
     connect(m_session, SIGNAL(stateChanged(QCamera::State)),
@@ -75,7 +87,7 @@ QCameraFocus::FocusModes CameraBinFocus::focusMode() const
 
 void CameraBinFocus::setFocusMode(QCameraFocus::FocusModes mode)
 {
-    GstFocusMode photographyMode;
+    GstPhotographyFocusMode photographyMode;
 
     switch (mode) {
     case QCameraFocus::AutoFocus:
@@ -122,41 +134,71 @@ bool CameraBinFocus::isFocusModeSupported(QCameraFocus::FocusModes mode) const
 
 QCameraFocus::FocusPointMode CameraBinFocus::focusPointMode() const
 {
-    return QCameraFocus::FocusPointAuto;
+    return m_focusPointMode;
 }
 
 void CameraBinFocus::setFocusPointMode(QCameraFocus::FocusPointMode mode)
 {
     Q_UNUSED(mode);
+    if (m_focusPointMode != mode
+            && (mode == QCameraFocus::FocusPointAuto || mode == QCameraFocus::FocusPointCustom)) {
+        m_focusPointMode = mode;
+
+        if (m_focusPointMode == QCameraFocus::FocusPointAuto)
+            resetFocusPoint();
+
+        emit focusPointModeChanged(m_focusPointMode);
+
+    }
 }
 
 bool CameraBinFocus::isFocusPointModeSupported(QCameraFocus::FocusPointMode mode) const
 {
-    return mode == QCameraFocus::FocusPointAuto;
+    return mode == QCameraFocus::FocusPointAuto || mode == QCameraFocus::FocusPointCustom;
 }
 
 QPointF CameraBinFocus::customFocusPoint() const
 {
-    return QPointF(0.5, 0.5);
+    return m_focusPoint;
 }
 
 void CameraBinFocus::setCustomFocusPoint(const QPointF &point)
 {
-    Q_UNUSED(point);
+    if (m_focusPoint != point) {
+        m_focusPoint = point;
+
+        // Bound the focus point so the focus rect remains entirely within the unit square.
+        m_focusPoint.setX(qBound(m_focusRect.width() / 2, m_focusPoint.x(), 1 - m_focusRect.width() / 2));
+        m_focusPoint.setY(qBound(m_focusRect.height() / 2, m_focusPoint.y(), 1 - m_focusRect.height() / 2));
+
+        if (m_focusPointMode == QCameraFocus::FocusPointCustom) {
+            const QRectF focusRect = m_focusRect;
+            m_focusRect.moveCenter(m_focusPoint);
+
+            updateRegionOfInterest(m_focusRect, 1);
+
+            if (focusRect != m_focusRect) {
+                emit focusZonesChanged();
+            }
+        }
+
+        emit customFocusPointChanged(m_focusPoint);
+    }
 }
 
 QCameraFocusZoneList CameraBinFocus::focusZones() const
 {
-    return QCameraFocusZoneList() << QCameraFocusZone(QRectF(0.35, 0.35, 0.3, 0.3), m_focusZoneStatus);
+    return QCameraFocusZoneList() << QCameraFocusZone(m_focusRect, m_focusZoneStatus);
 }
 
 
 void CameraBinFocus::handleFocusMessage(GstMessage *gm)
 {
     //it's a sync message, so it's called from non main thread
-    if (gst_structure_has_name(gm->structure, GST_PHOTOGRAPHY_AUTOFOCUS_DONE)) {
+    const GstStructure *structure = gst_message_get_structure(gm);
+    if (gst_structure_has_name(structure, GST_PHOTOGRAPHY_AUTOFOCUS_DONE)) {
         gint status = GST_PHOTOGRAPHY_FOCUS_STATUS_NONE;
-        gst_structure_get_int (gm->structure, "status", &status);
+        gst_structure_get_int (structure, "status", &status);
         QCamera::LockStatus focusStatus = m_focusStatus;
         QCamera::LockChangeReason reason = QCamera::UserRequest;
 
@@ -213,8 +255,29 @@ void CameraBinFocus::_q_setFocusStatus(QCamera::LockStatus status, QCamera::Lock
 
 void CameraBinFocus::_q_handleCameraStateChange(QCamera::State state)
 {
-    if (state != QCamera::ActiveState)
+    m_cameraState = state;
+    if (state == QCamera::ActiveState) {
+        if (GstPad *pad = gst_element_get_static_pad(m_session->cameraSource(), "vfsrc")) {
+            if (GstCaps *caps = qt_gst_pad_get_current_caps(pad)) {
+                if (GstStructure *structure = gst_caps_get_structure(caps, 0)) {
+                    int width = 0;
+                    int height = 0;
+                    gst_structure_get_int(structure, "width", &width);
+                    gst_structure_get_int(structure, "height", &height);
+                    setViewfinderResolution(QSize(width, height));
+                }
+                gst_caps_unref(caps);
+            }
+            gst_object_unref(GST_OBJECT(pad));
+        }
+        if (m_focusPointMode == QCameraFocus::FocusPointCustom) {
+                updateRegionOfInterest(m_focusRect, 1);
+        }
+    } else {
         _q_setFocusStatus(QCamera::Unlocked, QCamera::LockLost);
+
+        resetFocusPoint();
+    }
 }
 
 void CameraBinFocus::_q_startFocusing()
@@ -229,4 +292,70 @@ void CameraBinFocus::_q_stopFocusing()
     _q_setFocusStatus(QCamera::Unlocked, QCamera::UserRequest);
 }
 
+void CameraBinFocus::setViewfinderResolution(const QSize &resolution)
+{
+    if (resolution != m_viewfinderResolution) {
+        m_viewfinderResolution = resolution;
+        if (!resolution.isEmpty()) {
+            const QPointF center = m_focusRect.center();
+            m_focusRect.setWidth(m_focusRect.height() * resolution.height() / resolution.width());
+            m_focusRect.moveCenter(center);
+        }
+    }
+}
+
+void CameraBinFocus::resetFocusPoint()
+{
+    const QRectF focusRect = m_focusRect;
+    m_focusPoint = QPointF(0.5, 0.5);
+    m_focusRect.moveCenter(m_focusPoint);
+
+    updateRegionOfInterest(QRectF(0, 0, 0, 0), 0);
+
+    if (focusRect != m_focusRect) {
+        emit customFocusPointChanged(m_focusPoint);
+        emit focusZonesChanged();
+    }
+}
+
+void CameraBinFocus::updateRegionOfInterest(const QRectF &focusRect, int priority)
+{
+    if (m_cameraState != QCamera::ActiveState)
+        return;
+
+    GstElement * const cameraSource = m_session->cameraSource();
+    if (!cameraSource)
+        return;
+
+    GstStructure *region = gst_structure_new(
+                "region",
+                "region-x"        , G_TYPE_UINT , uint(m_viewfinderResolution.width()  * focusRect.x()),
+                "region-y"        , G_TYPE_UINT,  uint(m_viewfinderResolution.height() * focusRect.y()),
+                "region-w"        , G_TYPE_UINT , uint(m_viewfinderResolution.width()  * focusRect.width()),
+                "region-h"        , G_TYPE_UINT,  uint(m_viewfinderResolution.height() * focusRect.height()),
+                "region-priority" , G_TYPE_UINT,  priority,
+                NULL);
+
+    GValue regionValue = G_VALUE_INIT;
+    g_value_init(&regionValue, GST_TYPE_STRUCTURE);
+    gst_value_set_structure(&regionValue, region);
+    gst_structure_free(region);
+
+    GValue regions = G_VALUE_INIT;
+    g_value_init(&regions, GST_TYPE_LIST);
+    gst_value_list_append_value(&regions, &regionValue);
+    g_value_unset(&regionValue);
+
+    GstStructure *regionsOfInterest = gst_structure_new(
+                "regions-of-interest",
+                "frame-width"     , G_TYPE_UINT , m_viewfinderResolution.width(),
+                "frame-height"    , G_TYPE_UINT,  m_viewfinderResolution.height(),
+                NULL);
+    gst_structure_set_value(regionsOfInterest, "regions", &regions);
+    g_value_unset(&regions);
+
+    GstEvent *event = gst_event_new_custom(GST_EVENT_CUSTOM_UPSTREAM, regionsOfInterest);
+    gst_element_send_event(cameraSource, event);
+}
+
 QT_END_NAMESPACE
diff --git a/src/plugins/gstreamer/camerabin/camerabinfocus.h b/src/plugins/gstreamer/camerabin/camerabinfocus.h
index e1f4dcd..45ca7fc 100644
--- a/src/plugins/gstreamer/camerabin/camerabinfocus.h
+++ b/src/plugins/gstreamer/camerabin/camerabinfocus.h
@@ -82,15 +82,25 @@ public Q_SLOTS:
     void _q_startFocusing();
     void _q_stopFocusing();
 
+    void setViewfinderResolution(const QSize &resolution);
+
 private Q_SLOTS:
     void _q_setFocusStatus(QCamera::LockStatus status, QCamera::LockChangeReason reason);
     void _q_handleCameraStateChange(QCamera::State state);
 
 private:
+    void resetFocusPoint();
+    void updateRegionOfInterest(const QRectF &focusRect, int priority);
+
     CameraBinSession *m_session;
+    QCamera::State m_cameraState;
     QCameraFocus::FocusModes m_focusMode;
+    QCameraFocus::FocusPointMode m_focusPointMode;
     QCamera::LockStatus m_focusStatus;
     QCameraFocusZone::FocusZoneStatus m_focusZoneStatus;
+    QPointF m_focusPoint;
+    QRectF m_focusRect;
+    QSize m_viewfinderResolution;
 };
 
 QT_END_NAMESPACE
diff --git a/src/plugins/gstreamer/camerabin/camerabinimagecapture.cpp b/src/plugins/gstreamer/camerabin/camerabinimagecapture.cpp
index 122a10e..e8dbe14 100644
--- a/src/plugins/gstreamer/camerabin/camerabinimagecapture.cpp
+++ b/src/plugins/gstreamer/camerabin/camerabinimagecapture.cpp
@@ -61,11 +61,13 @@ QT_BEGIN_NAMESPACE
 
 CameraBinImageCapture::CameraBinImageCapture(CameraBinSession *session)
     :QCameraImageCaptureControl(session)
+    , m_encoderProbe(this)
+    , m_muxerProbe(this)
     , m_session(session)
-    , m_ready(false)
-    , m_requestId(0)
     , m_jpegEncoderElement(0)
     , m_metadataMuxerElement(0)
+    , m_requestId(0)
+    , m_ready(false)
 {
     connect(m_session, SIGNAL(stateChanged(QCamera::State)), SLOT(updateState()));
     connect(m_session, SIGNAL(imageExposed(int)), this, SIGNAL(imageExposed(int)));
@@ -116,11 +118,18 @@ void CameraBinImageCapture::updateState()
     }
 }
 
-gboolean CameraBinImageCapture::metadataEventProbe(GstPad *pad, GstEvent *event, CameraBinImageCapture *self)
+#if GST_CHECK_VERSION(1,0,0)
+GstPadProbeReturn CameraBinImageCapture::encoderEventProbe(
+        GstPad *, GstPadProbeInfo *info, gpointer user_data)
 {
-    Q_UNUSED(pad);
-
-    if (GST_EVENT_TYPE(event) == GST_EVENT_TAG) {
+    GstEvent * const event = gst_pad_probe_info_get_event(info);
+#else
+gboolean CameraBinImageCapture::encoderEventProbe(
+        GstElement *, GstEvent *event, gpointer user_data)
+{
+#endif
+    CameraBinImageCapture  * const self = static_cast<CameraBinImageCapture *>(user_data);
+    if (event && GST_EVENT_TYPE(event) == GST_EVENT_TAG) {
         GstTagList *gstTags;
         gst_event_parse_tag(event, &gstTags);
         QMap<QByteArray, QVariant> extendedTags = QGstUtils::gstTagListToMap(gstTags);
@@ -154,17 +163,31 @@ gboolean CameraBinImageCapture::metadataEventProbe(GstPad *pad, GstEvent *event,
             }
         }
     }
+#if GST_CHECK_VERSION(1,0,0)
+    return GST_PAD_PROBE_OK;
+#else
+    return TRUE;
+#endif
+}
 
-    return true;
+void CameraBinImageCapture::EncoderProbe::probeCaps(GstCaps *caps)
+{
+#if GST_CHECK_VERSION(1,0,0)
+    capture->m_bufferFormat = QGstUtils::formatForCaps(caps, &capture->m_videoInfo);
+#else
+    int bytesPerLine = 0;
+    QVideoSurfaceFormat format = QGstUtils::formatForCaps(caps, &bytesPerLine);
+    capture->m_bytesPerLine = bytesPerLine;
+    capture->m_bufferFormat = format;
+#endif
 }
 
-gboolean CameraBinImageCapture::uncompressedBufferProbe(GstPad *pad, GstBuffer *buffer, CameraBinImageCapture *self)
+bool CameraBinImageCapture::EncoderProbe::probeBuffer(GstBuffer *buffer)
 {
-    Q_UNUSED(pad);
-    CameraBinSession *session = self->m_session;
+    CameraBinSession * const session = capture->m_session;
 
 #ifdef DEBUG_CAPTURE
-    qDebug() << "Uncompressed buffer probe" << gst_caps_to_string(GST_BUFFER_CAPS(buffer));
+    qDebug() << "Uncompressed buffer probe";
 #endif
 
     QCameraImageCapture::CaptureDestinations destination =
@@ -173,21 +196,23 @@ gboolean CameraBinImageCapture::uncompressedBufferProbe(GstPad *pad, GstBuffer *
 
     if (destination & QCameraImageCapture::CaptureToBuffer) {
         if (format != QVideoFrame::Format_Jpeg) {
-            GstCaps *caps = GST_BUFFER_CAPS(buffer);
-            int bytesPerLine = -1;
-            QVideoSurfaceFormat format = QVideoSurfaceGstSink::formatForCaps(caps, &bytesPerLine);
 #ifdef DEBUG_CAPTURE
             qDebug() << "imageAvailable(uncompressed):" << format;
 #endif
-            QGstVideoBuffer *videoBuffer = new QGstVideoBuffer(buffer, bytesPerLine);
+#if GST_CHECK_VERSION(1,0,0)
+            QGstVideoBuffer *videoBuffer = new QGstVideoBuffer(buffer, capture->m_videoInfo);
+#else
+            QGstVideoBuffer *videoBuffer = new QGstVideoBuffer(buffer, capture->m_bytesPerLine);
+#endif
 
-            QVideoFrame frame(videoBuffer,
-                              format.frameSize(),
-                              format.pixelFormat());
+            QVideoFrame frame(
+                        videoBuffer,
+                        capture->m_bufferFormat.frameSize(),
+                        capture->m_bufferFormat.pixelFormat());
 
-            QMetaObject::invokeMethod(self, "imageAvailable",
+            QMetaObject::invokeMethod(capture, "imageAvailable",
                                       Qt::QueuedConnection,
-                                      Q_ARG(int, self->m_requestId),
+                                      Q_ARG(int, capture->m_requestId),
                                       Q_ARG(QVideoFrame, frame));
         }
     }
@@ -200,25 +225,40 @@ gboolean CameraBinImageCapture::uncompressedBufferProbe(GstPad *pad, GstBuffer *
     return keepBuffer;
 }
 
-gboolean CameraBinImageCapture::jpegBufferProbe(GstPad *pad, GstBuffer *buffer, CameraBinImageCapture *self)
+void CameraBinImageCapture::MuxerProbe::probeCaps(GstCaps *caps)
 {
-    Q_UNUSED(pad);
-    CameraBinSession *session = self->m_session;
+    capture->m_jpegResolution = QGstUtils::capsCorrectedResolution(caps);
+}
 
-#ifdef DEBUG_CAPTURE
-    qDebug() << "Jpeg buffer probe" << gst_caps_to_string(GST_BUFFER_CAPS(buffer));
-#endif
+bool CameraBinImageCapture::MuxerProbe::probeBuffer(GstBuffer *buffer)
+{
+    CameraBinSession * const session = capture->m_session;
 
     QCameraImageCapture::CaptureDestinations destination =
             session->captureDestinationControl()->captureDestination();
 
     if ((destination & QCameraImageCapture::CaptureToBuffer) &&
          session->captureBufferFormatControl()->bufferFormat() == QVideoFrame::Format_Jpeg) {
-        QGstVideoBuffer *videoBuffer = new QGstVideoBuffer(buffer,
-                                                           -1); //bytesPerLine is not available for jpegs
 
-        QSize resolution = QGstUtils::capsCorrectedResolution(GST_BUFFER_CAPS(buffer));
+        QSize resolution = capture->m_jpegResolution;
         //if resolution is not presented in caps, try to find it from encoded jpeg data:
+#if GST_CHECK_VERSION(1,0,0)
+        GstMapInfo mapInfo;
+        if (resolution.isEmpty() && gst_buffer_map(buffer, &mapInfo, GST_MAP_READ)) {
+            QBuffer data;
+            data.setData(reinterpret_cast<const char*>(mapInfo.data), mapInfo.size);
+
+            QImageReader reader(&data, "JPEG");
+            resolution = reader.size();
+
+            gst_buffer_unmap(buffer, &mapInfo);
+        }
+
+        GstVideoInfo info;
+        gst_video_info_set_format(
+                    &info, GST_VIDEO_FORMAT_ENCODED, resolution.width(), resolution.height());
+        QGstVideoBuffer *videoBuffer = new QGstVideoBuffer(buffer, info);
+#else
         if (resolution.isEmpty()) {
             QBuffer data;
             data.setData(reinterpret_cast<const char*>(GST_BUFFER_DATA(buffer)), GST_BUFFER_SIZE(buffer));
@@ -226,20 +266,28 @@ gboolean CameraBinImageCapture::jpegBufferProbe(GstPad *pad, GstBuffer *buffer,
             resolution = reader.size();
         }
 
+        QGstVideoBuffer *videoBuffer = new QGstVideoBuffer(buffer,
+                                                           -1); //bytesPerLine is not available for jpegs
+#endif
+
+
         QVideoFrame frame(videoBuffer,
                           resolution,
                           QVideoFrame::Format_Jpeg);
-
-        QMetaObject::invokeMethod(self, "imageAvailable",
+        QMetaObject::invokeMethod(capture, "imageAvailable",
                                   Qt::QueuedConnection,
-                                  Q_ARG(int, self->m_requestId),
+                                  Q_ARG(int, capture->m_requestId),
                                   Q_ARG(QVideoFrame, frame));
     }
 
-    //drop the buffer if capture to file was disabled
-    return destination & QCameraImageCapture::CaptureToFile;
+
+    // Theoretically we could drop the buffer here when don't want to capture to file but that
+    // prevents camerabin from recognizing that capture has been completed and returning
+    // to its idle state.
+    return true;
 }
 
+
 bool CameraBinImageCapture::processBusMessage(const QGstreamerMessage &message)
 {
     //Install metadata event and buffer probes
@@ -260,9 +308,10 @@ bool CameraBinImageCapture::processBusMessage(const QGstreamerMessage &message)
                 return false;
 
             QString elementName = QString::fromLatin1(gst_element_get_name(element));
+#if !GST_CHECK_VERSION(1,0,0)
             GstElementClass *elementClass = GST_ELEMENT_GET_CLASS(element);
             QString elementLongName = elementClass->details.longname;
-
+#endif
             if (elementName.contains("jpegenc") && element != m_jpegEncoderElement) {
                 m_jpegEncoderElement = element;
                 GstPad *sinkpad = gst_element_get_static_pad(element, "sink");
@@ -272,21 +321,23 @@ bool CameraBinImageCapture::processBusMessage(const QGstreamerMessage &message)
 #ifdef DEBUG_CAPTURE
                 qDebug() << "install metadata probe";
 #endif
-                gst_pad_add_event_probe(sinkpad,
-                                        G_CALLBACK(CameraBinImageCapture::metadataEventProbe),
-                                        this);
-
+#if GST_CHECK_VERSION(1,0,0)
+                gst_pad_add_probe(
+                            sinkpad, GST_PAD_PROBE_TYPE_EVENT_DOWNSTREAM, encoderEventProbe, this, NULL);
+#else
+                gst_pad_add_event_probe(sinkpad, G_CALLBACK(encoderEventProbe), this);
+#endif
 #ifdef DEBUG_CAPTURE
                 qDebug() << "install uncompressed buffer probe";
 #endif
-                gst_pad_add_buffer_probe(sinkpad,
-                                         G_CALLBACK(CameraBinImageCapture::uncompressedBufferProbe),
-                                         this);
+                m_encoderProbe.addProbeToPad(sinkpad, true);
 
                 gst_object_unref(sinkpad);
-            } else if ((elementName.contains("jifmux") ||
-                        elementName.startsWith("metadatamux") ||
-                        elementLongName == QLatin1String("JPEG stream muxer"))
+            } else if ((elementName.contains("jifmux")
+#if !GST_CHECK_VERSION(1,0,0)
+                        || elementLongName == QLatin1String("JPEG stream muxer")
+#endif
+                        || elementName.startsWith("metadatamux"))
                        && element != m_metadataMuxerElement) {
                 //Jpeg encoded buffer probe is added after jifmux/metadatamux
                 //element to ensure the resulting jpeg buffer contains capture metadata
@@ -296,9 +347,8 @@ bool CameraBinImageCapture::processBusMessage(const QGstreamerMessage &message)
 #ifdef DEBUG_CAPTURE
                 qDebug() << "install jpeg buffer probe";
 #endif
-                gst_pad_add_buffer_probe(srcpad,
-                                         G_CALLBACK(CameraBinImageCapture::jpegBufferProbe),
-                                         this);
+                m_muxerProbe.addProbeToPad(srcpad);
+
                 gst_object_unref(srcpad);
             }
         }
diff --git a/src/plugins/gstreamer/camerabin/camerabinimagecapture.h b/src/plugins/gstreamer/camerabin/camerabinimagecapture.h
index 0ad0a8c..7f8eb91 100644
--- a/src/plugins/gstreamer/camerabin/camerabinimagecapture.h
+++ b/src/plugins/gstreamer/camerabin/camerabinimagecapture.h
@@ -46,6 +46,10 @@
 #include <qcameraimagecapturecontrol.h>
 #include "camerabinsession.h"
 
+#include <qvideosurfaceformat.h>
+
+#include <private/qgstreamerbufferprobe_p.h>
+
 QT_BEGIN_NAMESPACE
 
 class CameraBinImageCapture : public QCameraImageCaptureControl, public QGstreamerBusMessageFilter
@@ -69,15 +73,47 @@ private slots:
     void updateState();
 
 private:
-    static gboolean metadataEventProbe(GstPad *pad, GstEvent *event, CameraBinImageCapture *);
-    static gboolean uncompressedBufferProbe(GstPad *pad, GstBuffer *buffer, CameraBinImageCapture *);
-    static gboolean jpegBufferProbe(GstPad *pad, GstBuffer *buffer, CameraBinImageCapture *);
+#if GST_CHECK_VERSION(1,0,0)
+    static GstPadProbeReturn encoderEventProbe(GstPad *, GstPadProbeInfo *info, gpointer user_data);
+#else
+    static gboolean encoderEventProbe(GstElement *, GstEvent *event, gpointer user_data);
+#endif
+
+    class EncoderProbe : public QGstreamerBufferProbe
+    {
+    public:
+        EncoderProbe(CameraBinImageCapture *capture) : capture(capture) {}
+        void probeCaps(GstCaps *caps);
+        bool probeBuffer(GstBuffer *buffer);
+
+    private:
+        CameraBinImageCapture * const capture;
+    } m_encoderProbe;
+
+    class MuxerProbe : public QGstreamerBufferProbe
+    {
+    public:
+        MuxerProbe(CameraBinImageCapture *capture) : capture(capture) {}
+        void probeCaps(GstCaps *caps);
+        bool probeBuffer(GstBuffer *buffer);
+
+    private:
+        CameraBinImageCapture * const capture;
 
+    } m_muxerProbe;
+
+    QVideoSurfaceFormat m_bufferFormat;
+    QSize m_jpegResolution;
     CameraBinSession *m_session;
-    bool m_ready;
-    int m_requestId;
     GstElement *m_jpegEncoderElement;
     GstElement *m_metadataMuxerElement;
+#if GST_CHECK_VERSION(1,0,0)
+    GstVideoInfo m_videoInfo;
+#else
+    int m_bytesPerLine;
+#endif
+    int m_requestId;
+    bool m_ready;
 };
 
 QT_END_NAMESPACE
diff --git a/src/plugins/gstreamer/camerabin/camerabinimageprocessing.cpp b/src/plugins/gstreamer/camerabin/camerabinimageprocessing.cpp
index fb98020..e9d63d3 100644
--- a/src/plugins/gstreamer/camerabin/camerabinimageprocessing.cpp
+++ b/src/plugins/gstreamer/camerabin/camerabinimageprocessing.cpp
@@ -42,7 +42,11 @@
 #include "camerabinimageprocessing.h"
 #include "camerabinsession.h"
 
-#include <gst/interfaces/colorbalance.h>
+#if GST_CHECK_VERSION(1,0,0)
+# include <gst/video/colorbalance.h>
+#else
+# include <gst/interfaces/colorbalance.h>
+#endif
 
 QT_BEGIN_NAMESPACE
 
@@ -134,7 +138,7 @@ bool CameraBinImageProcessing::setColorBalanceValue(const QString& channel, qrea
 QCameraImageProcessing::WhiteBalanceMode CameraBinImageProcessing::whiteBalanceMode() const
 {
 #ifdef HAVE_GST_PHOTOGRAPHY
-    GstWhiteBalanceMode wbMode;
+    GstPhotographyWhiteBalanceMode wbMode;
     gst_photography_get_white_balance_mode(m_session->photography(), &wbMode);
     return m_mappedWbValues[wbMode];
 #else
diff --git a/src/plugins/gstreamer/camerabin/camerabinimageprocessing.h b/src/plugins/gstreamer/camerabin/camerabinimageprocessing.h
index 519a58c..52e09d0 100644
--- a/src/plugins/gstreamer/camerabin/camerabinimageprocessing.h
+++ b/src/plugins/gstreamer/camerabin/camerabinimageprocessing.h
@@ -49,7 +49,10 @@
 #include <glib.h>
 
 #ifdef HAVE_GST_PHOTOGRAPHY
-#include <gst/interfaces/photography.h>
+# include <gst/interfaces/photography.h>
+# if !GST_CHECK_VERSION(1,0,0)
+typedef GstWhiteBalanceMode GstPhotographyWhiteBalanceMode;
+# endif
 #endif
 
 QT_BEGIN_NAMESPACE
@@ -81,7 +84,7 @@ private:
     CameraBinSession *m_session;
     QMap<QCameraImageProcessingControl::ProcessingParameter, int> m_values;
 #ifdef HAVE_GST_PHOTOGRAPHY
-    QMap<GstWhiteBalanceMode, QCameraImageProcessing::WhiteBalanceMode> m_mappedWbValues;
+    QMap<GstPhotographyWhiteBalanceMode, QCameraImageProcessing::WhiteBalanceMode> m_mappedWbValues;
 #endif
 };
 
diff --git a/src/plugins/gstreamer/camerabin/camerabininfocontrol.cpp b/src/plugins/gstreamer/camerabin/camerabininfocontrol.cpp
new file mode 100644
index 0000000..a3ee369
--- /dev/null
+++ b/src/plugins/gstreamer/camerabin/camerabininfocontrol.cpp
@@ -0,0 +1,71 @@
+/****************************************************************************
+**
+** Copyright (C) 2014 Jolla Ltd.
+** Contact: http://www.qt-project.org/legal
+**
+** This file is part of the Qt Toolkit.
+**
+** $QT_BEGIN_LICENSE:LGPL$
+** Commercial License Usage
+** Licensees holding valid commercial Qt licenses may use this file in
+** accordance with the commercial license agreement provided with the
+** Software or, alternatively, in accordance with the terms contained in
+** a written agreement between you and Digia.  For licensing terms and
+** conditions see http://qt.digia.com/licensing.  For further information
+** use the contact form at http://qt.digia.com/contact-us.
+**
+** GNU Lesser General Public License Usage
+** Alternatively, this file may be used under the terms of the GNU Lesser
+** General Public License version 2.1 as published by the Free Software
+** Foundation and appearing in the file LICENSE.LGPL included in the
+** packaging of this file.  Please review the following information to
+** ensure the GNU Lesser General Public License version 2.1 requirements
+** will be met: http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html.
+**
+** In addition, as a special exception, Digia gives you certain additional
+** rights.  These rights are described in the Digia Qt LGPL Exception
+** version 1.1, included in the file LGPL_EXCEPTION.txt in this package.
+**
+** GNU General Public License Usage
+** Alternatively, this file may be used under the terms of the GNU
+** General Public License version 3.0 as published by the Free Software
+** Foundation and appearing in the file LICENSE.GPL included in the
+** packaging of this file.  Please review the following information to
+** ensure the GNU General Public License version 3.0 requirements will be
+** met: http://www.gnu.org/copyleft/gpl.html.
+**
+**
+** $QT_END_LICENSE$
+**
+****************************************************************************/
+
+
+#include "camerabininfocontrol.h"
+
+#include <private/qgstutils_p.h>
+
+QT_BEGIN_NAMESPACE
+
+CameraBinInfoControl::CameraBinInfoControl(GstElementFactory *sourceFactory, QObject *parent)
+    : QCameraInfoControl(parent)
+    , m_sourceFactory(sourceFactory)
+{
+    gst_object_ref(GST_OBJECT(m_sourceFactory));
+}
+
+CameraBinInfoControl::~CameraBinInfoControl()
+{
+    gst_object_unref(GST_OBJECT(m_sourceFactory));
+}
+
+QCamera::Position CameraBinInfoControl::cameraPosition(const QString &device) const
+{
+    return QGstUtils::cameraPosition(device, m_sourceFactory);
+}
+
+int CameraBinInfoControl::cameraOrientation(const QString &device) const
+{
+    return QGstUtils::cameraOrientation(device, m_sourceFactory);
+}
+
+QT_END_NAMESPACE
diff --git a/src/plugins/gstreamer/camerabin/camerabininfocontrol.h b/src/plugins/gstreamer/camerabin/camerabininfocontrol.h
new file mode 100644
index 0000000..577eb3f
--- /dev/null
+++ b/src/plugins/gstreamer/camerabin/camerabininfocontrol.h
@@ -0,0 +1,67 @@
+/****************************************************************************
+**
+** Copyright (C) 2014 Jolla Ltd.
+** Contact: http://www.qt-project.org/legal
+**
+** This file is part of the Qt Toolkit.
+**
+** $QT_BEGIN_LICENSE:LGPL$
+** Commercial License Usage
+** Licensees holding valid commercial Qt licenses may use this file in
+** accordance with the commercial license agreement provided with the
+** Software or, alternatively, in accordance with the terms contained in
+** a written agreement between you and Digia.  For licensing terms and
+** conditions see http://qt.digia.com/licensing.  For further information
+** use the contact form at http://qt.digia.com/contact-us.
+**
+** GNU Lesser General Public License Usage
+** Alternatively, this file may be used under the terms of the GNU Lesser
+** General Public License version 2.1 as published by the Free Software
+** Foundation and appearing in the file LICENSE.LGPL included in the
+** packaging of this file.  Please review the following information to
+** ensure the GNU Lesser General Public License version 2.1 requirements
+** will be met: http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html.
+**
+** In addition, as a special exception, Digia gives you certain additional
+** rights.  These rights are described in the Digia Qt LGPL Exception
+** version 1.1, included in the file LGPL_EXCEPTION.txt in this package.
+**
+** GNU General Public License Usage
+** Alternatively, this file may be used under the terms of the GNU
+** General Public License version 3.0 as published by the Free Software
+** Foundation and appearing in the file LICENSE.GPL included in the
+** packaging of this file.  Please review the following information to
+** ensure the GNU General Public License version 3.0 requirements will be
+** met: http://www.gnu.org/copyleft/gpl.html.
+**
+**
+** $QT_END_LICENSE$
+**
+****************************************************************************/
+
+#ifndef CAMERABININFOCONTROL_H
+#define CAMERABININFOCONTROL_H
+
+#include <qcamerainfocontrol.h>
+
+#include <gst/gst.h>
+
+QT_BEGIN_NAMESPACE
+
+class CameraBinInfoControl : public QCameraInfoControl
+{
+    Q_OBJECT
+public:
+    CameraBinInfoControl(GstElementFactory *sourceFactory, QObject *parent);
+    ~CameraBinInfoControl();
+
+    QCamera::Position cameraPosition(const QString &deviceName) const;
+    int cameraOrientation(const QString &deviceName) const;
+
+private:
+    GstElementFactory * const m_sourceFactory;
+};
+
+QT_END_NAMESPACE
+
+#endif
diff --git a/src/plugins/gstreamer/camerabin/camerabinmetadata.cpp b/src/plugins/gstreamer/camerabin/camerabinmetadata.cpp
index 170d25a..9a01787 100644
--- a/src/plugins/gstreamer/camerabin/camerabinmetadata.cpp
+++ b/src/plugins/gstreamer/camerabin/camerabinmetadata.cpp
@@ -134,7 +134,7 @@ static const QGStreamerMetaDataKeys *qt_gstreamerMetaDataKeys()
         metadataKeys->append(QGStreamerMetaDataKey(QMediaMetaData::AlbumTitle, GST_TAG_ALBUM, QVariant::String));
         metadataKeys->append(QGStreamerMetaDataKey(QMediaMetaData::AlbumArtist,  GST_TAG_ARTIST, QVariant::String));
         metadataKeys->append(QGStreamerMetaDataKey(QMediaMetaData::ContributingArtist, GST_TAG_PERFORMER, QVariant::String));
-#if (GST_VERSION_MAJOR >= 0) && (GST_VERSION_MINOR >= 10) && (GST_VERSION_MICRO >= 19)
+#if GST_CHECK_VERSION(0,10,19)
         metadataKeys->append(QGStreamerMetaDataKey(QMediaMetaData::Composer, GST_TAG_COMPOSER, QVariant::String));
 #endif
         //metadataKeys->append(QGStreamerMetaDataKey(QMediaMetaData::Conductor, 0, QVariant::String));
@@ -161,8 +161,7 @@ static const QGStreamerMetaDataKeys *qt_gstreamerMetaDataKeys()
         //metadataKeys->append(QGStreamerMetaDataKey(QMediaMetaData::Director, 0, QVariant::String));
         metadataKeys->append(QGStreamerMetaDataKey(QMediaMetaData::LeadPerformer, GST_TAG_PERFORMER, QVariant::String));
         //metadataKeys->append(QGStreamerMetaDataKey(QMediaMetaData::Writer, 0, QVariant::String));
-
-#if (GST_VERSION_MAJOR >= 0) && (GST_VERSION_MINOR >= 10) && (GST_VERSION_MICRO >= 30)
+#if GST_CHECK_VERSION(0,10,30)
         // Photos
         metadataKeys->append(QGStreamerMetaDataKey(QMediaMetaData::CameraManufacturer, GST_TAG_DEVICE_MANUFACTURER, QVariant::String));
         metadataKeys->append(QGStreamerMetaDataKey(QMediaMetaData::CameraModel, GST_TAG_DEVICE_MODEL, QVariant::String));
diff --git a/src/plugins/gstreamer/camerabin/camerabinrecorder.cpp b/src/plugins/gstreamer/camerabin/camerabinrecorder.cpp
index 7cef82a..ac892d6 100644
--- a/src/plugins/gstreamer/camerabin/camerabinrecorder.cpp
+++ b/src/plugins/gstreamer/camerabin/camerabinrecorder.cpp
@@ -118,9 +118,10 @@ void CameraBinRecorder::updateStatus()
             m_state = QMediaRecorder::StoppedState;
             m_session->stopVideoRecording();
         }
-        m_status = m_session->pendingState() == QCamera::ActiveState ?
-                    QMediaRecorder::LoadingStatus :
-                    QMediaRecorder::UnloadedStatus;
+        m_status = m_session->pendingState() == QCamera::ActiveState
+                    && m_session->captureMode().testFlag(QCamera::CaptureVideo)
+                ? QMediaRecorder::LoadingStatus
+                : QMediaRecorder::UnloadedStatus;
     }
 
     if (m_state != oldState)
@@ -169,8 +170,6 @@ void CameraBinRecorder::applySettings()
 
                 QVideoEncoderSettings videoSettings = videoEncoderControl->videoSettings();
                 videoSettings.setCodec(candidate[1]);
-                if (videoSettings.resolution().isEmpty())
-                    videoSettings.setResolution(640, 480);
                 videoEncoderControl->setActualVideoSettings(videoSettings);
 
                 QAudioEncoderSettings audioSettings = audioEncoderControl->audioSettings();
diff --git a/src/plugins/gstreamer/camerabin/camerabinservice.cpp b/src/plugins/gstreamer/camerabin/camerabinservice.cpp
index df02a9e..abf8798 100644
--- a/src/plugins/gstreamer/camerabin/camerabinservice.cpp
+++ b/src/plugins/gstreamer/camerabin/camerabinservice.cpp
@@ -48,6 +48,7 @@
 #include "camerabinimageencoder.h"
 #include "camerabincontrol.h"
 #include "camerabinmetadata.h"
+#include "camerabininfocontrol.h"
 
 #ifdef HAVE_GST_PHOTOGRAPHY
 #include "camerabinexposure.h"
@@ -63,11 +64,11 @@
 #include "camerabincapturedestination.h"
 #include "camerabinviewfindersettings.h"
 #include <private/qgstreamerbushelper_p.h>
+#include <private/qgstutils_p.h>
 
 #include <private/qgstreameraudioinputselector_p.h>
 #include <private/qgstreamervideoinputdevicecontrol_p.h>
 
-
 #if defined(HAVE_WIDGETS)
 #include <private/qgstreamervideowidget_p.h>
 #endif
@@ -89,8 +90,9 @@
 
 QT_BEGIN_NAMESPACE
 
-CameraBinService::CameraBinService(const QString &service, QObject *parent):
-    QMediaService(parent)
+CameraBinService::CameraBinService(GstElementFactory *sourceFactory, QObject *parent):
+    QMediaService(parent),
+    m_cameraInfoControl(0)
 {
     m_captureSession = 0;
     m_metaDataControl = 0;
@@ -106,40 +108,31 @@ CameraBinService::CameraBinService(const QString &service, QObject *parent):
 #endif
     m_imageCaptureControl = 0;
 
-    if (service == Q_MEDIASERVICE_CAMERA) {
-        m_captureSession = new CameraBinSession(this);
-        m_videoInputDevice = new QGstreamerVideoInputDeviceControl(
-                    m_captureSession->buildCameraSource(), m_captureSession);
-        m_imageCaptureControl = new CameraBinImageCapture(m_captureSession);
+    m_captureSession = new CameraBinSession(sourceFactory, this);
+    m_videoInputDevice = new QGstreamerVideoInputDeviceControl(sourceFactory, m_captureSession);
+    m_imageCaptureControl = new CameraBinImageCapture(m_captureSession);
 
-        connect(m_videoInputDevice, SIGNAL(selectedDeviceChanged(QString)),
-                m_captureSession, SLOT(setDevice(QString)));
+    connect(m_videoInputDevice, SIGNAL(selectedDeviceChanged(QString)),
+            m_captureSession, SLOT(setDevice(QString)));
 
-        if (m_videoInputDevice->deviceCount())
-            m_captureSession->setDevice(m_videoInputDevice->deviceName(m_videoInputDevice->selectedDevice()));
+    if (m_videoInputDevice->deviceCount())
+        m_captureSession->setDevice(m_videoInputDevice->deviceName(m_videoInputDevice->selectedDevice()));
 
 #if defined(Q_WS_MAEMO_6) && defined(__arm__) && defined(HAVE_WIDGETS)
-        m_videoRenderer = new QGstreamerGLTextureRenderer(this);
+    m_videoRenderer = new QGstreamerGLTextureRenderer(this);
 #else
-        m_videoRenderer = new QGstreamerVideoRenderer(this);
+    m_videoRenderer = new QGstreamerVideoRenderer(this);
 #endif
 
 #ifdef Q_WS_MAEMO_6
-        m_videoWindow = new QGstreamerVideoWindow(this, "omapxvsink");
+    m_videoWindow = new QGstreamerVideoWindow(this, "omapxvsink");
 #else
-        m_videoWindow = new QGstreamerVideoWindow(this);
+    m_videoWindow = new QGstreamerVideoWindow(this);
 #endif
-
 #if defined(HAVE_WIDGETS)
-        m_videoWidgetControl = new QGstreamerVideoWidgetControl(this);
+    m_videoWidgetControl = new QGstreamerVideoWidgetControl(this);
 #endif
 
-    }
-    if (!m_captureSession) {
-        qWarning() << Q_FUNC_INFO << "Service type is not supported:" << service;
-        return;
-    }
-
     m_audioInputSelector = new QGstreamerAudioInputSelector(this);
     connect(m_audioInputSelector, SIGNAL(activeInputChanged(QString)), m_captureSession, SLOT(setCaptureDevice(QString)));
 
@@ -244,6 +237,12 @@ QMediaControl *CameraBinService::requestControl(const char *name)
     if (qstrcmp(name, QCameraViewfinderSettingsControl_iid) == 0)
         return m_captureSession->viewfinderSettingsControl();
 
+    if (qstrcmp(name, QCameraInfoControl_iid) == 0) {
+        if (!m_cameraInfoControl)
+            m_cameraInfoControl = new CameraBinInfoControl(m_captureSession->sourceFactory(), this);
+        return m_cameraInfoControl;
+    }
+
     return 0;
 }
 
@@ -257,7 +256,7 @@ void CameraBinService::releaseControl(QMediaControl *control)
 
 bool CameraBinService::isCameraBinAvailable()
 {
-    GstElementFactory *factory = gst_element_factory_find("camerabin2");
+    GstElementFactory *factory = gst_element_factory_find(QT_GSTREAMER_CAMERABIN_ELEMENT_NAME);
     if (factory) {
         gst_object_unref(GST_OBJECT(factory));
         return true;
diff --git a/src/plugins/gstreamer/camerabin/camerabinservice.h b/src/plugins/gstreamer/camerabin/camerabinservice.h
index 7d3b3df..4dc0f40 100644
--- a/src/plugins/gstreamer/camerabin/camerabinservice.h
+++ b/src/plugins/gstreamer/camerabin/camerabinservice.h
@@ -67,7 +67,7 @@ class CameraBinService : public QMediaService
     Q_OBJECT
 
 public:
-    CameraBinService(const QString &service, QObject *parent = 0);
+    CameraBinService(GstElementFactory *sourceFactory, QObject *parent = 0);
     virtual ~CameraBinService();
 
     QMediaControl *requestControl(const char *name);
@@ -92,6 +92,7 @@ private:
     QGstreamerVideoWidgetControl *m_videoWidgetControl;
 #endif
     CameraBinImageCapture *m_imageCaptureControl;
+    QMediaControl *m_cameraInfoControl;
 };
 
 QT_END_NAMESPACE
diff --git a/src/plugins/gstreamer/camerabin/camerabinserviceplugin.cpp b/src/plugins/gstreamer/camerabin/camerabinserviceplugin.cpp
index 3decd60..bfb0c49 100644
--- a/src/plugins/gstreamer/camerabin/camerabinserviceplugin.cpp
+++ b/src/plugins/gstreamer/camerabin/camerabinserviceplugin.cpp
@@ -55,12 +55,25 @@
 
 QT_BEGIN_NAMESPACE
 
+template <typename T, int N> static int lengthOf(const T(&)[N]) { return N; }
+
+CameraBinServicePlugin::CameraBinServicePlugin()
+    : m_sourceFactory(0)
+{
+}
+
+CameraBinServicePlugin::~CameraBinServicePlugin()
+{
+    if (m_sourceFactory)
+        gst_object_unref(GST_OBJECT(m_sourceFactory));
+}
+
 QMediaService* CameraBinServicePlugin::create(const QString &key)
 {
     QGstUtils::initializeGst();
 
     if (key == QLatin1String(Q_MEDIASERVICE_CAMERA))
-        return new CameraBinService(key);
+        return new CameraBinService(sourceFactory());
 
     qWarning() << "Gstreamer camerabin service plugin: unsupported key:" << key;
     return 0;
@@ -82,40 +95,24 @@ QMediaServiceProviderHint::Features CameraBinServicePlugin::supportedFeatures(
 
 QByteArray CameraBinServicePlugin::defaultDevice(const QByteArray &service) const
 {
-    if (service == Q_MEDIASERVICE_CAMERA) {
-        if (m_cameraDevices.isEmpty())
-            updateDevices();
-
-        return m_defaultCameraDevice;
-    }
-
-    return QByteArray();
+    return service == Q_MEDIASERVICE_CAMERA
+            ? QGstUtils::enumerateCameras(sourceFactory()).value(0).name.toUtf8()
+            : QByteArray();
 }
 
 QList<QByteArray> CameraBinServicePlugin::devices(const QByteArray &service) const
 {
-    if (service == Q_MEDIASERVICE_CAMERA) {
-        if (m_cameraDevices.isEmpty())
-            updateDevices();
 
-        return m_cameraDevices;
-    }
-
-    return QList<QByteArray>();
+    return service == Q_MEDIASERVICE_CAMERA
+            ? QGstUtils::cameraDevices(m_sourceFactory)
+            : QList<QByteArray>();
 }
 
-QString CameraBinServicePlugin::deviceDescription(const QByteArray &service, const QByteArray &device)
+QString CameraBinServicePlugin::deviceDescription(const QByteArray &service, const QByteArray &deviceName)
 {
-    if (service == Q_MEDIASERVICE_CAMERA) {
-        if (m_cameraDevices.isEmpty())
-            updateDevices();
-
-        for (int i=0; i<m_cameraDevices.count(); i++)
-            if (m_cameraDevices[i] == device)
-                return m_cameraDescriptions[i];
-    }
-
-    return QString();
+    return service == Q_MEDIASERVICE_CAMERA
+            ? QGstUtils::cameraDescription(deviceName, m_sourceFactory)
+            : QString();
 }
 
 QVariant CameraBinServicePlugin::deviceProperty(const QByteArray &service, const QByteArray &device, const QByteArray &property)
@@ -126,53 +123,36 @@ QVariant CameraBinServicePlugin::deviceProperty(const QByteArray &service, const
     return QVariant();
 }
 
-void CameraBinServicePlugin::updateDevices() const
+QCamera::Position CameraBinServicePlugin::cameraPosition(const QByteArray &deviceName) const
 {
-    m_defaultCameraDevice.clear();
-    m_cameraDevices.clear();
-    m_cameraDescriptions.clear();
-
-    QDir devDir("/dev");
-    devDir.setFilter(QDir::System);
-
-    QFileInfoList entries = devDir.entryInfoList(QStringList() << "video*");
-
-    foreach (const QFileInfo &entryInfo, entries) {
-        int fd = qt_safe_open(entryInfo.filePath().toLatin1().constData(), O_RDWR );
-        if (fd == -1)
-            continue;
-
-        bool isCamera = false;
-
-        v4l2_input input;
-        memset(&input, 0, sizeof(input));
-        for (; ::ioctl(fd, VIDIOC_ENUMINPUT, &input) >= 0; ++input.index) {
-            if (input.type == V4L2_INPUT_TYPE_CAMERA || input.type == 0) {
-                isCamera = ::ioctl(fd, VIDIOC_S_INPUT, input.index) != 0;
-                break;
-            }
-        }
-
-        if (isCamera) {
-            // find out its driver "name"
-            QString name;
-            struct v4l2_capability vcap;
-            memset(&vcap, 0, sizeof(struct v4l2_capability));
+    return QGstUtils::cameraPosition(deviceName, m_sourceFactory);
+}
 
-            if (ioctl(fd, VIDIOC_QUERYCAP, &vcap) != 0)
-                name = entryInfo.fileName();
-            else
-                name = QString((const char*)vcap.card);
-            //qDebug() << "found camera: " << name;
+int CameraBinServicePlugin::cameraOrientation(const QByteArray &deviceName) const
+{
+    return QGstUtils::cameraOrientation(deviceName, m_sourceFactory);
+}
 
-            m_cameraDevices.append(entryInfo.filePath().toLocal8Bit());
-            m_cameraDescriptions.append(name);
+GstElementFactory *CameraBinServicePlugin::sourceFactory() const
+{
+    if (!m_sourceFactory) {
+        GstElementFactory *factory = 0;
+        const QByteArray envCandidate = qgetenv("QT_GSTREAMER_CAMERABIN_SRC");
+        if (!envCandidate.isEmpty())
+            factory = gst_element_factory_find(envCandidate.constData());
+
+        static const char *candidates[] = { "subdevsrc", "wrappercamerabinsrc" };
+        for (int i = 0; !factory && i < lengthOf(candidates); ++i)
+            factory = gst_element_factory_find(candidates[i]);
+
+        if (factory) {
+            m_sourceFactory = GST_ELEMENT_FACTORY(gst_plugin_feature_load(
+                    GST_PLUGIN_FEATURE(factory)));
+            gst_object_unref((GST_OBJECT(factory)));
         }
-        qt_safe_close(fd);
     }
 
-    if (!m_cameraDevices.isEmpty())
-        m_defaultCameraDevice = m_cameraDevices.first();
+    return m_sourceFactory;
 }
 
 QT_END_NAMESPACE
diff --git a/src/plugins/gstreamer/camerabin/camerabinserviceplugin.h b/src/plugins/gstreamer/camerabin/camerabinserviceplugin.h
index 50ffc59..6b192d8 100644
--- a/src/plugins/gstreamer/camerabin/camerabinserviceplugin.h
+++ b/src/plugins/gstreamer/camerabin/camerabinserviceplugin.h
@@ -44,7 +44,9 @@
 #define CAMERABINSERVICEPLUGIN_H
 
 #include <qmediaserviceproviderplugin.h>
-#include <QtCore/QObject>
+#include <private/qgstreamervideoinputdevicecontrol_p.h>
+
+#include <gst/gst.h>
 
 QT_BEGIN_NAMESPACE
 
@@ -53,13 +55,18 @@ class CameraBinServicePlugin
     , public QMediaServiceSupportedDevicesInterface
     , public QMediaServiceDefaultDeviceInterface
     , public QMediaServiceFeaturesInterface
+    , public QMediaServiceCameraInfoInterface
 {
     Q_OBJECT
     Q_INTERFACES(QMediaServiceSupportedDevicesInterface)
     Q_INTERFACES(QMediaServiceDefaultDeviceInterface)
     Q_INTERFACES(QMediaServiceFeaturesInterface)
+    Q_INTERFACES(QMediaServiceCameraInfoInterface)
     Q_PLUGIN_METADATA(IID "org.qt-project.qt.mediaserviceproviderfactory/5.0" FILE "camerabin.json")
 public:
+    CameraBinServicePlugin();
+    ~CameraBinServicePlugin();
+
     QMediaService* create(QString const& key);
     void release(QMediaService *service);
 
@@ -70,12 +77,13 @@ public:
     QString deviceDescription(const QByteArray &service, const QByteArray &device);
     QVariant deviceProperty(const QByteArray &service, const QByteArray &device, const QByteArray &property);
 
+    QCamera::Position cameraPosition(const QByteArray &device) const;
+    int cameraOrientation(const QByteArray &device) const;
+
 private:
-    void updateDevices() const;
+    GstElementFactory *sourceFactory() const;
 
-    mutable QByteArray m_defaultCameraDevice;
-    mutable QList<QByteArray> m_cameraDevices;
-    mutable QStringList m_cameraDescriptions;
+    mutable GstElementFactory *m_sourceFactory;
 };
 
 QT_END_NAMESPACE
diff --git a/src/plugins/gstreamer/camerabin/camerabinsession.cpp b/src/plugins/gstreamer/camerabin/camerabinsession.cpp
index 6e3448f..dfc7252 100644
--- a/src/plugins/gstreamer/camerabin/camerabinsession.cpp
+++ b/src/plugins/gstreamer/camerabin/camerabinsession.cpp
@@ -119,7 +119,7 @@
 
 QT_BEGIN_NAMESPACE
 
-CameraBinSession::CameraBinSession(QObject *parent)
+CameraBinSession::CameraBinSession(GstElementFactory *sourceFactory, QObject *parent)
     :QObject(parent),
      m_recordingActive(false),
      m_state(QCamera::UnloadedState),
@@ -133,6 +133,7 @@ CameraBinSession::CameraBinSession(QObject *parent)
      m_viewfinderInterface(0),
      m_videoSrc(0),
      m_viewfinderElement(0),
+     m_sourceFactory(sourceFactory),
      m_viewfinderHasChanged(true),
      m_videoInputHasChanged(true),
      m_audioSrc(0),
@@ -142,7 +143,10 @@ CameraBinSession::CameraBinSession(QObject *parent)
      m_audioEncoder(0),
      m_muxer(0)
 {
-    m_camerabin = gst_element_factory_make("camerabin2", "camerabin2");
+    if (m_sourceFactory)
+        gst_object_ref(GST_OBJECT(m_sourceFactory));
+    m_camerabin = gst_element_factory_make(QT_GSTREAMER_CAMERABIN_ELEMENT_NAME, "camerabin");
+
     g_signal_connect(G_OBJECT(m_camerabin), "notify::idle", G_CALLBACK(updateBusyStatus), this);
     qt_gst_object_ref_sink(m_camerabin);
 
@@ -177,7 +181,15 @@ CameraBinSession::CameraBinSession(QObject *parent)
     //post image preview in RGB format
     g_object_set(G_OBJECT(m_camerabin), POST_PREVIEWS_PROPERTY, TRUE, NULL);
 
+#if GST_CHECK_VERSION(1,0,0)
+    GstCaps *previewCaps = gst_caps_new_simple(
+                "video/x-raw",
+                "format", G_TYPE_STRING, "RGBx",
+                NULL);
+#else
     GstCaps *previewCaps = gst_caps_from_string("video/x-raw-rgb");
+#endif
+
     g_object_set(G_OBJECT(m_camerabin), PREVIEW_CAPS_PROPERTY, previewCaps, NULL);
     gst_caps_unref(previewCaps);
 }
@@ -195,6 +207,9 @@ CameraBinSession::~CameraBinSession()
     }
     if (m_viewfinderElement)
         gst_object_unref(GST_OBJECT(m_viewfinderElement));
+
+    if (m_sourceFactory)
+        gst_object_unref(GST_OBJECT(m_sourceFactory));
 }
 
 #ifdef HAVE_GST_PHOTOGRAPHY
@@ -239,6 +254,7 @@ bool CameraBinSession::setupCameraBin()
             qWarning() << "Staring camera without viewfinder available";
             m_viewfinderElement = gst_element_factory_make("fakesink", NULL);
         }
+        g_object_set(G_OBJECT(m_viewfinderElement), "sync", FALSE, NULL);
         qt_gst_object_ref_sink(GST_OBJECT(m_viewfinderElement));
         gst_element_set_state(m_camerabin, GST_STATE_NULL);
         g_object_set(G_OBJECT(m_camerabin), VIEWFINDER_SINK_PROPERTY, m_viewfinderElement, NULL);
@@ -247,61 +263,27 @@ bool CameraBinSession::setupCameraBin()
     return true;
 }
 
-static GstCaps *resolutionToCaps(const QSize &resolution, const QPair<int, int> &rate = qMakePair<int,int>(0,0))
+static GstCaps *resolutionToCaps(const QSize &resolution, qreal frameRate = 0.0)
 {
-    if (resolution.isEmpty())
-        return gst_caps_new_any();
+    GstCaps *caps = QGstUtils::videoFilterCaps();
 
-    GstCaps *caps = 0;
-    if (rate.second > 0) {
-        caps = gst_caps_new_full(gst_structure_new("video/x-raw-yuv",
-                                                   "width", G_TYPE_INT, resolution.width(),
-                                                   "height", G_TYPE_INT, resolution.height(),
-                                                   "framerate", GST_TYPE_FRACTION, rate.first, rate.second,
-                                                   NULL),
-                                 gst_structure_new("video/x-raw-rgb",
-                                                   "width", G_TYPE_INT, resolution.width(),
-                                                   "height", G_TYPE_INT, resolution.height(),
-                                                   "framerate", GST_TYPE_FRACTION, rate.first, rate.second,
-                                                   NULL),
-                                 gst_structure_new("video/x-raw-data",
-                                                   "width", G_TYPE_INT, resolution.width(),
-                                                   "height", G_TYPE_INT, resolution.height(),
-                                                   "framerate", GST_TYPE_FRACTION, rate.first, rate.second,
-                                                   NULL),
-                                gst_structure_new("video/x-android-buffer",
-                                                   "width", G_TYPE_INT, resolution.width(),
-                                                                                    "height", G_TYPE_INT, resolution.height(),
-                                                                                    "framerate", GST_TYPE_FRACTION, rate.first, rate.second,
-                                                                                    NULL),
-                                 gst_structure_new("image/jpeg",
-                                                   "width", G_TYPE_INT, resolution.width(),
-                                                   "height", G_TYPE_INT, resolution.height(),
-                                                   "framerate", GST_TYPE_FRACTION, rate.first, rate.second,
-                                                   NULL),
-                                 NULL);
-    } else {
-        caps = gst_caps_new_full (gst_structure_new ("video/x-raw-yuv",
-                                                     "width", G_TYPE_INT, resolution.width(),
-                                                     "height", G_TYPE_INT, resolution.height(),
-                                                     NULL),
-                                  gst_structure_new ("video/x-raw-rgb",
-                                                     "width", G_TYPE_INT, resolution.width(),
-                                                     "height", G_TYPE_INT, resolution.height(),
-                                                     NULL),
-                                  gst_structure_new("video/x-raw-data",
-                                                    "width", G_TYPE_INT, resolution.width(),
-                                                    "height", G_TYPE_INT, resolution.height(),
-                                                    NULL),
-                                  gst_structure_new ("video/x-android-buffer",
-                                                     "width", G_TYPE_INT, resolution.width(),
-                                                     "height", G_TYPE_INT, resolution.height(),
-                                                     NULL),
-                                  gst_structure_new ("image/jpeg",
-                                                     "width", G_TYPE_INT, resolution.width(),
-                                                     "height", G_TYPE_INT, resolution.height(),
-                                                     NULL),
-                                  NULL);
+    if (!resolution.isEmpty()) {
+        gst_caps_set_simple(
+                    caps,
+                    "width", G_TYPE_INT, resolution.width(),
+                    "height", G_TYPE_INT, resolution.height(),
+                     NULL);
+    }
+
+    if (frameRate > 0.0) {
+        gint numerator;
+        gint denominator;
+        gst_util_double_to_fraction(frameRate, &numerator, &denominator);
+
+        gst_caps_set_simple(
+                    caps,
+                    "framerate", GST_TYPE_FRACTION, numerator, denominator,
+                    NULL);
     }
 
     return caps;
@@ -310,40 +292,40 @@ static GstCaps *resolutionToCaps(const QSize &resolution, const QPair<int, int>
 void CameraBinSession::setupCaptureResolution()
 {
     QSize resolution = m_imageEncodeControl->imageSettings().resolution();
-    if (!resolution.isEmpty()) {
+    {
         GstCaps *caps = resolutionToCaps(resolution);
 #if CAMERABIN_DEBUG
-        qDebug() << Q_FUNC_INFO << "set image resolution" << resolution << gst_caps_to_string(caps);
+        qDebug() << Q_FUNC_INFO << "set image resolution" << resolution << caps;
 #endif
         g_object_set(m_camerabin, IMAGE_CAPTURE_CAPS_PROPERTY, caps, NULL);
-        gst_caps_unref(caps);
-    } else {
-        g_object_set(m_camerabin, IMAGE_CAPTURE_CAPS_PROPERTY, NULL, NULL);
+        if (caps)
+            gst_caps_unref(caps);
     }
 
+    const QSize viewfinderResolution = m_viewfinderSettingsControl->resolution();
     resolution = m_videoEncodeControl->actualVideoSettings().resolution();
-    //qreal framerate = m_videoEncodeControl->videoSettings().frameRate();
-    if (!resolution.isEmpty()) {
-        GstCaps *caps = resolutionToCaps(resolution /*, framerate*/); //convert to rational
+    qreal framerate = m_videoEncodeControl->videoSettings().frameRate();
+    {
+        GstCaps *caps = resolutionToCaps(
+                    !resolution.isEmpty() ? resolution : viewfinderResolution, framerate);
 #if CAMERABIN_DEBUG
-        qDebug() << Q_FUNC_INFO << "set video resolution" << resolution << gst_caps_to_string(caps);
+        qDebug() << Q_FUNC_INFO << "set video resolution" << resolution << caps;
 #endif
         g_object_set(m_camerabin, VIDEO_CAPTURE_CAPS_PROPERTY, caps, NULL);
-        gst_caps_unref(caps);
-    } else {
-        g_object_set(m_camerabin, VIDEO_CAPTURE_CAPS_PROPERTY, NULL, NULL);
+        if (caps)
+            gst_caps_unref(caps);
     }
 
-    resolution = m_viewfinderSettingsControl->resolution();
-    if (!resolution.isEmpty()) {
+    if (!viewfinderResolution.isEmpty())
+        resolution = viewfinderResolution;
+    {
         GstCaps *caps = resolutionToCaps(resolution);
 #if CAMERABIN_DEBUG
-        qDebug() << Q_FUNC_INFO << "set viewfinder resolution" << resolution << gst_caps_to_string(caps);
+        qDebug() << Q_FUNC_INFO << "set viewfinder resolution" << resolution << caps;
 #endif
         g_object_set(m_camerabin, VIEWFINDER_CAPS_PROPERTY, caps, NULL);
-        gst_caps_unref(caps);
-    } else {
-        g_object_set(m_camerabin, VIEWFINDER_CAPS_PROPERTY, NULL, NULL);
+        if (caps)
+            gst_caps_unref(caps);
     }
 }
 
@@ -356,13 +338,17 @@ void CameraBinSession::setAudioCaptureCaps()
     if (sampleRate == -1 && channelCount == -1)
         return;
 
+#if GST_CHECK_VERSION(1,0,0)
+    GstStructure *structure = gst_structure_new_empty(QT_GSTREAMER_RAW_AUDIO_MIME);
+#else
     GstStructure *structure = gst_structure_new(
-                "audio/x-raw-int",
+                QT_GSTREAMER_RAW_AUDIO_MIME,
                 "endianness", G_TYPE_INT, 1234,
                 "signed", G_TYPE_BOOLEAN, TRUE,
                 "width", G_TYPE_INT, 16,
                 "depth", G_TYPE_INT, 16,
                 NULL);
+#endif
     if (sampleRate != -1)
         gst_structure_set(structure, "rate", G_TYPE_INT, sampleRate, NULL);
     if (channelCount != -1)
@@ -383,32 +369,17 @@ GstElement *CameraBinSession::buildCameraSource()
     m_videoInputHasChanged = false;
 
     GstElement *videoSrc = 0;
+
+    if (!videoSrc)
     g_object_get(G_OBJECT(m_camerabin), CAMERA_SOURCE_PROPERTY, &videoSrc, NULL);
 
-    // If the QT_GSTREAMER_CAMERABIN_SRC environment variable has been set use the source
-    // it recommends.
-    const QByteArray envCandidate = qgetenv("QT_GSTREAMER_CAMERABIN_SRC");
-    if (!m_videoSrc && !envCandidate.isEmpty()) {
-        m_videoSrc = gst_element_factory_make(envCandidate.constData(), "camera_source");
-    }
+    if (m_sourceFactory)
+        m_videoSrc = gst_element_factory_create(m_sourceFactory, "camera_source");
 
     // If gstreamer has set a default source use it.
     if (!m_videoSrc)
         m_videoSrc = videoSrc;
 
-    // If there's no better guidance try the names of some known camera source elements.
-    if (!m_videoSrc) {
-        const QList<QByteArray> candidates = QList<QByteArray>()
-                << "subdevsrc"
-                << "wrappercamerabinsrc";
-
-        foreach (const QByteArray &sourceElementName, candidates) {
-            m_videoSrc = gst_element_factory_make(sourceElementName.constData(), "camera_source");
-            if (m_videoSrc)
-                break;
-        }
-    }
-
     if (m_videoSrc && !m_inputDevice.isEmpty()) {
 #if CAMERABIN_DEBUG
         qDebug() << "set camera device" << m_inputDevice;
@@ -487,6 +458,11 @@ QUrl CameraBinSession::outputLocation() const
 
 bool CameraBinSession::setOutputLocation(const QUrl& sink)
 {
+    if (!sink.isRelative() && !sink.isLocalFile()) {
+        qWarning("Output location must be a local file");
+        return false;
+    }
+
     m_sink = m_actualSink = sink;
     return true;
 }
@@ -723,10 +699,9 @@ void CameraBinSession::updateBusyStatus(GObject *o, GParamSpec *p, gpointer d)
 
 qint64 CameraBinSession::duration() const
 {
-    GstFormat   format = GST_FORMAT_TIME;
     gint64      duration = 0;
 
-    if ( m_camerabin && gst_element_query_position(m_camerabin, &format, &duration))
+    if (m_camerabin && qt_gst_element_query_position(m_camerabin, GST_FORMAT_TIME, &duration))
         return duration / 1000000;
     else
         return 0;
@@ -757,129 +732,57 @@ void CameraBinSession::setMetaData(const QMap<QByteArray, QVariant> &data)
 {
     m_metaData = data;
 
-    if (m_camerabin) {
-        GstIterator *elements = gst_bin_iterate_all_by_interface(GST_BIN(m_camerabin), GST_TYPE_TAG_SETTER);
-        GstElement *element = 0;
-        while (gst_iterator_next(elements, (void**)&element) == GST_ITERATOR_OK) {
-            gst_tag_setter_reset_tags(GST_TAG_SETTER(element));
-
-            QMapIterator<QByteArray, QVariant> it(data);
-            while (it.hasNext()) {
-                it.next();
-                const QString tagName = it.key();
-                const QVariant tagValue = it.value();
-
-                switch(tagValue.type()) {
-                    case QVariant::String:
-                        gst_tag_setter_add_tags(GST_TAG_SETTER(element),
-                            GST_TAG_MERGE_REPLACE,
-                            tagName.toUtf8().constData(),
-                            tagValue.toString().toUtf8().constData(),
-                            NULL);
-                        break;
-                    case QVariant::Int:
-                    case QVariant::LongLong:
-                        gst_tag_setter_add_tags(GST_TAG_SETTER(element),
-                            GST_TAG_MERGE_REPLACE,
-                            tagName.toUtf8().constData(),
-                            tagValue.toInt(),
-                            NULL);
-                        break;
-                    case QVariant::Double:
-                        gst_tag_setter_add_tags(GST_TAG_SETTER(element),
-                            GST_TAG_MERGE_REPLACE,
-                            tagName.toUtf8().constData(),
-                            tagValue.toDouble(),
-                            NULL);
-                        break;
-                    case QVariant::DateTime: {
-                        QDateTime date = tagValue.toDateTime().toLocalTime();
-                        gst_tag_setter_add_tags(GST_TAG_SETTER(element),
-                            GST_TAG_MERGE_REPLACE,
-                            tagName.toUtf8().constData(),
-                            gst_date_time_new_local_time(
-                                        date.date().year(), date.date().month(), date.date().day(),
-                                        date.time().hour(), date.time().minute(), date.time().second()),
-                            NULL);
-                        break;
-                    }
-                    default:
-                        break;
-                }
-            }
-        }
-        gst_iterator_free(elements);
-    }
+    if (m_camerabin)
+        QGstUtils::setMetaData(m_camerabin, data);
 }
 
 bool CameraBinSession::processSyncMessage(const QGstreamerMessage &message)
 {
     GstMessage* gm = message.rawMessage();
-    const GstStructure *st;
-    const GValue *image;
-    GstBuffer *buffer = NULL;
 
     if (gm && GST_MESSAGE_TYPE(gm) == GST_MESSAGE_ELEMENT) {
-        if (m_captureMode == QCamera::CaptureStillImage &&
-            gst_structure_has_name(gm->structure, "preview-image")) {
-            st = gst_message_get_structure(gm);
-
-            if (gst_structure_has_field_typed(st, "buffer", GST_TYPE_BUFFER)) {
-                image = gst_structure_get_value(st, "buffer");
-                if (image) {
-                    buffer = gst_value_get_buffer(image);
-
-                    QImage img;
-
-                    GstCaps *caps = gst_buffer_get_caps(buffer);
-                    if (caps) {
-                        GstStructure *structure = gst_caps_get_structure(caps, 0);
-                        gint width = 0;
-                        gint height = 0;
-#if CAMERABIN_DEBUG
-                        qDebug() << "Preview caps:" << gst_structure_to_string(structure);
+        const GstStructure *st = gst_message_get_structure(gm);
+        const GValue *sampleValue = 0;
+        if (m_captureMode == QCamera::CaptureStillImage
+                    && gst_structure_has_name(st, "preview-image")
+#if GST_CHECK_VERSION(1,0,0)
+                    && gst_structure_has_field_typed(st, "sample", GST_TYPE_SAMPLE)
+                    && (sampleValue = gst_structure_get_value(st, "sample"))) {
+            GstSample * const sample = gst_value_get_sample(sampleValue);
+            GstCaps * const previewCaps = gst_sample_get_caps(sample);
+            GstBuffer * const buffer = gst_sample_get_buffer(sample);
+#else
+                    && gst_structure_has_field_typed(st, "buffer", GST_TYPE_BUFFER)
+                    && (sampleValue = gst_structure_get_value(st, "buffer"))) {
+            GstBuffer * const buffer = gst_value_get_buffer(sampleValue);
 #endif
 
-                        if (structure &&
-                            gst_structure_get_int(structure, "width", &width) &&
-                            gst_structure_get_int(structure, "height", &height) &&
-                            width > 0 && height > 0) {
-                            if (qstrcmp(gst_structure_get_name(structure), "video/x-raw-rgb") == 0) {
-                                QImage::Format format = QImage::Format_Invalid;
-                                int bpp = 0;
-                                gst_structure_get_int(structure, "bpp", &bpp);
-
-                                if (bpp == 24)
-                                    format = QImage::Format_RGB888;
-                                else if (bpp == 32)
-                                    format = QImage::Format_RGB32;
-
-                                if (format != QImage::Format_Invalid) {
-                                    img = QImage((const uchar *)buffer->data, width, height, format);
-                                    img.bits(); //detach
-                                 }
-                            }
-                        }
-                        gst_caps_unref(caps);
-
-                        static QMetaMethod exposedSignal = QMetaMethod::fromSignal(&CameraBinSession::imageExposed);
-                        exposedSignal.invoke(this,
-                                             Qt::QueuedConnection,
-                                             Q_ARG(int,m_requestId));
-
-                        static QMetaMethod capturedSignal = QMetaMethod::fromSignal(&CameraBinSession::imageCaptured);
-                        capturedSignal.invoke(this,
-                                              Qt::QueuedConnection,
-                                              Q_ARG(int,m_requestId),
-                                              Q_ARG(QImage,img));
-                    }
-
-                }
-                return true;
+            QImage image;
+#if GST_CHECK_VERSION(1,0,0)
+            GstVideoInfo previewInfo;
+            if (gst_video_info_from_caps(&previewInfo, previewCaps))
+                image = QGstUtils::bufferToImage(buffer, previewInfo);
+            gst_sample_unref(sample);
+#else
+            image = QGstUtils::bufferToImage(buffer);
+            gst_buffer_unref(buffer);
+#endif
+            if (!image.isNull()) {
+                static QMetaMethod exposedSignal = QMetaMethod::fromSignal(&CameraBinSession::imageExposed);
+                exposedSignal.invoke(this,
+                                     Qt::QueuedConnection,
+                                     Q_ARG(int,m_requestId));
+
+                static QMetaMethod capturedSignal = QMetaMethod::fromSignal(&CameraBinSession::imageCaptured);
+                capturedSignal.invoke(this,
+                                      Qt::QueuedConnection,
+                                      Q_ARG(int,m_requestId),
+                                      Q_ARG(QImage,image));
             }
+            return true;
         }
 #ifdef HAVE_GST_PHOTOGRAPHY
-        if (gst_structure_has_name(gm->structure, GST_PHOTOGRAPHY_AUTOFOCUS_DONE))
+        if (gst_structure_has_name(st, GST_PHOTOGRAPHY_AUTOFOCUS_DONE))
             m_cameraFocusControl->handleFocusMessage(gm);
 #endif
     }
@@ -1007,8 +910,9 @@ void CameraBinSession::recordVideo()
     if (m_actualSink.isEmpty()) {
         QString ext = m_mediaContainerControl->suggestedFileExtension(m_mediaContainerControl->actualContainerFormat());
         m_actualSink = QUrl::fromLocalFile(generateFileName("clip_", defaultDir(QCamera::CaptureVideo), ext));
-    } else if (!m_actualSink.isLocalFile()) {
-        m_actualSink = QUrl::fromLocalFile(m_actualSink.toEncoded());
+    } else {
+        // Output location was rejected in setOutputlocation() if not a local file
+        m_actualSink = QUrl::fromLocalFile(QDir::currentPath()).resolved(m_actualSink);
     }
 
     QString fileName = m_actualSink.toLocalFile();
@@ -1070,20 +974,12 @@ QList< QPair<int,int> > CameraBinSession::supportedFrameRates(const QSize &frame
     if (frameSize.isEmpty()) {
         caps = gst_caps_copy(supportedCaps);
     } else {
-        GstCaps *filter = gst_caps_new_full(
-                gst_structure_new(
-                        "video/x-raw-rgb",
-                        "width"     , G_TYPE_INT , frameSize.width(),
-                        "height"    , G_TYPE_INT, frameSize.height(), NULL),
-                gst_structure_new(
-                        "video/x-raw-yuv",
-                        "width"     , G_TYPE_INT, frameSize.width(),
-                        "height"    , G_TYPE_INT, frameSize.height(), NULL),
-                gst_structure_new(
-                        "image/jpeg",
-                        "width"     , G_TYPE_INT, frameSize.width(),
-                        "height"    , G_TYPE_INT, frameSize.height(), NULL),
-                NULL);
+        GstCaps *filter = QGstUtils::videoFilterCaps();
+        gst_caps_set_simple(
+                    filter,
+                    "width", G_TYPE_INT, frameSize.width(),
+                    "height", G_TYPE_INT, frameSize.height(),
+                     NULL);
 
         caps = gst_caps_intersect(supportedCaps, filter);
         gst_caps_unref(filter);
@@ -1094,7 +990,7 @@ QList< QPair<int,int> > CameraBinSession::supportedFrameRates(const QSize &frame
     caps = gst_caps_make_writable(caps);
     for (uint i=0; i<gst_caps_get_size(caps); i++) {
         GstStructure *structure = gst_caps_get_structure(caps, i);
-        gst_structure_set_name(structure, "video/x-raw-yuv");
+        gst_structure_set_name(structure, "video/x-raw");
         const GValue *oldRate = gst_structure_get_value(structure, "framerate");
         GValue rate;
         memset(&rate, 0, sizeof(rate));
@@ -1103,8 +999,11 @@ QList< QPair<int,int> > CameraBinSession::supportedFrameRates(const QSize &frame
         gst_structure_remove_all_fields(structure);
         gst_structure_set_value(structure, "framerate", &rate);
     }
+#if GST_CHECK_VERSION(1,0,0)
+    caps = gst_caps_simplify(caps);
+#else
     gst_caps_do_simplify(caps);
-
+#endif
 
     for (uint i=0; i<gst_caps_get_size(caps); i++) {
         GstStructure *structure = gst_caps_get_structure(caps, i);
@@ -1115,7 +1014,7 @@ QList< QPair<int,int> > CameraBinSession::supportedFrameRates(const QSize &frame
     qSort(res.begin(), res.end(), rateLessThan);
 
 #if CAMERABIN_DEBUG
-    qDebug() << "Supported rates:" << gst_caps_to_string(caps);
+    qDebug() << "Supported rates:" << caps;
     qDebug() << res;
 #endif
 
@@ -1174,31 +1073,24 @@ QList<QSize> CameraBinSession::supportedResolutions(QPair<int,int> rate,
                      SUPPORTED_IMAGE_CAPTURE_CAPS_PROPERTY : SUPPORTED_VIDEO_CAPTURE_CAPS_PROPERTY,
                  &supportedCaps, NULL);
 
-    if (!supportedCaps)
-        return res;
-
 #if CAMERABIN_DEBUG
-    qDebug() << "Source caps:" << gst_caps_to_string(supportedCaps);
+    qDebug() << "Source caps:" << supportedCaps;
 #endif
 
+    if (!supportedCaps)
+        return res;
+
     GstCaps *caps = 0;
     bool isContinuous = false;
 
     if (rate.first <= 0 || rate.second <= 0) {
         caps = gst_caps_copy(supportedCaps);
     } else {
-        GstCaps *filter = gst_caps_new_full(
-                gst_structure_new(
-                        "video/x-raw-rgb",
-                        "framerate"     , GST_TYPE_FRACTION , rate.first, rate.second, NULL),
-                gst_structure_new(
-                        "video/x-raw-yuv",
-                        "framerate"     , GST_TYPE_FRACTION , rate.first, rate.second, NULL),
-                gst_structure_new(
-                        "image/jpeg",
-                        "framerate"     , GST_TYPE_FRACTION , rate.first, rate.second, NULL),
-                NULL);
-
+        GstCaps *filter = QGstUtils::videoFilterCaps();
+        gst_caps_set_simple(
+                    filter,
+                    "framerate"     , GST_TYPE_FRACTION , rate.first, rate.second,
+                     NULL);
         caps = gst_caps_intersect(supportedCaps, filter);
         gst_caps_unref(filter);
     }
@@ -1208,7 +1100,7 @@ QList<QSize> CameraBinSession::supportedResolutions(QPair<int,int> rate,
     caps = gst_caps_make_writable(caps);
     for (uint i=0; i<gst_caps_get_size(caps); i++) {
         GstStructure *structure = gst_caps_get_structure(caps, i);
-        gst_structure_set_name(structure, "video/x-raw-yuv");
+        gst_structure_set_name(structure, "video/x-raw");
         const GValue *oldW = gst_structure_get_value(structure, "width");
         const GValue *oldH = gst_structure_get_value(structure, "height");
         GValue w;
@@ -1223,7 +1115,13 @@ QList<QSize> CameraBinSession::supportedResolutions(QPair<int,int> rate,
         gst_structure_set_value(structure, "width", &w);
         gst_structure_set_value(structure, "height", &h);
     }
+
+#if GST_CHECK_VERSION(1,0,0)
+    caps = gst_caps_simplify(caps);
+#else
     gst_caps_do_simplify(caps);
+#endif
+
 
     for (uint i=0; i<gst_caps_get_size(caps); i++) {
         GstStructure *structure = gst_caps_get_structure(caps, i);
diff --git a/src/plugins/gstreamer/camerabin/camerabinsession.h b/src/plugins/gstreamer/camerabin/camerabinsession.h
index d772179..24d1aeb 100644
--- a/src/plugins/gstreamer/camerabin/camerabinsession.h
+++ b/src/plugins/gstreamer/camerabin/camerabinsession.h
@@ -51,6 +51,7 @@
 #ifdef HAVE_GST_PHOTOGRAPHY
 #include <gst/interfaces/photography.h>
 #endif
+#include <gst/video/video.h>
 
 #include <private/qgstreamerbushelper_p.h>
 #include "qcamera.h"
@@ -83,9 +84,10 @@ public:
 };
 
 
-class CameraBinSession : public QObject,
-                         public QGstreamerBusMessageFilter,
-                         public QGstreamerSyncMessageFilter
+class CameraBinSession
+    : public QObject
+    , public QGstreamerBusMessageFilter
+    , public QGstreamerSyncMessageFilter
 {
     Q_OBJECT
     Q_PROPERTY(qint64 duration READ duration NOTIFY durationChanged)
@@ -96,13 +98,14 @@ public:
        BackCamera // Main photo camera
     };
 
-    CameraBinSession(QObject *parent);
+    CameraBinSession(GstElementFactory *sourceFactory, QObject *parent);
     ~CameraBinSession();
 
 #ifdef HAVE_GST_PHOTOGRAPHY
     GstPhotography *photography();
 #endif
     GstElement *cameraBin() { return m_camerabin; }
+    GstElement *cameraSource() { return m_videoSrc; }
     QGstreamerBusHelper *bus() { return m_busHelper; }
 
     CameraRole cameraRole() const;
@@ -120,6 +123,7 @@ public:
     QString generateFileName(const QString &prefix, const QDir &dir, const QString &ext) const;
 
     GstElement *buildCameraSource();
+    GstElementFactory *sourceFactory() const { return m_sourceFactory; }
 
     CameraBinControl *cameraControl() const { return m_cameraControl; }
     CameraBinAudioEncoder *audioEncodeControl() const { return m_audioEncodeControl; }
@@ -196,6 +200,13 @@ private:
     void setAudioCaptureCaps();
     static void updateBusyStatus(GObject *o, GParamSpec *p, gpointer d);
 
+    void probeCaps(GstCaps *caps);
+    bool probeBuffer(GstBuffer *buffer);
+
+#if GST_CHECK_VERSION(1,0,0)
+    GstVideoInfo m_previewInfo;
+#endif
+
     QUrl m_sink;
     QUrl m_actualSink;
     bool m_recordingActive;
@@ -238,6 +249,7 @@ private:
     GstElement *m_camerabin;
     GstElement *m_videoSrc;
     GstElement *m_viewfinderElement;
+    GstElementFactory *m_sourceFactory;
     bool m_viewfinderHasChanged;
     bool m_videoInputHasChanged;
 
diff --git a/src/plugins/gstreamer/camerabin/camerabinviewfindersettings.cpp b/src/plugins/gstreamer/camerabin/camerabinviewfindersettings.cpp
index 373dbee..b61a506 100644
--- a/src/plugins/gstreamer/camerabin/camerabinviewfindersettings.cpp
+++ b/src/plugins/gstreamer/camerabin/camerabinviewfindersettings.cpp
@@ -89,6 +89,7 @@ void CameraBinViewfinderSettings::setViewfinderParameter(ViewfinderParameter par
     switch (parameter) {
     case Resolution:
         m_resolution = value.toSize();
+        break;
     case PixelAspectRatio:
     case MinimumFrameRate:
     case MaximumFrameRate:
diff --git a/src/plugins/gstreamer/common.pri b/src/plugins/gstreamer/common.pri
index 8b421b8..eb6a299 100644
--- a/src/plugins/gstreamer/common.pri
+++ b/src/plugins/gstreamer/common.pri
@@ -12,14 +12,18 @@ LIBS += -lqgsttools_p
 CONFIG += link_pkgconfig
 
 PKGCONFIG += \
-    gstreamer-0.10 \
-    gstreamer-base-0.10 \
-    gstreamer-interfaces-0.10 \
-    gstreamer-audio-0.10 \
-    gstreamer-video-0.10 \
-    gstreamer-pbutils-0.10
+    gstreamer-$$GST_VERSION \
+    gstreamer-base-$$GST_VERSION \
+    gstreamer-audio-$$GST_VERSION \
+    gstreamer-video-$$GST_VERSION \
+    gstreamer-pbutils-$$GST_VERSION
+
+maemo*:PKGCONFIG +=gstreamer-plugins-bad-$$GST_VERSION
+
+mir: {
+    DEFINES += HAVE_MIR
+}
 
-maemo*:PKGCONFIG +=gstreamer-plugins-bad-0.10
 
 config_resourcepolicy {
     DEFINES += HAVE_RESOURCE_POLICY
@@ -27,8 +31,8 @@ config_resourcepolicy {
 }
 
 config_gstreamer_appsrc {
-    PKGCONFIG += gstreamer-app-0.10
+    PKGCONFIG += gstreamer-app-$$GST_VERSION
     DEFINES += HAVE_GST_APPSRC
-    LIBS += -lgstapp-0.10
+    LIBS += -lgstapp-$$GST_VERSION
 }
 
diff --git a/src/plugins/gstreamer/gstreamer.pro b/src/plugins/gstreamer/gstreamer.pro
index 7649010..0ff3510 100644
--- a/src/plugins/gstreamer/gstreamer.pro
+++ b/src/plugins/gstreamer/gstreamer.pro
@@ -2,8 +2,8 @@ TEMPLATE = subdirs
 
 SUBDIRS += \
     audiodecoder \
-    mediacapture \
-    mediaplayer
+    mediaplayer \
+    mediacapture
 
 config_gstreamer_encodingprofiles {
     SUBDIRS += camerabin
diff --git a/src/plugins/gstreamer/mediacapture/mediacapturecamera.json b/src/plugins/gstreamer/mediacapture/mediacapturecamera.json
index af9f357..f5fba17 100644
--- a/src/plugins/gstreamer/mediacapture/mediacapturecamera.json
+++ b/src/plugins/gstreamer/mediacapture/mediacapturecamera.json
@@ -1,4 +1,4 @@
 {
-    "Keys": ["gstreamermediacapture"]
+    "Keys": ["gstreamermediacapture"],
     "Services": ["org.qt-project.qt.audiosource", "org.qt-project.qt.camera"]
 }
diff --git a/src/plugins/gstreamer/mediacapture/qgstreameraudioencode.cpp b/src/plugins/gstreamer/mediacapture/qgstreameraudioencode.cpp
index e735566..2a94de3 100644
--- a/src/plugins/gstreamer/mediacapture/qgstreameraudioencode.cpp
+++ b/src/plugins/gstreamer/mediacapture/qgstreameraudioencode.cpp
@@ -42,6 +42,7 @@
 #include "qgstreameraudioencode.h"
 #include "qgstreamercapturesession.h"
 #include "qgstreamermediacontainercontrol.h"
+#include <private/qgstutils_p.h>
 
 #include <QtCore/qdebug.h>
 
@@ -183,7 +184,7 @@ GstElement *QGstreamerAudioEncode::createEncoder()
 
     if (m_audioSettings.sampleRate() > 0 || m_audioSettings.channelCount() > 0) {
         GstCaps *caps = gst_caps_new_empty();
-        GstStructure *structure = gst_structure_new("audio/x-raw-int", NULL);
+        GstStructure *structure = qt_gst_structure_new_empty(QT_GSTREAMER_RAW_AUDIO_MIME);
 
         if (m_audioSettings.sampleRate() > 0)
             gst_structure_set(structure, "rate", G_TYPE_INT, m_audioSettings.sampleRate(), NULL );
diff --git a/src/plugins/gstreamer/mediacapture/qgstreamercaptureservice.cpp b/src/plugins/gstreamer/mediacapture/qgstreamercaptureservice.cpp
index 92b362f..e1904fc 100644
--- a/src/plugins/gstreamer/mediacapture/qgstreamercaptureservice.cpp
+++ b/src/plugins/gstreamer/mediacapture/qgstreamercaptureservice.cpp
@@ -67,25 +67,23 @@
 
 QT_BEGIN_NAMESPACE
 
-QGstreamerCaptureService::QGstreamerCaptureService(const QString &service, QObject *parent):
-    QMediaService(parent)
-{
-    m_captureSession = 0;
-    m_cameraControl = 0;
-    m_metaDataControl = 0;
-
-    m_videoInput = 0;
-    m_audioInputSelector = 0;
-    m_videoInputDevice = 0;
-
-    m_videoOutput = 0;
-    m_videoRenderer = 0;
-    m_videoWindow = 0;
+QGstreamerCaptureService::QGstreamerCaptureService(const QString &service, QObject *parent)
+    : QMediaService(parent)
+    , m_captureSession(0)
+    , m_cameraControl(0)
+    , m_videoInput(0)
+    , m_metaDataControl(0)
+    , m_audioInputSelector(0)
+    , m_videoInputDevice(0)
+    , m_videoOutput(0)
+    , m_videoRenderer(0)
+    , m_videoWindow(0)
 #if defined(HAVE_WIDGETS)
-    m_videoWidgetControl = 0;
+    , m_videoWidgetControl(0)
 #endif
-    m_imageCaptureControl = 0;
-
+    , m_imageCaptureControl(0)
+    , m_audioProbeControl(0)
+{
     if (service == Q_MEDIASERVICE_AUDIOSOURCE) {
         m_captureSession = new QGstreamerCaptureSession(QGstreamerCaptureSession::Audio, this);
     }
@@ -164,12 +162,12 @@ QMediaControl *QGstreamerCaptureService::requestControl(const char *name)
         return m_imageCaptureControl;
 
     if (qstrcmp(name,QMediaAudioProbeControl_iid) == 0) {
-        if (m_captureSession) {
-            QGstreamerAudioProbeControl *probe = new QGstreamerAudioProbeControl(this);
-            m_captureSession->addProbe(probe);
-            return probe;
+        if (!m_audioProbeControl) {
+            m_audioProbeControl = new QGstreamerAudioProbeControl(this);
+            m_captureSession->addProbe(m_audioProbeControl);
         }
-        return 0;
+        m_audioProbeControl->ref.ref();
+        return m_audioProbeControl;
     }
 
     if (!m_videoOutput) {
@@ -195,17 +193,15 @@ QMediaControl *QGstreamerCaptureService::requestControl(const char *name)
 
 void QGstreamerCaptureService::releaseControl(QMediaControl *control)
 {
-    if (control && control == m_videoOutput) {
+    if (!control) {
+        return;
+    } else if (control == m_videoOutput) {
         m_videoOutput = 0;
         m_captureSession->setVideoPreview(0);
-    }
-
-    QGstreamerAudioProbeControl* audioProbe = qobject_cast<QGstreamerAudioProbeControl*>(control);
-    if (audioProbe) {
-        if (m_captureSession)
-            m_captureSession->removeProbe(audioProbe);
-        delete audioProbe;
-        return;
+    } else if (control == m_audioProbeControl && !m_audioProbeControl->ref.deref()) {
+        m_captureSession->removeProbe(m_audioProbeControl);
+        delete m_audioProbeControl;
+        m_audioProbeControl = 0;
     }
 }
 
diff --git a/src/plugins/gstreamer/mediacapture/qgstreamercaptureservice.h b/src/plugins/gstreamer/mediacapture/qgstreamercaptureservice.h
index fc29b4f..e861ecf 100644
--- a/src/plugins/gstreamer/mediacapture/qgstreamercaptureservice.h
+++ b/src/plugins/gstreamer/mediacapture/qgstreamercaptureservice.h
@@ -51,6 +51,7 @@ QT_BEGIN_NAMESPACE
 class QAudioInputSelectorControl;
 class QVideoDeviceSelectorControl;
 
+class QGstreamerAudioProbeControl;
 class QGstreamerCaptureSession;
 class QGstreamerCameraControl;
 class QGstreamerMessage;
@@ -92,6 +93,8 @@ private:
     QMediaControl *m_videoWidgetControl;
 #endif
     QGstreamerImageCaptureControl *m_imageCaptureControl;
+
+    QGstreamerAudioProbeControl *m_audioProbeControl;
 };
 
 QT_END_NAMESPACE
diff --git a/src/plugins/gstreamer/mediacapture/qgstreamercaptureserviceplugin.cpp b/src/plugins/gstreamer/mediacapture/qgstreamercaptureserviceplugin.cpp
index 8b88fbb..3866ffd 100644
--- a/src/plugins/gstreamer/mediacapture/qgstreamercaptureserviceplugin.cpp
+++ b/src/plugins/gstreamer/mediacapture/qgstreamercaptureserviceplugin.cpp
@@ -51,9 +51,6 @@
 #include "qgstreamercaptureservice.h"
 #include <private/qgstutils_p.h>
 
-#include <private/qcore_unix_p.h>
-#include <linux/videodev2.h>
-
 QMediaService* QGstreamerCaptureServicePlugin::create(const QString &key)
 {
     QGstUtils::initializeGst();
@@ -87,40 +84,19 @@ QMediaServiceProviderHint::Features QGstreamerCaptureServicePlugin::supportedFea
 
 QByteArray QGstreamerCaptureServicePlugin::defaultDevice(const QByteArray &service) const
 {
-    if (service == Q_MEDIASERVICE_CAMERA) {
-        if (m_cameraDevices.isEmpty())
-            updateDevices();
-
-        return m_defaultCameraDevice;
-    }
-
-    return QByteArray();
+    return service == Q_MEDIASERVICE_CAMERA
+            ? QGstUtils::enumerateCameras().value(0).name.toUtf8()
+            : QByteArray();
 }
 
 QList<QByteArray> QGstreamerCaptureServicePlugin::devices(const QByteArray &service) const
 {
-    if (service == Q_MEDIASERVICE_CAMERA) {
-        if (m_cameraDevices.isEmpty())
-            updateDevices();
-
-        return m_cameraDevices;
-    }
-
-    return QList<QByteArray>();
+    return service == Q_MEDIASERVICE_CAMERA ? QGstUtils::cameraDevices() : QList<QByteArray>();
 }
 
 QString QGstreamerCaptureServicePlugin::deviceDescription(const QByteArray &service, const QByteArray &device)
 {
-    if (service == Q_MEDIASERVICE_CAMERA) {
-        if (m_cameraDevices.isEmpty())
-            updateDevices();
-
-        for (int i=0; i<m_cameraDevices.count(); i++)
-            if (m_cameraDevices[i] == device)
-                return m_cameraDescriptions[i];
-    }
-
-    return QString();
+    return service == Q_MEDIASERVICE_CAMERA ? QGstUtils::cameraDescription(deviceName) : QString();
 }
 
 QVariant QGstreamerCaptureServicePlugin::deviceProperty(const QByteArray &service, const QByteArray &device, const QByteArray &property)
@@ -131,56 +107,6 @@ QVariant QGstreamerCaptureServicePlugin::deviceProperty(const QByteArray &servic
     return QVariant();
 }
 
-void QGstreamerCaptureServicePlugin::updateDevices() const
-{
-    m_defaultCameraDevice.clear();
-    m_cameraDevices.clear();
-    m_cameraDescriptions.clear();
-
-    QDir devDir("/dev");
-    devDir.setFilter(QDir::System);
-
-    QFileInfoList entries = devDir.entryInfoList(QStringList() << "video*");
-
-    foreach( const QFileInfo &entryInfo, entries ) {
-        //qDebug() << "Try" << entryInfo.filePath();
-
-        int fd = qt_safe_open(entryInfo.filePath().toLatin1().constData(), O_RDWR );
-        if (fd == -1)
-            continue;
-
-        bool isCamera = false;
-
-        v4l2_input input;
-        memset(&input, 0, sizeof(input));
-        for (; ::ioctl(fd, VIDIOC_ENUMINPUT, &input) >= 0; ++input.index) {
-            if(input.type == V4L2_INPUT_TYPE_CAMERA || input.type == 0) {
-                isCamera = ::ioctl(fd, VIDIOC_S_INPUT, input.index) != 0;
-                break;
-            }
-        }
-
-        if (isCamera) {
-            // find out its driver "name"
-            QString name;
-            struct v4l2_capability vcap;
-            memset(&vcap, 0, sizeof(struct v4l2_capability));
-
-            if (ioctl(fd, VIDIOC_QUERYCAP, &vcap) != 0)
-                name = entryInfo.fileName();
-            else
-                name = QString((const char*)vcap.card);
-            //qDebug() << "found camera: " << name;
-
-            m_cameraDevices.append(entryInfo.filePath().toLocal8Bit());
-            m_cameraDescriptions.append(name);
-        }
-        qt_safe_close(fd);
-    }
-
-    if (!m_cameraDevices.isEmpty())
-        m_defaultCameraDevice = m_cameraDevices.first();
-}
 #endif
 
 QMultimedia::SupportEstimate QGstreamerCaptureServicePlugin::hasSupport(const QString &mimeType,
@@ -192,90 +118,16 @@ QMultimedia::SupportEstimate QGstreamerCaptureServicePlugin::hasSupport(const QS
     return QGstUtils::hasSupport(mimeType, codecs, m_supportedMimeTypeSet);
 }
 
-void QGstreamerCaptureServicePlugin::updateSupportedMimeTypes() const
-{
-    //enumerate supported mime types
-    gst_init(NULL, NULL);
-
-    GList *plugins, *orig_plugins;
-    orig_plugins = plugins = gst_default_registry_get_plugin_list ();
-
-    while (plugins) {
-        GList *features, *orig_features;
-
-        GstPlugin *plugin = (GstPlugin *) (plugins->data);
-        plugins = g_list_next (plugins);
 
-        if (plugin->flags & (1<<1)) //GST_PLUGIN_FLAG_BLACKLISTED
-            continue;
-
-        orig_features = features = gst_registry_get_feature_list_by_plugin(gst_registry_get_default (),
-                                                                        plugin->desc.name);
-        while (features) {
-            if (!G_UNLIKELY(features->data == NULL)) {
-                GstPluginFeature *feature = GST_PLUGIN_FEATURE(features->data);
-                if (GST_IS_ELEMENT_FACTORY (feature)) {
-                    GstElementFactory *factory = GST_ELEMENT_FACTORY(gst_plugin_feature_load(feature));
-                    if (factory
-                       && factory->numpadtemplates > 0
-                       && (qstrcmp(factory->details.klass, "Codec/Decoder/Audio") == 0
-                          || qstrcmp(factory->details.klass, "Codec/Decoder/Video") == 0
-                          || qstrcmp(factory->details.klass, "Codec/Demux") == 0 )) {
-                        const GList *pads = factory->staticpadtemplates;
-                        while (pads) {
-                            GstStaticPadTemplate *padtemplate = (GstStaticPadTemplate*)(pads->data);
-                            pads = g_list_next (pads);
-                            if (padtemplate->direction != GST_PAD_SINK)
-                                continue;
-                            if (padtemplate->static_caps.string) {
-                                GstCaps *caps = gst_static_caps_get(&padtemplate->static_caps);
-                                if (!gst_caps_is_any (caps) && ! gst_caps_is_empty (caps)) {
-                                    for (guint i = 0; i < gst_caps_get_size(caps); i++) {
-                                        GstStructure *structure = gst_caps_get_structure(caps, i);
-                                        QString nameLowcase = QString(gst_structure_get_name (structure)).toLower();
-
-                                        m_supportedMimeTypeSet.insert(nameLowcase);
-                                        if (nameLowcase.contains("mpeg")) {
-                                            //Because mpeg version number is only included in the detail
-                                            //description,  it is necessary to manually extract this information
-                                            //in order to match the mime type of mpeg4.
-                                            const GValue *value = gst_structure_get_value(structure, "mpegversion");
-                                            if (value) {
-                                                gchar *str = gst_value_serialize (value);
-                                                QString versions(str);
-                                                QStringList elements = versions.split(QRegExp("\\D+"), QString::SkipEmptyParts);
-                                                foreach (const QString &e, elements)
-                                                    m_supportedMimeTypeSet.insert(nameLowcase + e);
-                                                g_free (str);
-                                            }
-                                        }
-                                    }
-                                }
-                                gst_caps_unref(caps);
-                            }
-                        }
-                        gst_object_unref (factory);
-                    }
-                } else if (GST_IS_TYPE_FIND_FACTORY(feature)) {
-                    QString name(gst_plugin_feature_get_name(feature));
-                    if (name.contains('/')) //filter out any string without '/' which is obviously not a mime type
-                        m_supportedMimeTypeSet.insert(name.toLower());
-                }
-            }
-            features = g_list_next (features);
-        }
-        gst_plugin_feature_list_free (orig_features);
-    }
-    gst_plugin_list_free (orig_plugins);
+static bool isEncoderOrMuxer(GstElementFactory *factory)
+{
+    return gst_element_factory_list_is_type(factory, GST_ELEMENT_FACTORY_TYPE_MUXER)
+                || gst_element_factory_list_is_type(factory, GST_ELEMENT_FACTORY_TYPE_ENCODER);
+}
 
-#if defined QT_SUPPORTEDMIMETYPES_DEBUG
-    QStringList list = m_supportedMimeTypeSet.toList();
-    list.sort();
-    if (qgetenv("QT_DEBUG_PLUGINS").toInt() > 0) {
-        foreach (const QString &type, list)
-            qDebug() << type;
-    }
-#endif
+void QGstreamerCaptureServicePlugin::updateSupportedMimeTypes() const
+{
+    m_supportedMimeTypeSet = QGstUtils::supportedMimeTypes(isEncoderOrMuxer);
 }
 
 QStringList QGstreamerCaptureServicePlugin::supportedMimeTypes() const
diff --git a/src/plugins/gstreamer/mediacapture/qgstreamercaptureserviceplugin.h b/src/plugins/gstreamer/mediacapture/qgstreamercaptureserviceplugin.h
index a1141d3..a46be9e 100644
--- a/src/plugins/gstreamer/mediacapture/qgstreamercaptureserviceplugin.h
+++ b/src/plugins/gstreamer/mediacapture/qgstreamercaptureserviceplugin.h
@@ -87,13 +87,6 @@ public:
     QStringList supportedMimeTypes() const;
 
 private:
-#if defined(USE_GSTREAMER_CAMERA)
-    void updateDevices() const;
-
-    mutable QByteArray m_defaultCameraDevice;
-    mutable QList<QByteArray> m_cameraDevices;
-    mutable QStringList m_cameraDescriptions;
-#endif
     void updateSupportedMimeTypes() const;
 
     mutable QSet<QString> m_supportedMimeTypeSet; //for fast access
diff --git a/src/plugins/gstreamer/mediacapture/qgstreamercapturesession.cpp b/src/plugins/gstreamer/mediacapture/qgstreamercapturesession.cpp
index 518a66b..c3112a7 100644
--- a/src/plugins/gstreamer/mediacapture/qgstreamercapturesession.cpp
+++ b/src/plugins/gstreamer/mediacapture/qgstreamercapturesession.cpp
@@ -53,6 +53,7 @@
 
 #include <gst/gsttagsetter.h>
 #include <gst/gstversion.h>
+#include <gst/video/video.h>
 
 #include <QtCore/qdebug.h>
 #include <QtCore/qurl.h>
@@ -60,7 +61,6 @@
 #include <QCoreApplication>
 #include <QtCore/qmetaobject.h>
 #include <QtCore/qfile.h>
-
 #include <QtGui/qimage.h>
 
 QT_BEGIN_NAMESPACE
@@ -72,7 +72,7 @@ QGstreamerCaptureSession::QGstreamerCaptureSession(QGstreamerCaptureSession::Cap
      m_waitingForEos(false),
      m_pipelineMode(EmptyPipeline),
      m_captureMode(captureMode),
-     m_audioBufferProbeId(-1),
+     m_audioProbe(0),
      m_audioInputFactory(0),
      m_audioPreviewFactory(0),
      m_videoInputFactory(0),
@@ -134,8 +134,10 @@ GstElement *QGstreamerCaptureSession::buildEncodeBin()
         return 0;
     }
 
+    // Output location was rejected in setOutputlocation() if not a local file
+    QUrl actualSink = QUrl::fromLocalFile(QDir::currentPath()).resolved(m_sink);
     GstElement *fileSink = gst_element_factory_make("filesink", "filesink");
-    g_object_set(G_OBJECT(fileSink), "location", m_sink.toString().toLocal8Bit().constData(), NULL);
+    g_object_set(G_OBJECT(fileSink), "location", QFile::encodeName(actualSink.toLocalFile()).constData(), NULL);
     gst_bin_add_many(GST_BIN(encodeBin), muxer, fileSink,  NULL);
 
     if (!gst_element_link(muxer, fileSink)) {
@@ -175,7 +177,7 @@ GstElement *QGstreamerCaptureSession::buildEncodeBin()
 
     if (m_captureMode & Video) {
         GstElement *videoQueue = gst_element_factory_make("queue", "video-encode-queue");
-        GstElement *colorspace = gst_element_factory_make("ffmpegcolorspace", "ffmpegcolorspace-encoder");
+        GstElement *colorspace = gst_element_factory_make(QT_GSTREAMER_COLORCONVERSION_ELEMENT_NAME, "videoconvert-encoder");
         GstElement *videoscale = gst_element_factory_make("videoscale","videoscale-encoder");
         gst_bin_add_many(GST_BIN(encodeBin), videoQueue, colorspace, videoscale, NULL);
 
@@ -286,7 +288,7 @@ GstElement *QGstreamerCaptureSession::buildVideoPreview()
 
     if (m_viewfinderInterface) {
         GstElement *bin = gst_bin_new("video-preview-bin");
-        GstElement *colorspace = gst_element_factory_make("ffmpegcolorspace", "ffmpegcolorspace-preview");
+        GstElement *colorspace = gst_element_factory_make(QT_GSTREAMER_COLORCONVERSION_ELEMENT_NAME, "videoconvert-preview");
         GstElement *capsFilter = gst_element_factory_make("capsfilter", "capsfilter-video-preview");
         GstElement *preview = m_viewfinderInterface->videoSink();
 
@@ -305,36 +307,25 @@ GstElement *QGstreamerCaptureSession::buildVideoPreview()
             resolution = m_imageEncodeControl->imageSettings().resolution();
         }
 
-        if (!resolution.isEmpty() || frameRate > 0.001) {
-            GstCaps *caps = gst_caps_new_empty();
-            QStringList structureTypes;
-            structureTypes << "video/x-raw-yuv" << "video/x-raw-rgb";
-
-            foreach(const QString &structureType, structureTypes) {
-                GstStructure *structure = gst_structure_new(structureType.toLatin1().constData(), NULL);
-
-                if (!resolution.isEmpty()) {
-                    gst_structure_set(structure, "width", G_TYPE_INT, resolution.width(), NULL);
-                    gst_structure_set(structure, "height", G_TYPE_INT, resolution.height(), NULL);
-                }
-
-                if (frameRate > 0.001) {
-                    QPair<int,int> rate = m_videoEncodeControl->rateAsRational();
+        GstCaps *caps = QGstUtils::videoFilterCaps();
 
-                    //qDebug() << "frame rate:" << num << denum;
+        if (!resolution.isEmpty()) {
+            gst_caps_set_simple(caps, "width", G_TYPE_INT, resolution.width(), NULL);
+            gst_caps_set_simple(caps, "height", G_TYPE_INT, resolution.height(), NULL);
+        }
+        if (frameRate > 0.001) {
+            QPair<int,int> rate = m_videoEncodeControl->rateAsRational();
 
-                    gst_structure_set(structure, "framerate", GST_TYPE_FRACTION, rate.first, rate.second, NULL);
-                }
+            //qDebug() << "frame rate:" << num << denum;
 
-                gst_caps_append_structure(caps,structure);
-            }
+            gst_caps_set_simple(caps, "framerate", GST_TYPE_FRACTION, rate.first, rate.second, NULL);
+        }
 
-            //qDebug() << "set video preview caps filter:" << gst_caps_to_string(caps);
+        //qDebug() << "set video preview caps filter:" << gst_caps_to_string(caps);
 
-            g_object_set(G_OBJECT(capsFilter), "caps", caps, NULL);
+        g_object_set(G_OBJECT(capsFilter), "caps", caps, NULL);
 
-            gst_caps_unref(caps);
-        }
+        gst_caps_unref(caps);
 
         // add ghostpads
         GstPad *pad = gst_element_get_static_pad(colorspace, "sink");
@@ -348,7 +339,7 @@ GstElement *QGstreamerCaptureSession::buildVideoPreview()
         previewElement = gst_element_factory_make("fakesink", "video-preview");
 #else
         GstElement *bin = gst_bin_new("video-preview-bin");
-        GstElement *colorspace = gst_element_factory_make("ffmpegcolorspace", "ffmpegcolorspace-preview");
+        GstElement *colorspace = gst_element_factory_make(QT_GSTREAMER_COLORCONVERSION_ELEMENT_NAME, "videoconvert-preview");
         GstElement *preview = gst_element_factory_make("ximagesink", "video-preview");
         gst_bin_add_many(GST_BIN(bin), colorspace, preview,  NULL);
         gst_element_link(colorspace,preview);
@@ -366,101 +357,49 @@ GstElement *QGstreamerCaptureSession::buildVideoPreview()
     return previewElement;
 }
 
-
-static gboolean passImageFilter(GstElement *element,
-                                GstBuffer *buffer,
-                                void *appdata)
+void QGstreamerCaptureSession::probeCaps(GstCaps *caps)
 {
-    Q_UNUSED(element);
-    Q_UNUSED(buffer);
-
-    QGstreamerCaptureSession *session = (QGstreamerCaptureSession *)appdata;
-    if (session->m_passImage || session->m_passPrerollImage) {
-        session->m_passImage = false;
-
-        if (session->m_passPrerollImage) {
-            session->m_passPrerollImage = false;
-            return TRUE;
-        }
-        session->m_passPrerollImage = false;
-
-        QImage img;
-
-        GstCaps *caps = gst_buffer_get_caps(buffer);
-        if (caps) {
-            GstStructure *structure = gst_caps_get_structure (caps, 0);
-            gint width = 0;
-            gint height = 0;
-
-            if (structure &&
-                gst_structure_get_int(structure, "width", &width) &&
-                gst_structure_get_int(structure, "height", &height) &&
-                width > 0 && height > 0) {
-                    if (qstrcmp(gst_structure_get_name(structure), "video/x-raw-yuv") == 0) {
-                        guint32 fourcc = 0;
-                        gst_structure_get_fourcc(structure, "format", &fourcc);
-
-                        if (fourcc == GST_MAKE_FOURCC('I','4','2','0')) {
-                            img = QImage(width/2, height/2, QImage::Format_RGB32);
-
-                            const uchar *data = (const uchar *)buffer->data;
+#if GST_CHECK_VERSION(1,0,0)
+    gst_video_info_from_caps(&m_previewInfo, caps);
+#else
+    Q_UNUSED(caps);
+#endif
+}
 
-                            for (int y=0; y<height; y+=2) {
-                                const uchar *yLine = data + y*width;
-                                const uchar *uLine = data + width*height + y*width/4;
-                                const uchar *vLine = data + width*height*5/4 + y*width/4;
+bool QGstreamerCaptureSession::probeBuffer(GstBuffer *buffer)
+{
+    if (m_passPrerollImage) {
+        m_passImage = false;
+        m_passPrerollImage = false;
 
-                                for (int x=0; x<width; x+=2) {
-                                    const qreal Y = 1.164*(yLine[x]-16);
-                                    const int U = uLine[x/2]-128;
-                                    const int V = vLine[x/2]-128;
+        return true;
+    } else  if (!m_passImage) {
+        return false;
+    }
 
-                                    int b = qBound(0, int(Y + 2.018*U), 255);
-                                    int g = qBound(0, int(Y - 0.813*V - 0.391*U), 255);
-                                    int r = qBound(0, int(Y + 1.596*V), 255);
+    m_passImage = false;
 
-                                    img.setPixel(x/2,y/2,qRgb(r,g,b));
-                                }
-                            }
-                        }
+#if GST_CHECK_VERSION(1,0,0)
+    QImage img = QGstUtils::bufferToImage(buffer, m_previewInfo);
+#else
+    QImage img = QGstUtils::bufferToImage(buffer);
+#endif
 
-                    } else if (qstrcmp(gst_structure_get_name(structure), "video/x-raw-rgb") == 0) {
-                        QImage::Format format = QImage::Format_Invalid;
-                        int bpp = 0;
-                        gst_structure_get_int(structure, "bpp", &bpp);
-
-                        if (bpp == 24)
-                            format = QImage::Format_RGB888;
-                        else if (bpp == 32)
-                            format = QImage::Format_RGB32;
-
-                        if (format != QImage::Format_Invalid) {
-                            img = QImage((const uchar *)buffer->data,
-                                         width,
-                                         height,
-                                         format);
-                            img.bits(); //detach
-                        }
-                    }
-            }
-            gst_caps_unref(caps);
-        }
+    if (img.isNull())
+        return true;
 
-        static QMetaMethod exposedSignal = QMetaMethod::fromSignal(&QGstreamerCaptureSession::imageExposed);
-        exposedSignal.invoke(session,
-                             Qt::QueuedConnection,
-                             Q_ARG(int,session->m_imageRequestId));
+    static QMetaMethod exposedSignal = QMetaMethod::fromSignal(&QGstreamerCaptureSession::imageExposed);
+    exposedSignal.invoke(this,
+                         Qt::QueuedConnection,
+                         Q_ARG(int,m_imageRequestId));
 
-        static QMetaMethod capturedSignal = QMetaMethod::fromSignal(&QGstreamerCaptureSession::imageCaptured);
-        capturedSignal.invoke(session,
-                              Qt::QueuedConnection,
-                              Q_ARG(int,session->m_imageRequestId),
-                              Q_ARG(QImage,img));
+    static QMetaMethod capturedSignal = QMetaMethod::fromSignal(&QGstreamerCaptureSession::imageCaptured);
+    capturedSignal.invoke(this,
+                          Qt::QueuedConnection,
+                          Q_ARG(int,m_imageRequestId),
+                          Q_ARG(QImage,img));
 
-        return TRUE;
-    } else {
-        return FALSE;
-    }
+    return true;
 }
 
 static gboolean saveImageFilter(GstElement *element,
@@ -477,7 +416,15 @@ static gboolean saveImageFilter(GstElement *element,
     if (!fileName.isEmpty()) {
         QFile f(fileName);
         if (f.open(QFile::WriteOnly)) {
-            f.write((const char *)buffer->data, buffer->size);
+#if GST_CHECK_VERSION(1,0,0)
+            GstMapInfo info;
+            if (gst_buffer_map(buffer, &info, GST_MAP_READ)) {
+                f.write(reinterpret_cast<const char *>(info.data), info.size);
+                gst_buffer_unmap(buffer, &info);
+            }
+#else
+            f.write(reinterpret_cast<const char *>(buffer->data), buffer->size);
+#endif
             f.close();
 
             static QMetaMethod savedSignal = QMetaMethod::fromSignal(&QGstreamerCaptureSession::imageSaved);
@@ -495,18 +442,19 @@ GstElement *QGstreamerCaptureSession::buildImageCapture()
 {
     GstElement *bin = gst_bin_new("image-capture-bin");
     GstElement *queue = gst_element_factory_make("queue", "queue-image-capture");
-    GstElement *colorspace = gst_element_factory_make("ffmpegcolorspace", "ffmpegcolorspace-image-capture");
+    GstElement *colorspace = gst_element_factory_make(QT_GSTREAMER_COLORCONVERSION_ELEMENT_NAME, "videoconvert-image-capture");
     GstElement *encoder = gst_element_factory_make("jpegenc", "image-encoder");
     GstElement *sink = gst_element_factory_make("fakesink","sink-image-capture");
 
     GstPad *pad = gst_element_get_static_pad(queue, "src");
     Q_ASSERT(pad);
-    gst_pad_add_buffer_probe(pad, G_CALLBACK(passImageFilter), this);
+
+    addProbeToPad(pad, false);
+
     gst_object_unref(GST_OBJECT(pad));
 
     g_object_set(G_OBJECT(sink), "signal-handoffs", TRUE, NULL);
-    g_signal_connect(G_OBJECT(sink), "handoff",
-                     G_CALLBACK(saveImageFilter), this);
+    g_signal_connect(G_OBJECT(sink), "handoff", G_CALLBACK(saveImageFilter), this);
 
     gst_bin_add_many(GST_BIN(bin), queue, colorspace, encoder, sink,  NULL);
     gst_element_link_many(queue, colorspace, encoder, sink, NULL);
@@ -721,6 +669,8 @@ void QGstreamerCaptureSession::dumpGraph(const QString &fileName)
     _gst_debug_bin_to_dot_file(GST_BIN(m_pipeline),
                                GstDebugGraphDetails(/*GST_DEBUG_GRAPH_SHOW_ALL |*/ GST_DEBUG_GRAPH_SHOW_MEDIA_TYPE | GST_DEBUG_GRAPH_SHOW_NON_DEFAULT_PARAMS | GST_DEBUG_GRAPH_SHOW_STATES),
                                fileName.toLatin1());
+#else
+    Q_UNUSED(fileName);
 #endif
 }
 
@@ -731,6 +681,11 @@ QUrl QGstreamerCaptureSession::outputLocation() const
 
 bool QGstreamerCaptureSession::setOutputLocation(const QUrl& sink)
 {
+    if (!sink.isRelative() && !sink.isLocalFile()) {
+        qWarning("Output location must be a local file");
+        return false;
+    }
+
     m_sink = sink;
     return true;
 }
@@ -878,10 +833,8 @@ void QGstreamerCaptureSession::setState(QGstreamerCaptureSession::State newState
 
 qint64 QGstreamerCaptureSession::duration() const
 {
-    GstFormat   format = GST_FORMAT_TIME;
-    gint64      duration = 0;
-
-    if ( m_encodeBin && gst_element_query_position(m_encodeBin, &format, &duration))
+    gint64 duration = 0;
+    if (m_encodeBin && qt_gst_element_query_position(m_encodeBin, GST_FORMAT_TIME, &duration))
         return duration / 1000000;
     else
         return 0;
@@ -897,50 +850,8 @@ void QGstreamerCaptureSession::setMetaData(const QMap<QByteArray, QVariant> &dat
     //qDebug() << "QGstreamerCaptureSession::setMetaData" << data;
     m_metaData = data;
 
-    if (m_encodeBin) {
-        GstIterator *elements = gst_bin_iterate_all_by_interface(GST_BIN(m_encodeBin), GST_TYPE_TAG_SETTER);
-        GstElement *element = 0;
-        while (gst_iterator_next(elements, (void**)&element) == GST_ITERATOR_OK) {
-            //qDebug() << "found element with tag setter interface:" << gst_element_get_name(element);
-            QMapIterator<QByteArray, QVariant> it(data);
-            while (it.hasNext()) {
-                it.next();
-                const QString tagName = it.key();
-                const QVariant tagValue = it.value();
-
-
-                switch(tagValue.type()) {
-                    case QVariant::String:
-                        gst_tag_setter_add_tags(GST_TAG_SETTER(element),
-                            GST_TAG_MERGE_REPLACE_ALL,
-                            tagName.toUtf8().constData(),
-                            tagValue.toString().toUtf8().constData(),
-                            NULL);
-                        break;
-                    case QVariant::Int:
-                    case QVariant::LongLong:
-                        gst_tag_setter_add_tags(GST_TAG_SETTER(element),
-                            GST_TAG_MERGE_REPLACE_ALL,
-                            tagName.toUtf8().constData(),
-                            tagValue.toInt(),
-                            NULL);
-                        break;
-                    case QVariant::Double:
-                        gst_tag_setter_add_tags(GST_TAG_SETTER(element),
-                            GST_TAG_MERGE_REPLACE_ALL,
-                            tagName.toUtf8().constData(),
-                            tagValue.toDouble(),
-                            NULL);
-                        break;
-                    default:
-                        break;
-                }
-
-            }
-
-        }
-        gst_iterator_free(elements);
-    }
+    if (m_encodeBin)
+        QGstUtils::setMetaData(GST_BIN(m_encodeBin), data);
 }
 
 bool QGstreamerCaptureSession::processBusMessage(const QGstreamerMessage &message)
@@ -1059,34 +970,16 @@ void QGstreamerCaptureSession::setVolume(qreal volume)
 
 void QGstreamerCaptureSession::addProbe(QGstreamerAudioProbeControl* probe)
 {
-    QMutexLocker locker(&m_audioProbeMutex);
-
-    if (m_audioProbes.contains(probe))
-        return;
-
-    m_audioProbes.append(probe);
+    Q_ASSERT(!m_audioProbe);
+    m_audioProbe = probe;
+    addAudioBufferProbe();
 }
 
 void QGstreamerCaptureSession::removeProbe(QGstreamerAudioProbeControl* probe)
 {
-    QMutexLocker locker(&m_audioProbeMutex);
-    m_audioProbes.removeOne(probe);
-}
-
-gboolean QGstreamerCaptureSession::padAudioBufferProbe(GstPad *pad, GstBuffer *buffer, gpointer user_data)
-{
-    Q_UNUSED(pad);
-
-    QGstreamerCaptureSession *session = reinterpret_cast<QGstreamerCaptureSession*>(user_data);
-    QMutexLocker locker(&session->m_audioProbeMutex);
-
-    if (session->m_audioProbes.isEmpty())
-        return TRUE;
-
-    foreach (QGstreamerAudioProbeControl* probe, session->m_audioProbes)
-        probe->bufferProbed(buffer);
-
-    return TRUE;
+    Q_ASSERT(m_audioProbe == probe);
+    removeAudioBufferProbe();
+    m_audioProbe = 0;
 }
 
 GstPad *QGstreamerCaptureSession::getAudioProbePad()
@@ -1115,26 +1008,25 @@ GstPad *QGstreamerCaptureSession::getAudioProbePad()
 
 void QGstreamerCaptureSession::removeAudioBufferProbe()
 {
-    if (m_audioBufferProbeId == -1)
+    if (!m_audioProbe)
         return;
 
     GstPad *pad = getAudioProbePad();
     if (pad) {
-        gst_pad_remove_buffer_probe(pad, m_audioBufferProbeId);
-        gst_object_unref(G_OBJECT(pad));
+        m_audioProbe->removeProbeFromPad(pad);
+        gst_object_unref(GST_OBJECT(pad));
     }
-
-    m_audioBufferProbeId = -1;
 }
 
 void QGstreamerCaptureSession::addAudioBufferProbe()
 {
-    Q_ASSERT(m_audioBufferProbeId == -1);
+    if (!m_audioProbe)
+        return;
 
     GstPad *pad = getAudioProbePad();
     if (pad) {
-        m_audioBufferProbeId = gst_pad_add_buffer_probe(pad, G_CALLBACK(padAudioBufferProbe), this);
-        gst_object_unref(G_OBJECT(pad));
+        m_audioProbe->addProbeToPad(pad);
+        gst_object_unref(GST_OBJECT(pad));
     }
 }
 
diff --git a/src/plugins/gstreamer/mediacapture/qgstreamercapturesession.h b/src/plugins/gstreamer/mediacapture/qgstreamercapturesession.h
index 51b2d23..5939d91 100644
--- a/src/plugins/gstreamer/mediacapture/qgstreamercapturesession.h
+++ b/src/plugins/gstreamer/mediacapture/qgstreamercapturesession.h
@@ -49,8 +49,10 @@
 #include <QtCore/qurl.h>
 
 #include <gst/gst.h>
+#include <gst/video/video.h>
 
 #include <private/qgstreamerbushelper_p.h>
+#include <private/qgstreamerbufferprobe_p.h>
 
 QT_BEGIN_NAMESPACE
 
@@ -78,7 +80,10 @@ public:
     virtual QList<QSize> supportedResolutions(qreal frameRate = -1) const = 0;
 };
 
-class QGstreamerCaptureSession : public QObject, public QGstreamerBusMessageFilter
+class QGstreamerCaptureSession
+        : public QObject
+        , public QGstreamerBusMessageFilter
+        , private QGstreamerBufferProbe
 {
     Q_OBJECT
     Q_PROPERTY(qint64 duration READ duration NOTIFY durationChanged)
@@ -139,7 +144,6 @@ public:
 
     void addProbe(QGstreamerAudioProbeControl* probe);
     void removeProbe(QGstreamerAudioProbeControl* probe);
-    static gboolean padAudioBufferProbe(GstPad *pad, GstBuffer *buffer, gpointer user_data);
 
 signals:
     void stateChanged(QGstreamerCaptureSession::State state);
@@ -164,6 +168,9 @@ public slots:
     void setVolume(qreal volume);
 
 private:
+    void probeCaps(GstCaps *caps);
+    bool probeBuffer(GstBuffer *buffer);
+
     enum PipelineMode { EmptyPipeline, PreviewPipeline, RecordingPipeline, PreviewAndRecordingPipeline };
 
     GstElement *buildEncodeBin();
@@ -188,9 +195,7 @@ private:
     QGstreamerCaptureSession::CaptureMode m_captureMode;
     QMap<QByteArray, QVariant> m_metaData;
 
-    QList<QGstreamerAudioProbeControl*> m_audioProbes;
-    QMutex m_audioProbeMutex;
-    int m_audioBufferProbeId;
+    QGstreamerAudioProbeControl *m_audioProbe;
 
     QGstreamerElementFactory *m_audioInputFactory;
     QGstreamerElementFactory *m_audioPreviewFactory;
@@ -225,6 +230,10 @@ private:
 
     GstElement *m_encodeBin;
 
+#if GST_CHECK_VERSION(1,0,0)
+    GstVideoInfo m_previewInfo;
+#endif
+
 public:
     bool m_passImage;
     bool m_passPrerollImage;
diff --git a/src/plugins/gstreamer/mediacapture/qgstreamervideoencode.cpp b/src/plugins/gstreamer/mediacapture/qgstreamervideoencode.cpp
index c297350..f1bdb62 100644
--- a/src/plugins/gstreamer/mediacapture/qgstreamervideoencode.cpp
+++ b/src/plugins/gstreamer/mediacapture/qgstreamervideoencode.cpp
@@ -42,7 +42,7 @@
 #include "qgstreamervideoencode.h"
 #include "qgstreamercapturesession.h"
 #include "qgstreamermediacontainercontrol.h"
-
+#include <private/qgstutils_p.h>
 #include <QtCore/qdebug.h>
 
 #include <math.h>
@@ -155,7 +155,7 @@ GstElement *QGstreamerVideoEncode::createEncoder()
     GstElement *capsFilter = gst_element_factory_make("capsfilter", "capsfilter-video");
     gst_bin_add(encoderBin, capsFilter);
 
-    GstElement *colorspace = gst_element_factory_make("ffmpegcolorspace", NULL);
+    GstElement *colorspace = gst_element_factory_make(QT_GSTREAMER_COLORCONVERSION_ELEMENT_NAME, NULL);
     gst_bin_add(encoderBin, colorspace);
     gst_bin_add(encoderBin, encoderElement);
 
@@ -260,27 +260,22 @@ GstElement *QGstreamerVideoEncode::createEncoder()
     }
 
     if (!m_videoSettings.resolution().isEmpty() || m_videoSettings.frameRate() > 0.001) {
-        GstCaps *caps = gst_caps_new_empty();
-        QStringList structureTypes;
-        structureTypes << "video/x-raw-yuv" << "video/x-raw-rgb";
-
-        foreach(const QString &structureType, structureTypes) {
-            GstStructure *structure = gst_structure_new(structureType.toLatin1().constData(), NULL);
-
-            if (!m_videoSettings.resolution().isEmpty()) {
-                gst_structure_set(structure, "width", G_TYPE_INT, m_videoSettings.resolution().width(), NULL);
-                gst_structure_set(structure, "height", G_TYPE_INT, m_videoSettings.resolution().height(), NULL);
-            }
-
-            if (m_videoSettings.frameRate() > 0.001) {
-                QPair<int,int> rate = rateAsRational();
-
-                //qDebug() << "frame rate:" << num << denum;
-
-                gst_structure_set(structure, "framerate", GST_TYPE_FRACTION, rate.first, rate.second, NULL);
-            }
+        GstCaps *caps = QGstUtils::videoFilterCaps();
+
+        if (!m_videoSettings.resolution().isEmpty()) {
+            gst_caps_set_simple(
+                        caps,
+                        "width", G_TYPE_INT, m_videoSettings.resolution().width(),
+                        "height", G_TYPE_INT, m_videoSettings.resolution().height(),
+                        NULL);
+        }
 
-            gst_caps_append_structure(caps,structure);
+        if (m_videoSettings.frameRate() > 0.001) {
+            QPair<int,int> rate = rateAsRational();
+            gst_caps_set_simple(
+                        caps,
+                        "framerate", GST_TYPE_FRACTION, rate.first, rate.second,
+                        NULL);
         }
 
         //qDebug() << "set video caps filter:" << gst_caps_to_string(caps);
diff --git a/src/plugins/gstreamer/mediaplayer/mediaplayer.pro b/src/plugins/gstreamer/mediaplayer/mediaplayer.pro
index 2ca9377..b986fc7 100644
--- a/src/plugins/gstreamer/mediaplayer/mediaplayer.pro
+++ b/src/plugins/gstreamer/mediaplayer/mediaplayer.pro
@@ -28,4 +28,3 @@ SOURCES += \
 
 OTHER_FILES += \
     mediaplayer.json
-
diff --git a/src/plugins/gstreamer/mediaplayer/qgstreamerplayercontrol.cpp b/src/plugins/gstreamer/mediaplayer/qgstreamerplayercontrol.cpp
index ff99aa3..18ac2c7 100644
--- a/src/plugins/gstreamer/mediaplayer/qgstreamerplayercontrol.cpp
+++ b/src/plugins/gstreamer/mediaplayer/qgstreamerplayercontrol.cpp
@@ -371,7 +371,7 @@ void QGstreamerPlayerControl::setMedia(const QMediaContent &content, QIODevice *
         emit bufferStatusChanged(0);
     }
 
-    if (m_stream) {
+    if (m_stream && m_stream != stream) {
         if (m_ownStream)
             delete m_stream;
         m_stream = 0;
@@ -427,7 +427,6 @@ void QGstreamerPlayerControl::setMedia(const QMediaContent &content, QIODevice *
         m_session->loadFromUri(request);
 #endif
 
-
 #if defined(HAVE_GST_APPSRC)
     if (!request.url().isEmpty() || userStreamValid) {
 #else
@@ -527,6 +526,8 @@ void QGstreamerPlayerControl::processEOS()
         m_session->showPrerollFrames(false); // stop showing prerolled frames in stop state
     }
 
+    qWarning() << "Processing EOS!";
+
     popAndNotifyState();
 }
 
diff --git a/src/plugins/gstreamer/mediaplayer/qgstreamerplayerservice.cpp b/src/plugins/gstreamer/mediaplayer/qgstreamerplayerservice.cpp
index 854da46..8558040 100644
--- a/src/plugins/gstreamer/mediaplayer/qgstreamerplayerservice.cpp
+++ b/src/plugins/gstreamer/mediaplayer/qgstreamerplayerservice.cpp
@@ -59,7 +59,11 @@
 #include <private/qgstreamervideorenderer_p.h>
 
 #if defined(Q_WS_MAEMO_6) && defined(__arm__)
-#include "qgstreamergltexturerenderer.h"
+#include "private/qgstreamergltexturerenderer.h"
+#endif
+
+#if defined(HAVE_MIR) && defined (__arm__)
+#include "private/qgstreamermirtexturerenderer_p.h"
 #endif
 
 #include "qgstreamerstreamscontrol.h"
@@ -74,6 +78,8 @@ QT_BEGIN_NAMESPACE
 
 QGstreamerPlayerService::QGstreamerPlayerService(QObject *parent):
      QMediaService(parent)
+     , m_audioProbeControl(0)
+     , m_videoProbeControl(0)
      , m_videoOutput(0)
      , m_videoRenderer(0)
      , m_videoWindow(0)
@@ -90,6 +96,8 @@ QGstreamerPlayerService::QGstreamerPlayerService(QObject *parent):
 
 #if defined(Q_WS_MAEMO_6) && defined(__arm__)
     m_videoRenderer = new QGstreamerGLTextureRenderer(this);
+#elif defined(HAVE_MIR) && defined (__arm__)
+    m_videoRenderer = new QGstreamerMirTextureRenderer(this, m_session);
 #else
     m_videoRenderer = new QGstreamerVideoRenderer(this);
 #endif
@@ -123,23 +131,23 @@ QMediaControl *QGstreamerPlayerService::requestControl(const char *name)
     if (qstrcmp(name, QMediaAvailabilityControl_iid) == 0)
         return m_availabilityControl;
 
-    if (qstrcmp(name,QMediaVideoProbeControl_iid) == 0) {
-        if (m_session) {
-            QGstreamerVideoProbeControl *probe = new QGstreamerVideoProbeControl(this);
+    if (qstrcmp(name, QMediaVideoProbeControl_iid) == 0) {
+        if (!m_videoProbeControl) {
             increaseVideoRef();
-            m_session->addProbe(probe);
-            return probe;
+            m_videoProbeControl = new QGstreamerVideoProbeControl(this);
+            m_session->addProbe(m_videoProbeControl);
         }
-        return 0;
+        m_videoProbeControl->ref.ref();
+        return m_videoProbeControl;
     }
 
-    if (qstrcmp(name,QMediaAudioProbeControl_iid) == 0) {
-        if (m_session) {
-            QGstreamerAudioProbeControl *probe = new QGstreamerAudioProbeControl(this);
-            m_session->addProbe(probe);
-            return probe;
+    if (qstrcmp(name, QMediaAudioProbeControl_iid) == 0) {
+        if (!m_audioProbeControl) {
+            m_audioProbeControl = new QGstreamerAudioProbeControl(this);
+            m_session->addProbe(m_audioProbeControl);
         }
-        return 0;
+        m_audioProbeControl->ref.ref();
+        return m_audioProbeControl;
     }
 
     if (!m_videoOutput) {
@@ -164,28 +172,21 @@ QMediaControl *QGstreamerPlayerService::requestControl(const char *name)
 
 void QGstreamerPlayerService::releaseControl(QMediaControl *control)
 {
-    if (control == m_videoOutput) {
+    if (!control) {
+        return;
+    } else if (control == m_videoOutput) {
         m_videoOutput = 0;
         m_control->setVideoOutput(0);
         decreaseVideoRef();
-    }
-
-    QGstreamerVideoProbeControl* videoProbe = qobject_cast<QGstreamerVideoProbeControl*>(control);
-    if (videoProbe) {
-        if (m_session) {
-            m_session->removeProbe(videoProbe);
-            decreaseVideoRef();
-        }
-        delete videoProbe;
-        return;
-    }
-
-    QGstreamerAudioProbeControl* audioProbe = qobject_cast<QGstreamerAudioProbeControl*>(control);
-    if (audioProbe) {
-        if (m_session)
-            m_session->removeProbe(audioProbe);
-        delete audioProbe;
-        return;
+    } else if (control == m_videoProbeControl && !m_videoProbeControl->ref.deref()) {
+        m_session->removeProbe(m_videoProbeControl);
+        delete m_videoProbeControl;
+        m_videoProbeControl = 0;
+        decreaseVideoRef();
+    } else if (control == m_audioProbeControl && !m_audioProbeControl->ref.deref()) {
+        m_session->removeProbe(m_audioProbeControl);
+        delete m_audioProbeControl;
+        m_audioProbeControl = 0;
     }
 }
 
diff --git a/src/plugins/gstreamer/mediaplayer/qgstreamerplayerservice.h b/src/plugins/gstreamer/mediaplayer/qgstreamerplayerservice.h
index 691f72c..17e01ae 100644
--- a/src/plugins/gstreamer/mediaplayer/qgstreamerplayerservice.h
+++ b/src/plugins/gstreamer/mediaplayer/qgstreamerplayerservice.h
@@ -60,6 +60,8 @@ class QGstreamerStreamsControl;
 class QGstreamerVideoRenderer;
 class QGstreamerVideoWidgetControl;
 class QGStreamerAvailabilityControl;
+class QGstreamerAudioProbeControl;
+class QGstreamerVideoProbeControl;
 
 class QGstreamerPlayerService : public QMediaService
 {
@@ -78,6 +80,9 @@ private:
     QGstreamerStreamsControl *m_streamsControl;
     QGStreamerAvailabilityControl *m_availabilityControl;
 
+    QGstreamerAudioProbeControl *m_audioProbeControl;
+    QGstreamerVideoProbeControl *m_videoProbeControl;
+
     QMediaControl *m_videoOutput;
     QMediaControl *m_videoRenderer;
     QMediaControl *m_videoWindow;
diff --git a/src/plugins/gstreamer/mediaplayer/qgstreamerplayerserviceplugin.cpp b/src/plugins/gstreamer/mediaplayer/qgstreamerplayerserviceplugin.cpp
index a9052ca..0e515d8 100644
--- a/src/plugins/gstreamer/mediaplayer/qgstreamerplayerserviceplugin.cpp
+++ b/src/plugins/gstreamer/mediaplayer/qgstreamerplayerserviceplugin.cpp
@@ -89,89 +89,15 @@ QMultimedia::SupportEstimate QGstreamerPlayerServicePlugin::hasSupport(const QSt
     return QGstUtils::hasSupport(mimeType, codecs, m_supportedMimeTypeSet);
 }
 
-void QGstreamerPlayerServicePlugin::updateSupportedMimeTypes() const
+static bool isDecoderOrDemuxer(GstElementFactory *factory)
 {
-    //enumerate supported mime types
-    gst_init(NULL, NULL);
-
-    GList *plugins, *orig_plugins;
-    orig_plugins = plugins = gst_default_registry_get_plugin_list ();
-
-    while (plugins) {
-        GList *features, *orig_features;
-
-        GstPlugin *plugin = (GstPlugin *) (plugins->data);
-        plugins = g_list_next (plugins);
-
-        if (plugin->flags & (1<<1)) //GST_PLUGIN_FLAG_BLACKLISTED
-            continue;
-
-        orig_features = features = gst_registry_get_feature_list_by_plugin(gst_registry_get_default (),
-                                                                        plugin->desc.name);
-        while (features) {
-            if (!G_UNLIKELY(features->data == NULL)) {
-                GstPluginFeature *feature = GST_PLUGIN_FEATURE(features->data);
-                if (GST_IS_ELEMENT_FACTORY (feature)) {
-                    GstElementFactory *factory = GST_ELEMENT_FACTORY(gst_plugin_feature_load(feature));
-                    if (factory
-                       && factory->numpadtemplates > 0
-                       && (qstrcmp(factory->details.klass, "Codec/Decoder/Audio") == 0
-                          || qstrcmp(factory->details.klass, "Codec/Decoder/Video") == 0
-                          || qstrcmp(factory->details.klass, "Codec/Demux") == 0 )) {
-                        const GList *pads = factory->staticpadtemplates;
-                        while (pads) {
-                            GstStaticPadTemplate *padtemplate = (GstStaticPadTemplate*)(pads->data);
-                            pads = g_list_next (pads);
-                            if (padtemplate->direction != GST_PAD_SINK)
-                                continue;
-                            if (padtemplate->static_caps.string) {
-                                GstCaps *caps = gst_static_caps_get(&padtemplate->static_caps);
-                                if (!gst_caps_is_any (caps) && ! gst_caps_is_empty (caps)) {
-                                    for (guint i = 0; i < gst_caps_get_size(caps); i++) {
-                                        GstStructure *structure = gst_caps_get_structure(caps, i);
-                                        QString nameLowcase = QString(gst_structure_get_name (structure)).toLower();
-
-                                        m_supportedMimeTypeSet.insert(nameLowcase);
-                                        if (nameLowcase.contains("mpeg")) {
-                                            //Because mpeg version number is only included in the detail
-                                            //description,  it is necessary to manually extract this information
-                                            //in order to match the mime type of mpeg4.
-                                            const GValue *value = gst_structure_get_value(structure, "mpegversion");
-                                            if (value) {
-                                                gchar *str = gst_value_serialize (value);
-                                                QString versions(str);
-                                                QStringList elements = versions.split(QRegExp("\\D+"), QString::SkipEmptyParts);
-                                                foreach (const QString &e, elements)
-                                                    m_supportedMimeTypeSet.insert(nameLowcase + e);
-                                                g_free (str);
-                                            }
-                                        }
-                                    }
-                                }
-                            }
-                        }
-                        gst_object_unref (factory);
-                    }
-                } else if (GST_IS_TYPE_FIND_FACTORY(feature)) {
-                    QString name(gst_plugin_feature_get_name(feature));
-                    if (name.contains('/')) //filter out any string without '/' which is obviously not a mime type
-                        m_supportedMimeTypeSet.insert(name.toLower());
-                }
-            }
-            features = g_list_next (features);
-        }
-        gst_plugin_feature_list_free (orig_features);
-    }
-    gst_plugin_list_free (orig_plugins);
+    return gst_element_factory_list_is_type(factory, GST_ELEMENT_FACTORY_TYPE_DEMUXER)
+                || gst_element_factory_list_is_type(factory, GST_ELEMENT_FACTORY_TYPE_DECODER);
+}
 
-#if defined QT_SUPPORTEDMIMETYPES_DEBUG
-    QStringList list = m_supportedMimeTypeSet.toList();
-    list.sort();
-    if (qgetenv("QT_DEBUG_PLUGINS").toInt() > 0) {
-        foreach (const QString &type, list)
-            qDebug() << type;
-    }
-#endif
+void QGstreamerPlayerServicePlugin::updateSupportedMimeTypes() const
+{
+     m_supportedMimeTypeSet = QGstUtils::supportedMimeTypes(isDecoderOrDemuxer);
 }
 
 QStringList QGstreamerPlayerServicePlugin::supportedMimeTypes() const
diff --git a/src/plugins/gstreamer/mediaplayer/qgstreamerplayersession.cpp b/src/plugins/gstreamer/mediaplayer/qgstreamerplayersession.cpp
index 87b71d7..7d749c7 100644
--- a/src/plugins/gstreamer/mediaplayer/qgstreamerplayersession.cpp
+++ b/src/plugins/gstreamer/mediaplayer/qgstreamerplayersession.cpp
@@ -93,6 +93,7 @@ typedef enum {
     GST_PLAY_FLAG_BUFFERING     = 0x000000100
 } GstPlayFlags;
 
+#if !GST_CHECK_VERSION(1,0,0)
 #define DEFAULT_RAW_CAPS \
     "video/x-raw-yuv; " \
     "video/x-raw-rgb; " \
@@ -105,7 +106,9 @@ typedef enum {
     "text/x-pango-markup; " \
     "video/x-dvd-subpicture; " \
     "subpicture/x-pgs"
+
 static GstStaticCaps static_RawCaps = GST_STATIC_CAPS(DEFAULT_RAW_CAPS);
+#endif
 
 QGstreamerPlayerSession::QGstreamerPlayerSession(QObject *parent)
     :QObject(parent),
@@ -113,7 +116,9 @@ QGstreamerPlayerSession::QGstreamerPlayerSession(QObject *parent)
      m_pendingState(QMediaPlayer::StoppedState),
      m_busHelper(0),
      m_playbin(0),
+#if !GST_CHECK_VERSION(1,0,0)
      m_usingColorspaceElement(false),
+#endif
      m_videoSink(0),
      m_pendingVideoSink(0),
      m_nullVideoSink(0),
@@ -125,8 +130,8 @@ QGstreamerPlayerSession::QGstreamerPlayerSession(QObject *parent)
 #if defined(HAVE_GST_APPSRC)
      m_appSrc(0),
 #endif
-     m_videoBufferProbeId(-1),
-     m_audioBufferProbeId(-1),
+     m_videoProbe(0),
+     m_audioProbe(0),
      m_volume(100),
      m_playbackRate(1.0),
      m_muted(false),
@@ -146,8 +151,7 @@ QGstreamerPlayerSession::QGstreamerPlayerSession(QObject *parent)
     Q_ASSERT(result == TRUE);
     Q_UNUSED(result);
 
-    m_playbin = gst_element_factory_make("playbin2", NULL);
-
+    m_playbin = gst_element_factory_make(QT_GSTREAMER_PLAYBIN_ELEMENT_NAME, NULL);
     if (m_playbin) {
         //GST_PLAY_FLAG_NATIVE_VIDEO omits configuration of ffmpegcolorspace and videoscale,
         //since those elements are included in the video output bin when necessary.
@@ -155,13 +159,14 @@ QGstreamerPlayerSession::QGstreamerPlayerSession(QObject *parent)
         int flags = GST_PLAY_FLAG_VIDEO | GST_PLAY_FLAG_AUDIO |
                     GST_PLAY_FLAG_NATIVE_VIDEO | GST_PLAY_FLAG_NATIVE_AUDIO;
 #else
-        int flags = 0;
-        g_object_get(G_OBJECT(m_playbin), "flags", &flags, NULL);
+        int flags = GST_PLAY_FLAG_VIDEO | GST_PLAY_FLAG_AUDIO;
         QByteArray envFlags = qgetenv("QT_GSTREAMER_PLAYBIN_FLAGS");
         if (!envFlags.isEmpty()) {
             flags |= envFlags.toInt();
+#if !GST_CHECK_VERSION(1,0,0)
         } else {
             flags |= GST_PLAY_FLAG_NATIVE_VIDEO;
+#endif
         }
 #endif
         g_object_set(G_OBJECT(m_playbin), "flags", flags, NULL);
@@ -193,12 +198,16 @@ QGstreamerPlayerSession::QGstreamerPlayerSession(QObject *parent)
         }
     }
 
+#if GST_CHECK_VERSION(1,0,0)
+    m_videoIdentity = gst_element_factory_make("identity", NULL); // floating ref
+#else
     m_videoIdentity = GST_ELEMENT(g_object_new(gst_video_connector_get_type(), 0)); // floating ref
     g_signal_connect(G_OBJECT(m_videoIdentity), "connection-failed", G_CALLBACK(insertColorSpaceElement), (gpointer)this);
+    m_colorSpace = gst_element_factory_make(QT_GSTREAMER_COLORCONVERSION_ELEMENT_NAME, "ffmpegcolorspace-vo");
 
-    m_colorSpace = gst_element_factory_make("ffmpegcolorspace", "ffmpegcolorspace-vo");
     // might not get a parent, take ownership to avoid leak
     qt_gst_object_ref_sink(GST_OBJECT(m_colorSpace));
+#endif
 
     m_nullVideoSink = gst_element_factory_make("fakesink", NULL);
     g_object_set(G_OBJECT(m_nullVideoSink), "sync", true, NULL);
@@ -214,7 +223,7 @@ QGstreamerPlayerSession::QGstreamerPlayerSession(QObject *parent)
 
     // add ghostpads
     GstPad *pad = gst_element_get_static_pad(m_videoIdentity,"sink");
-    gst_element_add_pad(GST_ELEMENT(m_videoOutputBin), gst_ghost_pad_new("videosink", pad));
+    gst_element_add_pad(GST_ELEMENT(m_videoOutputBin), gst_ghost_pad_new("sink", pad));
     gst_object_unref(GST_OBJECT(pad));
 
     if (m_playbin != 0) {
@@ -252,7 +261,9 @@ QGstreamerPlayerSession::~QGstreamerPlayerSession()
         delete m_busHelper;
         gst_object_unref(GST_OBJECT(m_bus));
         gst_object_unref(GST_OBJECT(m_playbin));
+#if !GST_CHECK_VERSION(1,0,0)
         gst_object_unref(GST_OBJECT(m_colorSpace));
+#endif
         gst_object_unref(GST_OBJECT(m_nullVideoSink));
         gst_object_unref(GST_OBJECT(m_videoOutputBin));
     }
@@ -347,12 +358,10 @@ qint64 QGstreamerPlayerSession::duration() const
 
 qint64 QGstreamerPlayerSession::position() const
 {
-    GstFormat   format = GST_FORMAT_TIME;
     gint64      position = 0;
 
-    if ( m_playbin && gst_element_query_position(m_playbin, &format, &position))
+    if (m_playbin && qt_gst_element_query_position(m_playbin, GST_FORMAT_TIME, &position))
         m_lastPosition = position / 1000000;
-
     return m_lastPosition;
 }
 
@@ -482,17 +491,26 @@ bool QGstreamerPlayerSession::isAudioAvailable() const
     return m_audioAvailable;
 }
 
+#if GST_CHECK_VERSION(1,0,0)
+static GstPadProbeReturn block_pad_cb(GstPad *pad, GstPadProbeInfo *info, gpointer user_data)
+#else
 static void block_pad_cb(GstPad *pad, gboolean blocked, gpointer user_data)
+#endif
 {
     Q_UNUSED(pad);
+#if GST_CHECK_VERSION(1,0,0)
+    Q_UNUSED(info);
+    Q_UNUSED(user_data);
+    return GST_PAD_PROBE_OK;
+#else
 #ifdef DEBUG_PLAYBIN
     qDebug() << "block_pad_cb, blocked:" << blocked;
 #endif
-
     if (blocked && user_data) {
         QGstreamerPlayerSession *session = reinterpret_cast<QGstreamerPlayerSession*>(user_data);
         QMetaObject::invokeMethod(session, "finishVideoOutputChange", Qt::QueuedConnection);
     }
+#endif
 }
 
 void QGstreamerPlayerSession::updateVideoRenderer()
@@ -537,7 +555,7 @@ void QGstreamerPlayerSession::setVideoRenderer(QObject *videoOutput)
     m_renderer = renderer;
 
 #ifdef DEBUG_VO_BIN_DUMP
-    _gst_debug_bin_to_dot_file_with_ts(GST_BIN(m_playbin),
+    gst_debug_bin_to_dot_file_with_ts(GST_BIN(m_playbin),
                                   GstDebugGraphDetails(GST_DEBUG_GRAPH_SHOW_ALL /* GST_DEBUG_GRAPH_SHOW_MEDIA_TYPE | GST_DEBUG_GRAPH_SHOW_NON_DEFAULT_PARAMS | GST_DEBUG_GRAPH_SHOW_STATES*/),
                                   "playbin_set");
 #endif
@@ -578,12 +596,14 @@ void QGstreamerPlayerSession::setVideoRenderer(QObject *videoOutput)
         gst_element_set_state(m_videoSink, GST_STATE_NULL);
         gst_element_set_state(m_playbin, GST_STATE_NULL);
 
+#if !GST_CHECK_VERSION(1,0,0)
         if (m_usingColorspaceElement) {
             gst_element_unlink(m_colorSpace, m_videoSink);
             gst_bin_remove(GST_BIN(m_videoOutputBin), m_colorSpace);
         } else {
             gst_element_unlink(m_videoIdentity, m_videoSink);
         }
+#endif
 
         removeVideoBufferProbe();
 
@@ -593,8 +613,9 @@ void QGstreamerPlayerSession::setVideoRenderer(QObject *videoOutput)
 
         gst_bin_add(GST_BIN(m_videoOutputBin), m_videoSink);
 
-        m_usingColorspaceElement = false;
         bool linked = gst_element_link(m_videoIdentity, m_videoSink);
+#if !GST_CHECK_VERSION(1,0,0)
+        m_usingColorspaceElement = false;
         if (!linked) {
             m_usingColorspaceElement = true;
 #ifdef DEBUG_PLAYBIN
@@ -603,6 +624,10 @@ void QGstreamerPlayerSession::setVideoRenderer(QObject *videoOutput)
             gst_bin_add(GST_BIN(m_videoOutputBin), m_colorSpace);
             linked = gst_element_link_many(m_videoIdentity, m_colorSpace, m_videoSink, NULL);
         }
+#endif
+
+        if (!linked)
+            qWarning() << "Linking video output element failed";
 
         if (g_object_class_find_property(G_OBJECT_GET_CLASS(m_videoSink), "show-preroll-frame") != 0) {
             gboolean value = m_displayPrerolledFrame;
@@ -641,7 +666,11 @@ void QGstreamerPlayerSession::setVideoRenderer(QObject *videoOutput)
 
         //block pads, async to avoid locking in paused state
         GstPad *srcPad = gst_element_get_static_pad(m_videoIdentity, "src");
+#if GST_CHECK_VERSION(1,0,0)
+        this->pad_probe_id = gst_pad_add_probe(srcPad, (GstPadProbeType)(GST_PAD_PROBE_TYPE_BUFFER | GST_PAD_PROBE_TYPE_BLOCKING), block_pad_cb, this, NULL);
+#else
         gst_pad_set_blocked_async(srcPad, true, &block_pad_cb, this);
+#endif
         gst_object_unref(GST_OBJECT(srcPad));
 
         //Unpause the sink to avoid waiting until the buffer is processed
@@ -679,16 +708,22 @@ void QGstreamerPlayerSession::finishVideoOutputChange()
     }
 
     if (m_pendingVideoSink == m_videoSink) {
+        qDebug() << "Abort, no change";
         //video output was change back to the current one,
         //no need to torment the pipeline, just unblock the pad
         if (gst_pad_is_blocked(srcPad))
+#if GST_CHECK_VERSION(1,0,0)
+            gst_pad_remove_probe(srcPad, this->pad_probe_id);
+#else
             gst_pad_set_blocked_async(srcPad, false, &block_pad_cb, 0);
+#endif
 
         m_pendingVideoSink = 0;
         gst_object_unref(GST_OBJECT(srcPad));
         return;
     }
 
+#if !GST_CHECK_VERSION(1,0,0)
     if (m_usingColorspaceElement) {
         gst_element_set_state(m_colorSpace, GST_STATE_NULL);
         gst_element_set_state(m_videoSink, GST_STATE_NULL);
@@ -696,6 +731,9 @@ void QGstreamerPlayerSession::finishVideoOutputChange()
         gst_element_unlink(m_colorSpace, m_videoSink);
         gst_bin_remove(GST_BIN(m_videoOutputBin), m_colorSpace);
     } else {
+#else
+    {
+#endif
         gst_element_set_state(m_videoSink, GST_STATE_NULL);
         gst_element_unlink(m_videoIdentity, m_videoSink);
     }
@@ -711,8 +749,9 @@ void QGstreamerPlayerSession::finishVideoOutputChange()
 
     addVideoBufferProbe();
 
-    m_usingColorspaceElement = false;
     bool linked = gst_element_link(m_videoIdentity, m_videoSink);
+#if !GST_CHECK_VERSION(1,0,0)
+    m_usingColorspaceElement = false;
     if (!linked) {
         m_usingColorspaceElement = true;
 #ifdef DEBUG_PLAYBIN
@@ -721,6 +760,7 @@ void QGstreamerPlayerSession::finishVideoOutputChange()
         gst_bin_add(GST_BIN(m_videoOutputBin), m_colorSpace);
         linked = gst_element_link_many(m_videoIdentity, m_colorSpace, m_videoSink, NULL);
     }
+#endif
 
     if (!linked)
         qWarning() << "Linking video output element failed";
@@ -728,6 +768,8 @@ void QGstreamerPlayerSession::finishVideoOutputChange()
 #ifdef DEBUG_PLAYBIN
     qDebug() << "notify the video connector it has to emit a new segment message...";
 #endif
+
+#if !GST_CHECK_VERSION(1,0,0)
     //it's necessary to send a new segment event just before
     //the first buffer pushed to the new sink
     g_signal_emit_by_name(m_videoIdentity,
@@ -735,7 +777,7 @@ void QGstreamerPlayerSession::finishVideoOutputChange()
                           true //emit connection-failed signal
                                //to have a chance to insert colorspace element
                           );
-
+#endif
 
     GstState state = GST_STATE_VOID_PENDING;
 
@@ -751,8 +793,10 @@ void QGstreamerPlayerSession::finishVideoOutputChange()
         break;
     }
 
+#if !GST_CHECK_VERSION(1,0,0)
     if (m_usingColorspaceElement)
         gst_element_set_state(m_colorSpace, state);
+#endif
 
     gst_element_set_state(m_videoSink, state);
 
@@ -768,16 +812,23 @@ void QGstreamerPlayerSession::finishVideoOutputChange()
 
     //don't have to wait here, it will unblock eventually
     if (gst_pad_is_blocked(srcPad))
-        gst_pad_set_blocked_async(srcPad, false, &block_pad_cb, 0);
+#if GST_CHECK_VERSION(1,0,0)
+            gst_pad_remove_probe(srcPad, this->pad_probe_id);
+#else
+            gst_pad_set_blocked_async(srcPad, false, &block_pad_cb, 0);
+#endif
+
     gst_object_unref(GST_OBJECT(srcPad));
 
 #ifdef DEBUG_VO_BIN_DUMP
-    _gst_debug_bin_to_dot_file_with_ts(GST_BIN(m_playbin),
-                                  GstDebugGraphDetails(GST_DEBUG_GRAPH_SHOW_ALL /* GST_DEBUG_GRAPH_SHOW_MEDIA_TYPE | GST_DEBUG_GRAPH_SHOW_NON_DEFAULT_PARAMS | GST_DEBUG_GRAPH_SHOW_STATES*/),
+    gst_debug_bin_to_dot_file_with_ts(GST_BIN(m_playbin),
+                                  GstDebugGraphDetails(GST_DEBUG_GRAPH_SHOW_ALL /* | GST_DEBUG_GRAPH_SHOW_MEDIA_TYPE | GST_DEBUG_GRAPH_SHOW_NON_DEFAULT_PARAMS | GST_DEBUG_GRAPH_SHOW_STATES */),
                                   "playbin_finish");
 #endif
 }
 
+#if !GST_CHECK_VERSION(1,0,0)
+
 void QGstreamerPlayerSession::insertColorSpaceElement(GstElement *element, gpointer data)
 {
 #ifdef DEBUG_PLAYBIN
@@ -822,6 +873,7 @@ void QGstreamerPlayerSession::insertColorSpaceElement(GstElement *element, gpoin
     gst_element_set_state(session->m_colorSpace, state);
 }
 
+#endif
 
 bool QGstreamerPlayerSession::isVideoAvailable() const
 {
@@ -838,6 +890,7 @@ bool QGstreamerPlayerSession::play()
 #ifdef DEBUG_PLAYBIN
     qDebug() << Q_FUNC_INFO;
 #endif
+
     m_everPlayed = false;
     if (m_playbin) {
         m_pendingState = QMediaPlayer::PlayingState;
@@ -1169,21 +1222,20 @@ bool QGstreamerPlayerSession::processBusMessage(const QGstreamerMessage &message
             case GST_MESSAGE_SEGMENT_DONE:
                 break;
             case GST_MESSAGE_LATENCY:
-#if (GST_VERSION_MAJOR >= 0) &&  (GST_VERSION_MINOR >= 10) && (GST_VERSION_MICRO >= 13)
+#if GST_CHECK_VERSION(0,10,13)
             case GST_MESSAGE_ASYNC_START:
                 break;
             case GST_MESSAGE_ASYNC_DONE:
             {
-                GstFormat   format = GST_FORMAT_TIME;
                 gint64      position = 0;
-                if (gst_element_query_position(m_playbin, &format, &position)) {
+                if (qt_gst_element_query_position(m_playbin, GST_FORMAT_TIME, &position)) {
                     position /= 1000000;
                     m_lastPosition = position;
                     emit positionChanged(position);
                 }
                 break;
             }
-#if GST_VERSION_MICRO >= 23
+#if GST_CHECK_VERSION(0,10,23)
             case GST_MESSAGE_REQUEST_STATE:
 #endif
 #endif
@@ -1335,8 +1387,11 @@ void QGstreamerPlayerSession::getStreamsInfo()
         default:
             break;
         }
-
+#if GST_CHECK_VERSION(1,0,0)
+        if (tags && GST_IS_TAG_LIST(tags)) {
+#else
         if (tags && gst_is_tag_list(tags)) {
+#endif
             gchar *languageCode = 0;
             if (gst_tag_list_get_string(tags, GST_TAG_LANGUAGE_CODE, &languageCode))
                 streamProperties[QMediaMetaData::Language] = QString::fromUtf8(languageCode);
@@ -1373,9 +1428,8 @@ void QGstreamerPlayerSession::updateVideoResolutionTag()
 #endif
     QSize size;
     QSize aspectRatio;
-
     GstPad *pad = gst_element_get_static_pad(m_videoIdentity, "src");
-    GstCaps *caps = gst_pad_get_negotiated_caps(pad);
+    GstCaps *caps = qt_gst_pad_get_current_caps(pad);
 
     if (caps) {
         const GstStructure *structure = gst_caps_get_structure(caps, 0);
@@ -1415,11 +1469,10 @@ void QGstreamerPlayerSession::updateVideoResolutionTag()
 
 void QGstreamerPlayerSession::updateDuration()
 {
-    GstFormat format = GST_FORMAT_TIME;
     gint64 gstDuration = 0;
     int duration = -1;
 
-    if (m_playbin && gst_element_query_duration(m_playbin, &format, &gstDuration))
+    if (m_playbin && qt_gst_element_query_duration(m_playbin, GST_FORMAT_TIME, &gstDuration))
         duration = gstDuration / 1000000;
 
     if (m_duration != duration) {
@@ -1475,7 +1528,7 @@ void QGstreamerPlayerSession::playbinNotifySource(GObject *o, GParamSpec *p, gpo
 
     // The rest
     if (g_object_class_find_property(G_OBJECT_GET_CLASS(source), "extra-headers") != 0) {
-        GstStructure *extras = gst_structure_empty_new("extras");
+        GstStructure *extras = qt_gst_structure_new_empty("extras");
 
         foreach (const QByteArray &rawHeader, self->m_request.rawHeaderList()) {
             if (rawHeader == userAgentString) // Filter User-Agent
@@ -1523,6 +1576,7 @@ void QGstreamerPlayerSession::playbinNotifySource(GObject *o, GParamSpec *p, gpo
         //rtspsrc acts like a live source and will therefore only generate data in the PLAYING state.
         self->m_sourceType = RTSPSrc;
         self->m_isLiveSource = true;
+        g_object_set(G_OBJECT(source), "buffer-mode", 1, NULL);
     } else {
         self->m_sourceType = UnknownSrc;
         self->m_isLiveSource = gst_base_src_is_live(GST_BASE_SRC(source));
@@ -1535,7 +1589,8 @@ void QGstreamerPlayerSession::playbinNotifySource(GObject *o, GParamSpec *p, gpo
         qDebug() << "Current source is a non-live source";
 #endif
 
-    g_object_set(G_OBJECT(self->m_videoSink), "sync", !self->m_isLiveSource, NULL);
+    if (self->m_videoSink)
+        g_object_set(G_OBJECT(self->m_videoSink), "sync", !self->m_isLiveSource, NULL);
 
     gst_object_unref(source);
 }
@@ -1630,7 +1685,11 @@ GstAutoplugSelectResult QGstreamerPlayerSession::handleAutoplugSelect(GstBin *bi
     const gchar *factoryName = gst_plugin_feature_get_name(GST_PLUGIN_FEATURE(factory));
     if (g_str_has_prefix(factoryName, "vaapi")) {
         GstPad *sinkPad = gst_element_get_static_pad(session->m_videoSink, "sink");
+#if GST_CHECK_VERSION(1,0,0)
+        GstCaps *sinkCaps = gst_pad_query_caps(sinkPad, NULL);
+#else
         GstCaps *sinkCaps = gst_pad_get_caps(sinkPad);
+#endif
 
 #if (GST_VERSION_MAJOR == 0) && ((GST_VERSION_MINOR < 10) || (GST_VERSION_MICRO < 33))
         if (!factory_can_src_any_caps(factory, sinkCaps))
@@ -1659,8 +1718,10 @@ void QGstreamerPlayerSession::handleElementAdded(GstBin *bin, GstElement *elemen
         // Disable on-disk buffering.
         g_object_set(G_OBJECT(element), "temp-template", NULL, NULL);
     } else if (g_str_has_prefix(elementName, "uridecodebin") ||
-               g_str_has_prefix(elementName, "decodebin2")) {
-
+#if GST_CHECK_VERSION(1,0,0)
+        g_str_has_prefix(elementName, "decodebin")) {
+#else
+        g_str_has_prefix(elementName, "decodebin2")) {
         if (g_str_has_prefix(elementName, "uridecodebin")) {
             // Add video/x-surface (VAAPI) to default raw formats
             g_object_set(G_OBJECT(element), "caps", gst_static_caps_get(&static_RawCaps), NULL);
@@ -1668,7 +1729,7 @@ void QGstreamerPlayerSession::handleElementAdded(GstBin *bin, GstElement *elemen
             // video sink doesn't support it
             g_signal_connect(element, "autoplug-select", G_CALLBACK(handleAutoplugSelect), session);
         }
-
+#endif
         //listen for queue2 element added to uridecodebin/decodebin2 as well.
         //Don't touch other bins since they may have unrelated queues
         g_signal_connect(element, "element-added",
@@ -1718,68 +1779,30 @@ void QGstreamerPlayerSession::showPrerollFrames(bool enabled)
 
 void QGstreamerPlayerSession::addProbe(QGstreamerVideoProbeControl* probe)
 {
-    QMutexLocker locker(&m_videoProbeMutex);
-
-    if (m_videoProbes.contains(probe))
-        return;
-
-    m_videoProbes.append(probe);
+    Q_ASSERT(!m_videoProbe);
+    m_videoProbe = probe;
+    addVideoBufferProbe();
 }
 
 void QGstreamerPlayerSession::removeProbe(QGstreamerVideoProbeControl* probe)
 {
-    QMutexLocker locker(&m_videoProbeMutex);
-    m_videoProbes.removeOne(probe);
-    // Do not emit flush signal in this case.
-    // Assume user releases any outstanding references to video frames.
-}
-
-gboolean QGstreamerPlayerSession::padVideoBufferProbe(GstPad *pad, GstBuffer *buffer, gpointer user_data)
-{
-    Q_UNUSED(pad);
-
-    QGstreamerPlayerSession *session = reinterpret_cast<QGstreamerPlayerSession*>(user_data);
-    QMutexLocker locker(&session->m_videoProbeMutex);
-
-    if (session->m_videoProbes.isEmpty())
-        return TRUE;
-
-    foreach (QGstreamerVideoProbeControl* probe, session->m_videoProbes)
-        probe->bufferProbed(buffer);
-
-    return TRUE;
+    Q_ASSERT(m_videoProbe == probe);
+    removeVideoBufferProbe();
+    m_videoProbe = 0;
 }
 
 void QGstreamerPlayerSession::addProbe(QGstreamerAudioProbeControl* probe)
 {
-    QMutexLocker locker(&m_audioProbeMutex);
-
-    if (m_audioProbes.contains(probe))
-        return;
-
-    m_audioProbes.append(probe);
+    Q_ASSERT(!m_audioProbe);
+    m_audioProbe = probe;
+    addAudioBufferProbe();
 }
 
 void QGstreamerPlayerSession::removeProbe(QGstreamerAudioProbeControl* probe)
 {
-    QMutexLocker locker(&m_audioProbeMutex);
-    m_audioProbes.removeOne(probe);
-}
-
-gboolean QGstreamerPlayerSession::padAudioBufferProbe(GstPad *pad, GstBuffer *buffer, gpointer user_data)
-{
-    Q_UNUSED(pad);
-
-    QGstreamerPlayerSession *session = reinterpret_cast<QGstreamerPlayerSession*>(user_data);
-    QMutexLocker locker(&session->m_audioProbeMutex);
-
-    if (session->m_audioProbes.isEmpty())
-        return TRUE;
-
-    foreach (QGstreamerAudioProbeControl* probe, session->m_audioProbes)
-        probe->bufferProbed(buffer);
-
-    return TRUE;
+    Q_ASSERT(m_audioProbe == probe);
+    removeAudioBufferProbe();
+    m_audioProbe = 0;
 }
 
 // This function is similar to stop(),
@@ -1804,80 +1827,62 @@ void QGstreamerPlayerSession::endOfMediaReset()
 
 void QGstreamerPlayerSession::removeVideoBufferProbe()
 {
-    if (m_videoBufferProbeId == -1)
+    if (!m_videoProbe)
         return;
 
-    if (!m_videoSink) {
-        m_videoBufferProbeId = -1;
-        return;
-    }
-
     GstPad *pad = gst_element_get_static_pad(m_videoSink, "sink");
     if (pad) {
-        gst_pad_remove_buffer_probe(pad, m_videoBufferProbeId);
+        m_videoProbe->removeProbeFromPad(pad);
         gst_object_unref(GST_OBJECT(pad));
     }
-
-    m_videoBufferProbeId = -1;
 }
 
 void QGstreamerPlayerSession::addVideoBufferProbe()
 {
-    Q_ASSERT(m_videoBufferProbeId == -1);
-    if (!m_videoSink)
+    if (!m_videoProbe)
         return;
 
     GstPad *pad = gst_element_get_static_pad(m_videoSink, "sink");
     if (pad) {
-        m_videoBufferProbeId = gst_pad_add_buffer_probe(pad, G_CALLBACK(padVideoBufferProbe), this);
+        m_videoProbe->addProbeToPad(pad);
         gst_object_unref(GST_OBJECT(pad));
     }
 }
 
 void QGstreamerPlayerSession::removeAudioBufferProbe()
 {
-    if (m_audioBufferProbeId == -1)
-        return;
-
-    if (!m_audioSink) {
-        m_audioBufferProbeId = -1;
+    if (!m_audioProbe)
         return;
-    }
 
     GstPad *pad = gst_element_get_static_pad(m_audioSink, "sink");
     if (pad) {
-        gst_pad_remove_buffer_probe(pad, m_audioBufferProbeId);
+        m_audioProbe->removeProbeFromPad(pad);
         gst_object_unref(GST_OBJECT(pad));
     }
-
-    m_audioBufferProbeId = -1;
 }
 
 void QGstreamerPlayerSession::addAudioBufferProbe()
 {
-    Q_ASSERT(m_audioBufferProbeId == -1);
-    if (!m_audioSink)
+    if (!m_audioProbe)
         return;
 
     GstPad *pad = gst_element_get_static_pad(m_audioSink, "sink");
     if (pad) {
-        m_audioBufferProbeId = gst_pad_add_buffer_probe(pad, G_CALLBACK(padAudioBufferProbe), this);
+        m_audioProbe->addProbeToPad(pad);
         gst_object_unref(GST_OBJECT(pad));
     }
 }
 
 void QGstreamerPlayerSession::flushVideoProbes()
 {
-    QMutexLocker locker(&m_videoProbeMutex);
-    foreach (QGstreamerVideoProbeControl* probe, m_videoProbes)
-        probe->startFlushing();
+    if (m_videoProbe)
+        m_videoProbe->startFlushing();
 }
 
 void QGstreamerPlayerSession::resumeVideoProbes()
 {
-    QMutexLocker locker(&m_videoProbeMutex);
-    foreach (QGstreamerVideoProbeControl* probe, m_videoProbes)
-        probe->stopFlushing();
+    if (m_videoProbe)
+        m_videoProbe->stopFlushing();
 }
 
 void QGstreamerPlayerSession::playlistTypeFindFunction(GstTypeFind *find, gpointer userData)
@@ -1885,7 +1890,11 @@ void QGstreamerPlayerSession::playlistTypeFindFunction(GstTypeFind *find, gpoint
     QGstreamerPlayerSession* session = (QGstreamerPlayerSession*)userData;
 
     const gchar *uri = 0;
+#if GST_CHECK_VERSION(1,0,0)
+    g_object_get(G_OBJECT(session->m_playbin), "current-uri", &uri, NULL);
+#else
     g_object_get(G_OBJECT(session->m_playbin), "uri", &uri, NULL);
+#endif
 
     guint64 length = gst_type_find_get_length(find);
     if (!length)
@@ -1894,7 +1903,7 @@ void QGstreamerPlayerSession::playlistTypeFindFunction(GstTypeFind *find, gpoint
         length = qMin(length, guint64(1024));
 
     while (length > 0) {
-        guint8 *data = gst_type_find_peek(find, 0, length);
+        const guint8 *data = gst_type_find_peek(find, 0, length);
         if (data) {
             session->m_isPlaylist = (QPlaylistFileParser::findPlaylistType(QString::fromUtf8(uri), 0, data, length) != QPlaylistFileParser::UNKNOWN);
             return;
diff --git a/src/plugins/gstreamer/mediaplayer/qgstreamerplayersession.h b/src/plugins/gstreamer/mediaplayer/qgstreamerplayersession.h
index 23e7031..4fe58f2 100644
--- a/src/plugins/gstreamer/mediaplayer/qgstreamerplayersession.h
+++ b/src/plugins/gstreamer/mediaplayer/qgstreamerplayersession.h
@@ -127,11 +127,9 @@ public:
 
     void addProbe(QGstreamerVideoProbeControl* probe);
     void removeProbe(QGstreamerVideoProbeControl* probe);
-    static gboolean padVideoBufferProbe(GstPad *pad, GstBuffer *buffer, gpointer user_data);
 
     void addProbe(QGstreamerAudioProbeControl* probe);
     void removeProbe(QGstreamerAudioProbeControl* probe);
-    static gboolean padAudioBufferProbe(GstPad *pad, GstBuffer *buffer, gpointer user_data);
 
     void endOfMediaReset();
 
@@ -180,7 +178,9 @@ private:
     static void playbinNotifySource(GObject *o, GParamSpec *p, gpointer d);
     static void handleVolumeChange(GObject *o, GParamSpec *p, gpointer d);
     static void handleMutedChange(GObject *o, GParamSpec *p, gpointer d);
+#if !GST_CHECK_VERSION(1,0,0)
     static void insertColorSpaceElement(GstElement *element, gpointer data);
+#endif
     static void handleElementAdded(GstBin *bin, GstElement *element, QGstreamerPlayerSession *session);
     static void handleStreamsChange(GstBin *bin, gpointer user_data);
     static GstAutoplugSelectResult handleAutoplugSelect(GstBin *bin, GstPad *pad, GstCaps *caps, GstElementFactory *factory, QGstreamerPlayerSession *session);
@@ -202,11 +202,14 @@ private:
     QGstreamerBusHelper* m_busHelper;
     GstElement* m_playbin;
 
+    GstElement* m_videoSink;
+
     GstElement* m_videoOutputBin;
     GstElement* m_videoIdentity;
+#if !GST_CHECK_VERSION(1,0,0)
     GstElement* m_colorSpace;
     bool m_usingColorspaceElement;
-    GstElement* m_videoSink;
+#endif
     GstElement* m_pendingVideoSink;
     GstElement* m_nullVideoSink;
 
@@ -226,13 +229,8 @@ private:
     QList<QMediaStreamsControl::StreamType> m_streamTypes;
     QMap<QMediaStreamsControl::StreamType, int> m_playbin2StreamOffset;
 
-    QList<QGstreamerVideoProbeControl*> m_videoProbes;
-    QMutex m_videoProbeMutex;
-    int m_videoBufferProbeId;
-
-    QList<QGstreamerAudioProbeControl*> m_audioProbes;
-    QMutex m_audioProbeMutex;
-    int m_audioBufferProbeId;
+    QGstreamerVideoProbeControl *m_videoProbe;
+    QGstreamerAudioProbeControl *m_audioProbe;
 
     int m_volume;
     qreal m_playbackRate;
@@ -260,6 +258,7 @@ private:
     bool m_isLiveSource;
 
     bool m_isPlaylist;
+    gulong pad_probe_id;
 };
 
 QT_END_NAMESPACE
diff --git a/src/plugins/plugins.pro b/src/plugins/plugins.pro
index 2677e26..45aa95e 100644
--- a/src/plugins/plugins.pro
+++ b/src/plugins/plugins.pro
@@ -36,11 +36,8 @@ unix:!mac:!android {
         SUBDIRS += audiocapture
     }
 
-    config_pulseaudio {
-        SUBDIRS += pulseaudio
-    } else:config_alsa {
-        SUBDIRS += alsa
-    }
+    config_pulseaudio: SUBDIRS += pulseaudio
+    config_alsa: SUBDIRS += alsa
 
     # v4l is turned off because it is not supported in Qt 5
     # !maemo*:SUBDIRS += v4l
@@ -51,7 +48,7 @@ mac:!simulator {
 
     config_avfoundation: SUBDIRS += avfoundation
 
-    !ios: SUBDIRS += qt7
+    contains(QT_CONFIG, opengl.*):!ios: SUBDIRS += qt7
 }
 
 config_resourcepolicy {
diff --git a/src/plugins/resourcepolicy/resourcepolicy.pro b/src/plugins/resourcepolicy/resourcepolicy.pro
index 7aa1ced..4805c52 100644
--- a/src/plugins/resourcepolicy/resourcepolicy.pro
+++ b/src/plugins/resourcepolicy/resourcepolicy.pro
@@ -13,9 +13,11 @@ INCLUDEPATH += $$PWD \
 
 HEADERS += \
     $$PWD/resourcepolicyplugin.h \
-    $$PWD/resourcepolicyimpl.h
+    $$PWD/resourcepolicyimpl.h \
+    $$PWD/resourcepolicyint.h
 
 SOURCES += \
     $$PWD/resourcepolicyplugin.cpp \
-    $$PWD/resourcepolicyimpl.cpp
+    $$PWD/resourcepolicyimpl.cpp \
+    $$PWD/resourcepolicyint.cpp
 
diff --git a/src/plugins/resourcepolicy/resourcepolicyimpl.cpp b/src/plugins/resourcepolicy/resourcepolicyimpl.cpp
index 0acabc0..3ad92fa 100644
--- a/src/plugins/resourcepolicy/resourcepolicyimpl.cpp
+++ b/src/plugins/resourcepolicy/resourcepolicyimpl.cpp
@@ -40,99 +40,62 @@
 **
 ****************************************************************************/
 
+#include <QGlobalStatic>
+
 #include <policy/resource.h>
 #include <policy/resources.h>
 #include <policy/resource-set.h>
 
 #include "resourcepolicyimpl.h"
+#include "resourcepolicyint.h"
+
+Q_GLOBAL_STATIC(ResourcePolicyInt, globalResourcePolicyInt);
 
 ResourcePolicyImpl::ResourcePolicyImpl(QObject *parent)
     : QMediaPlayerResourceSetInterface(parent)
-    , m_status(Initial)
-    , m_videoEnabled(false)
 {
-    m_resourceSet = new ResourcePolicy::ResourceSet("player", this);
-    m_resourceSet->setAlwaysReply();
-
-    ResourcePolicy::AudioResource *audioResource = new ResourcePolicy::AudioResource("player");
-    audioResource->setProcessID(QCoreApplication::applicationPid());
-    audioResource->setStreamTag("media.name", "*");
-    m_resourceSet->addResourceObject(audioResource);
-
-    m_resourceSet->update();
+    ResourcePolicyInt *set = globalResourcePolicyInt;
+    set->addClient(this);
+}
 
-    connect(m_resourceSet, SIGNAL(resourcesGranted(QList<ResourcePolicy::ResourceType>)),
-            this, SLOT(handleResourcesGranted()));
-    connect(m_resourceSet, SIGNAL(resourcesDenied()),
-            this, SLOT(handleResourcesDenied()));
-    connect(m_resourceSet, SIGNAL(lostResources()),
-            this, SLOT(handleResourcesLost()));
-    connect(m_resourceSet, SIGNAL(resourcesReleasedByManager()),
-            this, SLOT(handleResourcesLost()));
+ResourcePolicyImpl::~ResourcePolicyImpl()
+{
+    ResourcePolicyInt *set = globalResourcePolicyInt;
+    set->removeClient(this);
 }
 
 bool ResourcePolicyImpl::isVideoEnabled() const
 {
-    return m_videoEnabled;
+    ResourcePolicyInt *set = globalResourcePolicyInt;
+    return set->isVideoEnabled(this);
 }
 
 void ResourcePolicyImpl::setVideoEnabled(bool videoEnabled)
 {
-    if (m_videoEnabled != videoEnabled) {
-        m_videoEnabled = videoEnabled;
-
-        if (videoEnabled)
-            m_resourceSet->addResource(ResourcePolicy::VideoPlaybackType);
-        else
-            m_resourceSet->deleteResource(ResourcePolicy::VideoPlaybackType);
-
-        m_resourceSet->update();
-    }
+    ResourcePolicyInt *set = globalResourcePolicyInt;
+    set->setVideoEnabled(this, videoEnabled);
 }
 
 void ResourcePolicyImpl::acquire()
 {
-    m_status = RequestedResource;
-    m_resourceSet->acquire();
+    ResourcePolicyInt *set = globalResourcePolicyInt;
+    set->acquire(this);
 }
 
 void ResourcePolicyImpl::release()
 {
-    m_resourceSet->release();
-    m_status = Initial;
+    ResourcePolicyInt *set = globalResourcePolicyInt;
+    set->release(this);
 }
 
 bool ResourcePolicyImpl::isGranted() const
 {
-    return m_status == GrantedResource;
+    ResourcePolicyInt *set = globalResourcePolicyInt;
+    return set->isGranted(this);
 }
 
 bool ResourcePolicyImpl::isAvailable() const
 {
-    // TODO: is this used? what is it for?
-    qWarning() << Q_FUNC_INFO << "Stub";
-    return true;
+    ResourcePolicyInt *set = globalResourcePolicyInt;
+    return set->isAvailable();
 }
-
-void ResourcePolicyImpl::handleResourcesGranted()
-{
-    m_status = GrantedResource;
-    emit resourcesGranted();
-}
-
-void ResourcePolicyImpl::handleResourcesDenied()
-{
-    m_status = Initial;
-    emit resourcesDenied();
-}
-
-void ResourcePolicyImpl::handleResourcesLost()
-{
-    if (m_status != Initial) {
-        m_status = Initial;
-        emit resourcesLost();
-    }
-
-    m_resourceSet->release();
-}
-
diff --git a/src/plugins/resourcepolicy/resourcepolicyimpl.h b/src/plugins/resourcepolicy/resourcepolicyimpl.h
index 8680df8..28393b7 100644
--- a/src/plugins/resourcepolicy/resourcepolicyimpl.h
+++ b/src/plugins/resourcepolicy/resourcepolicyimpl.h
@@ -56,6 +56,7 @@ class ResourcePolicyImpl : public QMediaPlayerResourceSetInterface
     Q_OBJECT
 public:
     ResourcePolicyImpl(QObject *parent = 0);
+    ~ResourcePolicyImpl();
 
     bool isVideoEnabled() const;
     void setVideoEnabled(bool videoEnabled);
@@ -63,22 +64,6 @@ public:
     void release();
     bool isGranted() const;
     bool isAvailable() const;
-
-private slots:
-    void handleResourcesGranted();
-    void handleResourcesDenied();
-    void handleResourcesLost();
-
-private:
-    enum ResourceStatus {
-        Initial = 0,
-        RequestedResource,
-        GrantedResource
-    };
-
-    bool m_videoEnabled;
-    ResourcePolicy::ResourceSet *m_resourceSet;
-    ResourceStatus m_status;
 };
 
 #endif // RESOURCEPOLICYIMPL_H
diff --git a/src/plugins/resourcepolicy/resourcepolicyint.cpp b/src/plugins/resourcepolicy/resourcepolicyint.cpp
new file mode 100644
index 0000000..2fff64b
--- /dev/null
+++ b/src/plugins/resourcepolicy/resourcepolicyint.cpp
@@ -0,0 +1,311 @@
+/****************************************************************************
+**
+** Copyright (C) 2013 Jolla Ltd, author: <robin.burchell@jollamobile.com>
+** Copyright (C) 2013 Digia Plc and/or its subsidiary(-ies).
+** Contact: http://www.qt-project.org/legal
+**
+** This file is part of the Qt Toolkit.
+**
+** $QT_BEGIN_LICENSE:LGPL$
+** Commercial License Usage
+** Licensees holding valid commercial Qt licenses may use this file in
+** accordance with the commercial license agreement provided with the
+** Software or, alternatively, in accordance with the terms contained in
+** a written agreement between you and Digia.  For licensing terms and
+** conditions see http://qt.digia.com/licensing.  For further information
+** use the contact form at http://qt.digia.com/contact-us.
+**
+** GNU Lesser General Public License Usage
+** Alternatively, this file may be used under the terms of the GNU Lesser
+** General Public License version 2.1 as published by the Free Software
+** Foundation and appearing in the file LICENSE.LGPL included in the
+** packaging of this file.  Please review the following information to
+** ensure the GNU Lesser General Public License version 2.1 requirements
+** will be met: http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html.
+**
+** In addition, as a special exception, Digia gives you certain additional
+** rights.  These rights are described in the Digia Qt LGPL Exception
+** version 1.1, included in the file LGPL_EXCEPTION.txt in this package.
+**
+** GNU General Public License Usage
+** Alternatively, this file may be used under the terms of the GNU
+** General Public License version 3.0 as published by the Free Software
+** Foundation and appearing in the file LICENSE.GPL included in the
+** packaging of this file.  Please review the following information to
+** ensure the GNU General Public License version 3.0 requirements will be
+** met: http://www.gnu.org/copyleft/gpl.html.
+**
+**
+** $QT_END_LICENSE$
+**
+****************************************************************************/
+
+
+#include <policy/resource.h>
+#include <policy/resources.h>
+#include <policy/resource-set.h>
+
+#include "resourcepolicyint.h"
+#include "resourcepolicyimpl.h"
+
+#include <QMap>
+
+static int clientid = 0;
+
+ResourcePolicyInt::ResourcePolicyInt(QObject *parent)
+    : QObject(parent)
+    , m_acquired(0)
+    , m_status(Initial)
+    , m_video(0)
+    , m_resourceSet(0)
+{
+    m_resourceSet = new ResourcePolicy::ResourceSet("player", this);
+    m_resourceSet->setAlwaysReply();
+
+    ResourcePolicy::AudioResource *audioResource = new ResourcePolicy::AudioResource("player");
+    audioResource->setProcessID(QCoreApplication::applicationPid());
+    audioResource->setStreamTag("media.name", "*");
+    m_resourceSet->addResourceObject(audioResource);
+
+    m_resourceSet->update();
+
+    connect(m_resourceSet, SIGNAL(resourcesGranted(QList<ResourcePolicy::ResourceType>)),
+            this, SLOT(handleResourcesGranted()));
+    connect(m_resourceSet, SIGNAL(resourcesDenied()),
+            this, SLOT(handleResourcesDenied()));
+    connect(m_resourceSet, SIGNAL(lostResources()),
+            this, SLOT(handleResourcesLost()));
+    connect(m_resourceSet, SIGNAL(resourcesReleasedByManager()),
+            this, SLOT(handleResourcesLost()));
+}
+
+ResourcePolicyInt::~ResourcePolicyInt()
+{
+    delete m_resourceSet;
+    m_resourceSet = 0;
+#ifdef RESOURCE_DEBUG
+    qDebug() << "##### Tearing down singleton.";
+#endif
+}
+
+void ResourcePolicyInt::addClient(ResourcePolicyImpl *client)
+{
+    clientEntry entry;
+    entry.id = clientid++;
+    entry.client = client;
+    entry.status = Initial;
+    entry.videoEnabled = false;
+    m_clients.insert(entry.client, entry);
+#ifdef RESOURCE_DEBUG
+    qDebug() << "##### Add client " << client << " : " << entry.id;
+#endif
+}
+
+void ResourcePolicyInt::removeClient(ResourcePolicyImpl *client)
+{
+    QMap<const ResourcePolicyImpl*, clientEntry>::iterator i = m_clients.find(client);
+    if (i != m_clients.end()) {
+#ifdef RESOURCE_DEBUG
+        qDebug() << "##### Remove client " << client << " : " << i.value().id;
+#endif
+        if (i.value().status == GrantedResource)
+            --m_acquired;
+        m_clients.erase(i);
+    }
+
+    if (m_acquired == 0) {
+#ifdef RESOURCE_DEBUG
+        qDebug() << "##### Remove client, acquired = 0, release";
+#endif
+        m_resourceSet->release();
+        m_status = Initial;
+    }
+}
+
+bool ResourcePolicyInt::isVideoEnabled(const ResourcePolicyImpl *client) const
+{
+    QMap<const ResourcePolicyImpl*, clientEntry>::const_iterator i = m_clients.find(client);
+    if (i != m_clients.constEnd())
+        return i.value().videoEnabled;
+
+    return false;
+}
+
+void ResourcePolicyInt::setVideoEnabled(const ResourcePolicyImpl *client, bool videoEnabled)
+{
+    bool update = false;
+
+    QMap<const ResourcePolicyImpl*, clientEntry>::iterator i = m_clients.find(client);
+    if (i != m_clients.end()) {
+        if (videoEnabled == i.value().videoEnabled)
+            return;
+
+        if (videoEnabled) {
+            if (m_video > 0) {
+                i.value().videoEnabled = true;
+            } else {
+                m_resourceSet->addResource(ResourcePolicy::VideoPlaybackType);
+                update = true;
+            }
+            ++m_video;
+        } else {
+            --m_video;
+            i.value().videoEnabled = false;
+            if (m_video == 0) {
+                m_resourceSet->deleteResource(ResourcePolicy::VideoPlaybackType);
+                update = true;
+            }
+        }
+    }
+
+    if (update)
+        m_resourceSet->update();
+}
+
+void ResourcePolicyInt::acquire(const ResourcePolicyImpl *client)
+{
+    QMap<const ResourcePolicyImpl*, clientEntry>::iterator i = m_clients.find(client);
+    if (i != m_clients.end()) {
+#ifdef RESOURCE_DEBUG
+        qDebug() << "##### " << i.value().id << ": ACQUIRE";
+#endif
+        if (i.value().status == Initial) {
+
+            if (m_status == RequestedResource) {
+                i.value().status = RequestedResource;
+#ifdef RESOURCE_DEBUG
+                qDebug() << "##### " << i.value().id << ": Already requesting, set client as RequestResource and return";
+#endif
+                return;
+            }
+
+            if (m_status == GrantedResource) {
+                ++m_acquired;
+#ifdef RESOURCE_DEBUG
+                qDebug() << "##### " << i.value().id << ": Already granted, set as GrantedResource and return";
+#endif
+                i.value().status = GrantedResource;
+                emit i.value().client->resourcesGranted();
+                return;
+            }
+        } else if (i.value().status == RequestedResource) {
+#ifdef RESOURCE_DEBUG
+            qDebug() << "##### " << i.value().id << ": Already requesting, return";
+#endif
+            return;
+        } else {
+#ifdef RESOURCE_DEBUG
+            qDebug() << "##### " << i.value().id << ": Already granted, return ";
+#endif
+            return;
+        }
+        i.value().status = RequestedResource;
+        m_status = RequestedResource;
+
+#ifdef RESOURCE_DEBUG
+        qDebug() << "##### " << i.value().id << ": ACQUIRE call resourceSet->acquire()";
+#endif
+        // If m_status was Initial this is the first time resources are requested,
+        // so let's actually do the acquiring
+        m_resourceSet->acquire();
+    }
+}
+
+void ResourcePolicyInt::release(const ResourcePolicyImpl *client)
+{
+    QMap<const ResourcePolicyImpl*, clientEntry>::iterator i = m_clients.find(client);
+    if (i != m_clients.end()) {
+        if (i.value().status == GrantedResource) {
+            i.value().status = Initial;
+            --m_acquired;
+#ifdef RESOURCE_DEBUG
+            qDebug() << "##### " << i.value().id << ": RELEASE, acquired (" << m_acquired << ")";
+#endif
+        }
+    }
+
+    if (m_acquired == 0) {
+#ifdef RESOURCE_DEBUG
+        qDebug() << "##### " << i.value().id << ": RELEASE call resourceSet->release()";
+#endif
+        m_resourceSet->release();
+        m_status = Initial;
+    }
+}
+
+bool ResourcePolicyInt::isGranted(const ResourcePolicyImpl *client) const
+{
+    QMap<const ResourcePolicyImpl*, clientEntry>::const_iterator i = m_clients.find(client);
+    if (i != m_clients.constEnd()) {
+#ifdef RESOURCE_DEBUG
+            qDebug() << "##### " << i.value().id << ": IS GRANTED, status: " << i.value().status;
+#endif
+        return i.value().status == GrantedResource;
+    }
+
+    return false;
+}
+
+bool ResourcePolicyInt::isAvailable() const
+{
+    // TODO: is this used? what is it for?
+    qWarning() << Q_FUNC_INFO << "Stub";
+    return true;
+}
+
+void ResourcePolicyInt::handleResourcesGranted()
+{
+    m_status = GrantedResource;
+    QMap<const ResourcePolicyImpl*, clientEntry>::iterator i = m_clients.begin();
+    while (i != m_clients.end()) {
+        if (i.value().status == RequestedResource) {
+            ++m_acquired;
+#ifdef RESOURCE_DEBUG
+            qDebug() << "##### " << i.value().id << ": HANDLE GRANTED, acquired (" << m_acquired << ") emitting resourcesGranted()";
+#endif
+            i.value().status = GrantedResource;
+            emit i.value().client->resourcesGranted();
+        }
+        ++i;
+    }
+}
+
+void ResourcePolicyInt::handleResourcesDenied()
+{
+    m_status = Initial;
+    m_acquired = 0;
+    QMap<const ResourcePolicyImpl*, clientEntry>::iterator i = m_clients.begin();
+    while (i != m_clients.end()) {
+        if (i.value().status == RequestedResource) {
+#ifdef RESOURCE_DEBUG
+            qDebug() << "##### " << i.value().id << ": HANDLE DENIED, acquired (" << m_acquired << ") emitting resourcesDenied()";
+#endif
+            i.value().status = Initial;
+            emit i.value().client->resourcesDenied();
+        }
+        // Do we need to act for clients that are in granted state?
+        ++i;
+    }
+}
+
+void ResourcePolicyInt::handleResourcesLost()
+{
+    if (m_status != Initial) {
+        m_status = Initial;
+    }
+
+    m_acquired = 0;
+    m_resourceSet->release();
+
+    QMap<const ResourcePolicyImpl*, clientEntry>::iterator i = m_clients.begin();
+    while (i != m_clients.end()) {
+        if (i.value().status != Initial) {
+#ifdef RESOURCE_DEBUG
+            qDebug() << "##### " << i.value().id << ": HANDLE LOST, acquired (" << m_acquired << ") emitting resourcesLost()";
+#endif
+            i.value().status = Initial;
+            emit i.value().client->resourcesLost();
+        }
+        ++i;
+    }
+}
diff --git a/src/plugins/resourcepolicy/resourcepolicyint.h b/src/plugins/resourcepolicy/resourcepolicyint.h
new file mode 100644
index 0000000..39882b5
--- /dev/null
+++ b/src/plugins/resourcepolicy/resourcepolicyint.h
@@ -0,0 +1,100 @@
+/****************************************************************************
+**
+** Copyright (C) 2013 Jolla Ltd, author: <robin.burchell@jollamobile.com>
+** Copyright (C) 2013 Digia Plc and/or its subsidiary(-ies).
+** Contact: http://www.qt-project.org/legal
+**
+** This file is part of the Qt Toolkit.
+**
+** $QT_BEGIN_LICENSE:LGPL$
+** Commercial License Usage
+** Licensees holding valid commercial Qt licenses may use this file in
+** accordance with the commercial license agreement provided with the
+** Software or, alternatively, in accordance with the terms contained in
+** a written agreement between you and Digia.  For licensing terms and
+** conditions see http://qt.digia.com/licensing.  For further information
+** use the contact form at http://qt.digia.com/contact-us.
+**
+** GNU Lesser General Public License Usage
+** Alternatively, this file may be used under the terms of the GNU Lesser
+** General Public License version 2.1 as published by the Free Software
+** Foundation and appearing in the file LICENSE.LGPL included in the
+** packaging of this file.  Please review the following information to
+** ensure the GNU Lesser General Public License version 2.1 requirements
+** will be met: http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html.
+**
+** In addition, as a special exception, Digia gives you certain additional
+** rights.  These rights are described in the Digia Qt LGPL Exception
+** version 1.1, included in the file LGPL_EXCEPTION.txt in this package.
+**
+** GNU General Public License Usage
+** Alternatively, this file may be used under the terms of the GNU
+** General Public License version 3.0 as published by the Free Software
+** Foundation and appearing in the file LICENSE.GPL included in the
+** packaging of this file.  Please review the following information to
+** ensure the GNU General Public License version 3.0 requirements will be
+** met: http://www.gnu.org/copyleft/gpl.html.
+**
+**
+** $QT_END_LICENSE$
+**
+****************************************************************************/
+
+#ifndef RESOURCEPOLICYINT_H
+#define RESOURCEPOLICYINT_H
+
+#include <QObject>
+#include <QMap>
+
+#include <private/qmediaresourceset_p.h>
+#include "resourcepolicyimpl.h"
+
+namespace ResourcePolicy {
+    class ResourceSet;
+};
+
+enum ResourceStatus {
+    Initial = 0,
+    RequestedResource,
+    GrantedResource
+};
+
+struct clientEntry {
+    int id;
+    ResourcePolicyImpl *client;
+    ResourceStatus status;
+    bool videoEnabled;
+};
+
+class ResourcePolicyInt : public QObject
+{
+    Q_OBJECT
+public:
+    ResourcePolicyInt(QObject *parent = 0);
+    ~ResourcePolicyInt();
+
+    bool isVideoEnabled(const ResourcePolicyImpl *client) const;
+    void setVideoEnabled(const ResourcePolicyImpl *client, bool videoEnabled);
+    void acquire(const ResourcePolicyImpl *client);
+    void release(const ResourcePolicyImpl *client);
+    bool isGranted(const ResourcePolicyImpl *client) const;
+    bool isAvailable() const;
+
+    void addClient(ResourcePolicyImpl *client);
+    void removeClient(ResourcePolicyImpl *client);
+
+private slots:
+    void handleResourcesGranted();
+    void handleResourcesDenied();
+    void handleResourcesLost();
+
+private:
+    QMap<const ResourcePolicyImpl*, clientEntry> m_clients;
+
+    int m_acquired;
+    ResourceStatus m_status;
+    int m_video;
+    ResourcePolicy::ResourceSet *m_resourceSet;
+};
+
+#endif // RESOURCEPOLICYINT_H
diff --git a/src/qtmultimediaquicktools/qsgvideonode_i420.cpp b/src/qtmultimediaquicktools/qsgvideonode_i420.cpp
index 2d84f6e..2d904f8 100644
--- a/src/qtmultimediaquicktools/qsgvideonode_i420.cpp
+++ b/src/qtmultimediaquicktools/qsgvideonode_i420.cpp
@@ -257,33 +257,23 @@ void QSGVideoMaterial_YUV420::bind()
                 m_textureSize = m_frame.size();
             }
 
-            const uchar *bits = m_frame.bits();
-            int yStride = m_frame.bytesPerLine();
-            // The UV stride is usually half the Y stride and is 32-bit aligned.
-            // However it's not always the case, at least on Windows where the
-            // UV planes are sometimes not aligned.
-            // We calculate the stride using the UV byte count to always
-            // have a correct stride.
-            int uvStride = (m_frame.mappedBytes() - yStride * fh) / fh;
-            int offsetU = yStride * fh;
-            int offsetV = yStride * fh + uvStride * fh / 2;
-
-            m_yWidth = qreal(fw) / yStride;
-            m_uvWidth = qreal(fw) /  (2 * uvStride);
-
-            if (m_frame.pixelFormat() == QVideoFrame::Format_YV12)
-                qSwap(offsetU, offsetV);
+            const int y = 0;
+            const int u = m_frame.pixelFormat() == QVideoFrame::Format_YUV420P ? 1 : 2;
+            const int v = m_frame.pixelFormat() == QVideoFrame::Format_YUV420P ? 2 : 1;
+
+            m_yWidth = qreal(fw) / m_frame.bytesPerLine(y);
+            m_uvWidth = qreal(fw) / (2 * m_frame.bytesPerLine(u));
 
             GLint previousAlignment;
             glGetIntegerv(GL_UNPACK_ALIGNMENT, &previousAlignment);
             glPixelStorei(GL_UNPACK_ALIGNMENT, 1);
 
             functions->glActiveTexture(GL_TEXTURE1);
-            bindTexture(m_textureIds[1], uvStride, fh / 2, bits + offsetU);
+            bindTexture(m_textureIds[1], m_frame.bytesPerLine(u), fh / 2, m_frame.bits(u));
             functions->glActiveTexture(GL_TEXTURE2);
-            bindTexture(m_textureIds[2], uvStride, fh / 2, bits + offsetV);
+            bindTexture(m_textureIds[2], m_frame.bytesPerLine(v), fh / 2, m_frame.bits(v));
             functions->glActiveTexture(GL_TEXTURE0); // Finish with 0 as default texture unit
-            bindTexture(m_textureIds[0], yStride, fh, bits);
+            bindTexture(m_textureIds[0], m_frame.bytesPerLine(y), fh, m_frame.bits(y));
 
             glPixelStorei(GL_UNPACK_ALIGNMENT, previousAlignment);
 
@@ -350,7 +340,6 @@ void QSGVideoMaterialShader_YUV420::updateState(const RenderState &state,
         mat->m_opacity = state.opacity();
         program()->setUniformValue(m_id_opacity, GLfloat(mat->m_opacity));
     }
-
     if (state.isMatrixDirty())
         program()->setUniformValue(m_id_matrix, state.combinedMatrix());
 }
diff --git a/tests/auto/integration/qcamerabackend/tst_qcamerabackend.cpp b/tests/auto/integration/qcamerabackend/tst_qcamerabackend.cpp
index 8909691..4036fa3 100644
--- a/tests/auto/integration/qcamerabackend/tst_qcamerabackend.cpp
+++ b/tests/auto/integration/qcamerabackend/tst_qcamerabackend.cpp
@@ -503,6 +503,8 @@ void tst_QCameraBackend::testCaptureToBuffer()
         QCOMPARE(imageCapture.bufferFormat(), QVideoFrame::Format_Jpeg);
     }
 
+    QTRY_VERIFY(imageCapture.isReadyForCapture());
+
     //Try to capture to both buffer and file
 #ifdef Q_WS_MAEMO_6
     QVERIFY(imageCapture.isCaptureDestinationSupported(QCameraImageCapture::CaptureToBuffer | QCameraImageCapture::CaptureToFile));
@@ -659,11 +661,11 @@ void tst_QCameraBackend::testVideoRecording()
 {
     QFETCH(QByteArray, device);
 
-    QCamera *camera = device.isEmpty() ? new QCamera : new QCamera(device);
+    QScopedPointer<QCamera> camera(device.isEmpty() ? new QCamera : new QCamera(device));
 
-    QMediaRecorder recorder(camera);
+    QMediaRecorder recorder(camera.data());
 
-    QSignalSpy errorSignal(camera, SIGNAL(error(QCamera::Error)));
+    QSignalSpy errorSignal(camera.data(), SIGNAL(error(QCamera::Error)));
     QSignalSpy recorderErrorSignal(&recorder, SIGNAL(error(QMediaRecorder::Error)));
     QSignalSpy recorderStatusSignal(&recorder, SIGNAL(statusChanged(QMediaRecorder::Status)));
 
@@ -710,8 +712,6 @@ void tst_QCameraBackend::testVideoRecording()
     camera->setCaptureMode(QCamera::CaptureStillImage);
     QTRY_COMPARE(recorder.status(), QMediaRecorder::UnloadedStatus);
     QCOMPARE(recorderStatusSignal.last().first().value<QMediaRecorder::Status>(), recorder.status());
-
-    delete camera;
 }
 
 QTEST_MAIN(tst_QCameraBackend)
diff --git a/tests/auto/integration/qmediaplayerbackend/tst_qmediaplayerbackend.cpp b/tests/auto/integration/qmediaplayerbackend/tst_qmediaplayerbackend.cpp
index 689843e..d56a189 100644
--- a/tests/auto/integration/qmediaplayerbackend/tst_qmediaplayerbackend.cpp
+++ b/tests/auto/integration/qmediaplayerbackend/tst_qmediaplayerbackend.cpp
@@ -643,7 +643,7 @@ void tst_QMediaPlayerBackend::seekPauseSeek()
 
     {
         QVideoFrame frame = surface->m_frameList.back();
-        const qint64 elapsed = frame.startTime() - position;
+        const qint64 elapsed = (frame.startTime() / 1000) - position; // frame.startTime() is microsecond, position is milliseconds.
         QVERIFY2(qAbs(elapsed) < (qint64)500, QByteArray::number(elapsed).constData());
         QCOMPARE(frame.width(), 160);
         QCOMPARE(frame.height(), 120);
@@ -667,7 +667,7 @@ void tst_QMediaPlayerBackend::seekPauseSeek()
 
     {
         QVideoFrame frame = surface->m_frameList.back();
-        const qint64 elapsed = frame.startTime() - position;
+        const qint64 elapsed = (frame.startTime() / 1000) - position;
         QVERIFY2(qAbs(elapsed) < (qint64)500, QByteArray::number(elapsed).constData());
         QCOMPARE(frame.width(), 160);
         QCOMPARE(frame.height(), 120);
diff --git a/tests/auto/unit/qaudioformat/tst_qaudioformat.cpp b/tests/auto/unit/qaudioformat/tst_qaudioformat.cpp
index 22a5dc1..b52cdeb 100644
--- a/tests/auto/unit/qaudioformat/tst_qaudioformat.cpp
+++ b/tests/auto/unit/qaudioformat/tst_qaudioformat.cpp
@@ -69,9 +69,6 @@ private slots:
 
     void checkSizes();
     void checkSizes_data();
-
-    void debugOperator();
-    void debugOperator_data();
 };
 
 void tst_QAudioFormat::checkNull()
@@ -316,42 +313,6 @@ void tst_QAudioFormat::checkSizes_data()
     QTest::newRow("2ch_16b_8k_signed_8000_duration4") << f << 4 << 8000 << qrtr << 2000 << 8000 << qrtr + 126 << 8004 << 2001;
 }
 
-void tst_QAudioFormat::debugOperator_data()
-{
-    QTest::addColumn<QAudioFormat>("format");
-    QTest::addColumn<QString>("stringized");
-
-    // A small sampling
-    QAudioFormat f;
-    f.setByteOrder(QAudioFormat::LittleEndian);
-    QTest::newRow("plain") << f << QString::fromLatin1("QAudioFormat(-1Hz, -1bit, channelCount=-1, sampleType=Unknown, byteOrder=LittleEndian, codec=\"\") ");
-
-    f.setSampleRate(22050);
-    f.setChannelCount(4);
-    f.setCodec("audio/pcm");
-    f.setSampleType(QAudioFormat::Float);
-
-    QTest::newRow("float") << f << QString::fromLatin1("QAudioFormat(22050Hz, -1bit, channelCount=4, sampleType=Float, byteOrder=LittleEndian, codec=\"audio/pcm\") ");
-
-    f.setSampleType(QAudioFormat::UnSignedInt);
-    QTest::newRow("unsigned") << f << QString::fromLatin1("QAudioFormat(22050Hz, -1bit, channelCount=4, sampleType=UnSignedInt, byteOrder=LittleEndian, codec=\"audio/pcm\") ");
-
-    f.setSampleRate(44100);
-    QTest::newRow("44.1 unsigned") << f << QString::fromLatin1("QAudioFormat(44100Hz, -1bit, channelCount=4, sampleType=UnSignedInt, byteOrder=LittleEndian, codec=\"audio/pcm\") ");
-
-    f.setByteOrder(QAudioFormat::BigEndian);
-    QTest::newRow("44.1 big unsigned") << f << QString::fromLatin1("QAudioFormat(44100Hz, -1bit, channelCount=4, sampleType=UnSignedInt, byteOrder=BigEndian, codec=\"audio/pcm\") ");
-}
-
-void tst_QAudioFormat::debugOperator()
-{
-    QFETCH(QAudioFormat, format);
-    QFETCH(QString, stringized);
-
-    QTest::ignoreMessage(QtDebugMsg, stringized.toLatin1().constData());
-    qDebug() << format;
-}
-
 QTEST_MAIN(tst_QAudioFormat)
 
 #include "tst_qaudioformat.moc"
diff --git a/tests/auto/unit/qcamera/tst_qcamera.cpp b/tests/auto/unit/qcamera/tst_qcamera.cpp
index 3bbbc36..61dd05b 100644
--- a/tests/auto/unit/qcamera/tst_qcamera.cpp
+++ b/tests/auto/unit/qcamera/tst_qcamera.cpp
@@ -1126,21 +1126,21 @@ void tst_QCamera::testSetVideoOutputDestruction()
 
 void tst_QCamera::testEnumDebug()
 {
-    QTest::ignoreMessage(QtDebugMsg, "QCamera::ActiveState ");
+    QTest::ignoreMessage(QtDebugMsg, "QCamera::ActiveState");
     qDebug() << QCamera::ActiveState;
-    QTest::ignoreMessage(QtDebugMsg, "QCamera::ActiveStatus ");
+    QTest::ignoreMessage(QtDebugMsg, "QCamera::ActiveStatus");
     qDebug() << QCamera::ActiveStatus;
-    QTest::ignoreMessage(QtDebugMsg, "QCamera::CaptureVideo ");
+    QTest::ignoreMessage(QtDebugMsg, "QCamera::CaptureVideo");
     qDebug() << QCamera::CaptureVideo;
-    QTest::ignoreMessage(QtDebugMsg, "QCamera::CameraError ");
+    QTest::ignoreMessage(QtDebugMsg, "QCamera::CameraError");
     qDebug() << QCamera::CameraError;
-    QTest::ignoreMessage(QtDebugMsg, "QCamera::Unlocked ");
+    QTest::ignoreMessage(QtDebugMsg, "QCamera::Unlocked");
     qDebug() << QCamera::Unlocked;
-    QTest::ignoreMessage(QtDebugMsg, "QCamera::LockAcquired ");
+    QTest::ignoreMessage(QtDebugMsg, "QCamera::LockAcquired");
     qDebug() << QCamera::LockAcquired;
-    QTest::ignoreMessage(QtDebugMsg, "QCamera::NoLock ");
+    QTest::ignoreMessage(QtDebugMsg, "QCamera::NoLock");
     qDebug() << QCamera::NoLock;
-    QTest::ignoreMessage(QtDebugMsg, "QCamera::LockExposure ");
+    QTest::ignoreMessage(QtDebugMsg, "QCamera::LockExposure");
     qDebug() << QCamera::LockExposure;
     QTest::ignoreMessage(QtDebugMsg, "QCamera::FrontFace ");
     qDebug() << QCamera::FrontFace;
diff --git a/tests/auto/unit/qmediaplayer/tst_qmediaplayer.cpp b/tests/auto/unit/qmediaplayer/tst_qmediaplayer.cpp
index eed523a..ff8933f 100644
--- a/tests/auto/unit/qmediaplayer/tst_qmediaplayer.cpp
+++ b/tests/auto/unit/qmediaplayer/tst_qmediaplayer.cpp
@@ -1106,11 +1106,11 @@ void tst_QMediaPlayer::testPositionPropertyWatch()
 
 void tst_QMediaPlayer::debugEnums()
 {
-    QTest::ignoreMessage(QtDebugMsg, "QMediaPlayer::PlayingState ");
+    QTest::ignoreMessage(QtDebugMsg, "QMediaPlayer::PlayingState");
     qDebug() << QMediaPlayer::PlayingState;
-    QTest::ignoreMessage(QtDebugMsg, "QMediaPlayer::NoMedia ");
+    QTest::ignoreMessage(QtDebugMsg, "QMediaPlayer::NoMedia");
     qDebug() << QMediaPlayer::NoMedia;
-    QTest::ignoreMessage(QtDebugMsg, "QMediaPlayer::NetworkError ");
+    QTest::ignoreMessage(QtDebugMsg, "QMediaPlayer::NetworkError");
     qDebug() << QMediaPlayer::NetworkError;
 }
 
diff --git a/tests/auto/unit/qvideoframe/tst_qvideoframe.cpp b/tests/auto/unit/qvideoframe/tst_qvideoframe.cpp
index c7dbfbe..c9e11ff 100644
--- a/tests/auto/unit/qvideoframe/tst_qvideoframe.cpp
+++ b/tests/auto/unit/qvideoframe/tst_qvideoframe.cpp
@@ -87,21 +87,14 @@ private slots:
     void map();
     void mapImage_data();
     void mapImage();
+    void mapPlanes_data();
+    void mapPlanes();
     void imageDetach();
     void formatConversion_data();
     void formatConversion();
 
     void metadata();
 
-    void debugType_data();
-    void debugType();
-
-    void debug_data();
-    void debug();
-
-    void debugFormat_data();
-    void debugFormat();
-
     void isMapped();
     void isReadable();
     void isWritable();
@@ -124,6 +117,35 @@ public:
     void unmap() {}
 };
 
+class QtTestPlanarVideoBuffer : public QAbstractPlanarVideoBuffer
+{
+public:
+    QtTestPlanarVideoBuffer()
+        : QAbstractPlanarVideoBuffer(NoHandle), m_planeCount(0), m_mapMode(NotMapped) {}
+    explicit QtTestPlanarVideoBuffer(QAbstractVideoBuffer::HandleType type)
+        : QAbstractPlanarVideoBuffer(type), m_planeCount(0), m_mapMode(NotMapped) {}
+
+    MapMode mapMode() const { return m_mapMode; }
+
+    int map(MapMode mode, int *numBytes, int bytesPerLine[4], uchar *data[4]) {
+        m_mapMode = mode;
+        if (numBytes)
+            *numBytes = m_numBytes;
+        for (int i = 0; i < m_planeCount; ++i) {
+            data[i] = m_data[i];
+            bytesPerLine[i] = m_bytesPerLine[i];
+        }
+        return m_planeCount;
+    }
+    void unmap() { m_mapMode = NotMapped; }
+
+    uchar *m_data[4];
+    int m_bytesPerLine[4];
+    int m_planeCount;
+    int m_numBytes;
+    MapMode m_mapMode;
+};
+
 tst_QVideoFrame::tst_QVideoFrame()
 {
 }
@@ -736,6 +758,97 @@ void tst_QVideoFrame::mapImage()
     QCOMPARE(frame.mapMode(), QAbstractVideoBuffer::NotMapped);
 }
 
+void tst_QVideoFrame::mapPlanes_data()
+{
+    QTest::addColumn<QVideoFrame>("frame");
+    QTest::addColumn<QList<int> >("strides");
+    QTest::addColumn<QList<int> >("offsets");
+
+    static uchar bufferData[1024];
+
+    QtTestPlanarVideoBuffer *planarBuffer = new QtTestPlanarVideoBuffer;
+    planarBuffer->m_data[0] = bufferData;
+    planarBuffer->m_data[1] = bufferData + 512;
+    planarBuffer->m_data[2] = bufferData + 765;
+    planarBuffer->m_bytesPerLine[0] = 64;
+    planarBuffer->m_bytesPerLine[1] = 36;
+    planarBuffer->m_bytesPerLine[2] = 36;
+    planarBuffer->m_planeCount = 3;
+    planarBuffer->m_numBytes = sizeof(bufferData);
+
+    QTest::newRow("Planar")
+            << QVideoFrame(planarBuffer, QSize(64, 64), QVideoFrame::Format_YUV420P)
+            << (QList<int>() << 64 << 36 << 36)
+            << (QList<int>() << 512 << 765);
+    QTest::newRow("Format_YUV420P")
+            << QVideoFrame(8096, QSize(60, 64), 64, QVideoFrame::Format_YUV420P)
+            << (QList<int>() << 64 << 62 << 62)
+            << (QList<int>() << 4096 << 6080);
+    QTest::newRow("Format_YV12")
+            << QVideoFrame(8096, QSize(60, 64), 64, QVideoFrame::Format_YV12)
+            << (QList<int>() << 64 << 62 << 62)
+            << (QList<int>() << 4096 << 6080);
+    QTest::newRow("Format_NV12")
+            << QVideoFrame(8096, QSize(60, 64), 64, QVideoFrame::Format_NV12)
+            << (QList<int>() << 64 << 64)
+            << (QList<int>() << 4096);
+    QTest::newRow("Format_NV21")
+            << QVideoFrame(8096, QSize(60, 64), 64, QVideoFrame::Format_NV21)
+            << (QList<int>() << 64 << 64)
+            << (QList<int>() << 4096);
+    QTest::newRow("Format_IMC2")
+            << QVideoFrame(8096, QSize(60, 64), 64, QVideoFrame::Format_IMC2)
+            << (QList<int>() << 64 << 64)
+            << (QList<int>() << 4096);
+    QTest::newRow("Format_IMC4")
+            << QVideoFrame(8096, QSize(60, 64), 64, QVideoFrame::Format_IMC4)
+            << (QList<int>() << 64 << 64)
+            << (QList<int>() << 4096);
+    QTest::newRow("Format_IMC1")
+            << QVideoFrame(8096, QSize(60, 64), 64, QVideoFrame::Format_IMC1)
+            << (QList<int>() << 64 << 64 << 64)
+            << (QList<int>() << 4096 << 6144);
+    QTest::newRow("Format_IMC3")
+            << QVideoFrame(8096, QSize(60, 64), 64, QVideoFrame::Format_IMC3)
+            << (QList<int>() << 64 << 64 << 64)
+            << (QList<int>() << 4096 << 6144);
+    QTest::newRow("Format_ARGB32")
+            << QVideoFrame(8096, QSize(60, 64), 256, QVideoFrame::Format_ARGB32)
+            << (QList<int>() << 256)
+            << (QList<int>());
+}
+
+void tst_QVideoFrame::mapPlanes()
+{
+    QFETCH(QVideoFrame, frame);
+    QFETCH(QList<int>, strides);
+    QFETCH(QList<int>, offsets);
+
+    QCOMPARE(strides.count(), offsets.count() + 1);
+
+    QCOMPARE(frame.map(QAbstractVideoBuffer::ReadOnly), true);
+    QCOMPARE(frame.planeCount(), strides.count());
+
+    QVERIFY(strides.count() > 0);
+    QCOMPARE(frame.bytesPerLine(0), strides.at(0));
+    QVERIFY(frame.bits(0));
+
+    if (strides.count() > 1) {
+        QCOMPARE(frame.bytesPerLine(1), strides.at(1));
+        QCOMPARE(int(frame.bits(1) - frame.bits(0)), offsets.at(0));
+    }
+    if (strides.count() > 2) {
+        QCOMPARE(frame.bytesPerLine(2), strides.at(2));
+        QCOMPARE(int(frame.bits(2) - frame.bits(0)), offsets.at(1));
+    }
+    if (strides.count() > 3) {
+        QCOMPARE(frame.bytesPerLine(3), strides.at(3));
+        QCOMPARE(int(frame.bits(3) - frame.bits(0)), offsets.at(0));
+    }
+
+    frame.unmap();
+}
+
 void tst_QVideoFrame::imageDetach()
 {
     const uint red = qRgb(255, 0, 0);
@@ -1028,154 +1141,6 @@ void tst_QVideoFrame::isWritable()
     frame.unmap();
 }
 
-void tst_QVideoFrame::debugType_data()
-{
-    QTest::addColumn<QVideoFrame::FieldType>("fieldType");
-    QTest::addColumn<QString>("stringized");
-
-    ADD_ENUM_TEST(ProgressiveFrame);
-    ADD_ENUM_TEST(InterlacedFrame);
-    ADD_ENUM_TEST(TopField);
-    ADD_ENUM_TEST(BottomField);
-}
-
-void tst_QVideoFrame::debugType()
-{
-    QFETCH(QVideoFrame::FieldType, fieldType);
-    QFETCH(QString, stringized);
-
-    QTest::ignoreMessage(QtDebugMsg, stringized.toLatin1().constData());
-    qDebug() << fieldType;
-}
-
-void tst_QVideoFrame::debug_data()
-{
-    QTest::addColumn<QVideoFrame>("frame");
-    QTest::addColumn<QString>("stringized");
-
-    QVideoFrame f;
-    QTest::newRow("default") << f << QString::fromLatin1("QVideoFrame(QSize(-1, -1) , Format_Invalid, NoHandle, NotMapped, [no timestamp])");
-
-    QVideoFrame f2;
-    f2.setStartTime(12345);
-    f2.setEndTime(8000000000LL);
-    QTest::newRow("times") << f2 << QString::fromLatin1("QVideoFrame(QSize(-1, -1) , Format_Invalid, NoHandle, NotMapped, 0:00:00.12345 - 2:13:20.00)");
-
-    QVideoFrame f3;
-    f3.setFieldType(QVideoFrame::ProgressiveFrame);
-    QTest::newRow("times prog") << f3 << QString::fromLatin1("QVideoFrame(QSize(-1, -1) , Format_Invalid, NoHandle, NotMapped, [no timestamp])");
-
-    QVideoFrame f4;
-    f4.setFieldType(QVideoFrame::TopField);
-    QTest::newRow("times top") << f4 << QString::fromLatin1("QVideoFrame(QSize(-1, -1) , Format_Invalid, NoHandle, NotMapped, [no timestamp])");
-
-    QVideoFrame f5;
-    f5.setFieldType(QVideoFrame::TopField);
-    f5.setEndTime(90000000000LL);
-    QTest::newRow("end but no start") << f5 << QString::fromLatin1("QVideoFrame(QSize(-1, -1) , Format_Invalid, NoHandle, NotMapped, [no timestamp])");
-
-    QVideoFrame f6;
-    f6.setStartTime(12345000000LL);
-    f6.setEndTime(80000000000LL);
-    QTest::newRow("times big") << f6 << QString::fromLatin1("QVideoFrame(QSize(-1, -1) , Format_Invalid, NoHandle, NotMapped, 3:25:45.00 - 22:13:20.00)");
-
-    QVideoFrame g(0, QSize(320,240), 640, QVideoFrame::Format_ARGB32);
-    QTest::newRow("more valid") << g << QString::fromLatin1("QVideoFrame(QSize(320, 240) , Format_ARGB32, NoHandle, NotMapped, [no timestamp])");
-
-    QVideoFrame g2(0, QSize(320,240), 640, QVideoFrame::Format_ARGB32);
-    g2.setStartTime(9000000000LL);
-    g2.setEndTime(9000000000LL);
-    QTest::newRow("more valid") << g2 << QString::fromLatin1("QVideoFrame(QSize(320, 240) , Format_ARGB32, NoHandle, NotMapped, @2:30:00.00)");
-
-    QVideoFrame g3(0, QSize(320,240), 640, QVideoFrame::Format_ARGB32);
-    g3.setStartTime(900000LL);
-    g3.setEndTime(900000LL);
-    QTest::newRow("more valid single timestamp") << g3 << QString::fromLatin1("QVideoFrame(QSize(320, 240) , Format_ARGB32, NoHandle, NotMapped, @00:00.900000)");
-
-    QVideoFrame g4(0, QSize(320,240), 640, QVideoFrame::Format_ARGB32);
-    g4.setStartTime(200000000LL);
-    g4.setEndTime(300000000LL);
-    QTest::newRow("more valid") << g4 << QString::fromLatin1("QVideoFrame(QSize(320, 240) , Format_ARGB32, NoHandle, NotMapped, 03:20.00 - 05:00.00)");
-
-    QVideoFrame g5(0, QSize(320,240), 640, QVideoFrame::Format_ARGB32);
-    g5.setStartTime(200000000LL);
-    QTest::newRow("more valid until forever") << g5 << QString::fromLatin1("QVideoFrame(QSize(320, 240) , Format_ARGB32, NoHandle, NotMapped, 03:20.00 - forever)");
-
-    QVideoFrame g6(0, QSize(320,240), 640, QVideoFrame::Format_ARGB32);
-    g6.setStartTime(9000000000LL);
-    QTest::newRow("more valid for long forever") << g6 << QString::fromLatin1("QVideoFrame(QSize(320, 240) , Format_ARGB32, NoHandle, NotMapped, 2:30:00.00 - forever)");
-
-    QVideoFrame g7(0, QSize(320,240), 640, QVideoFrame::Format_ARGB32);
-    g7.setStartTime(9000000000LL);
-    g7.setMetaData("bar", 42);
-    QTest::newRow("more valid for long forever + metadata") << g7 << QString::fromLatin1("QVideoFrame(QSize(320, 240) , Format_ARGB32, NoHandle, NotMapped, 2:30:00.00 - forever, metaData: QMap((\"bar\", QVariant(int, 42) ) ) )");
-}
-
-void tst_QVideoFrame::debug()
-{
-    QFETCH(QVideoFrame, frame);
-    QFETCH(QString, stringized);
-
-    QTest::ignoreMessage(QtDebugMsg, stringized.toLatin1().constData());
-    qDebug() << frame;
-}
-
-void tst_QVideoFrame::debugFormat_data()
-{
-    QTest::addColumn<QVideoFrame::PixelFormat>("format");
-    QTest::addColumn<QString>("stringized");
-
-    ADD_ENUM_TEST(Format_Invalid);
-    ADD_ENUM_TEST(Format_ARGB32);
-    ADD_ENUM_TEST(Format_ARGB32_Premultiplied);
-    ADD_ENUM_TEST(Format_RGB32);
-    ADD_ENUM_TEST(Format_RGB24);
-    ADD_ENUM_TEST(Format_RGB565);
-    ADD_ENUM_TEST(Format_RGB555);
-    ADD_ENUM_TEST(Format_ARGB8565_Premultiplied);
-    ADD_ENUM_TEST(Format_BGRA32);
-    ADD_ENUM_TEST(Format_BGRA32_Premultiplied);
-    ADD_ENUM_TEST(Format_BGR32);
-    ADD_ENUM_TEST(Format_BGR24);
-    ADD_ENUM_TEST(Format_BGR565);
-    ADD_ENUM_TEST(Format_BGR555);
-    ADD_ENUM_TEST(Format_BGRA5658_Premultiplied);
-
-    ADD_ENUM_TEST(Format_AYUV444);
-    ADD_ENUM_TEST(Format_AYUV444_Premultiplied);
-    ADD_ENUM_TEST(Format_YUV444);
-    ADD_ENUM_TEST(Format_YUV420P);
-    ADD_ENUM_TEST(Format_YV12);
-    ADD_ENUM_TEST(Format_UYVY);
-    ADD_ENUM_TEST(Format_YUYV);
-    ADD_ENUM_TEST(Format_NV12);
-    ADD_ENUM_TEST(Format_NV21);
-    ADD_ENUM_TEST(Format_IMC1);
-    ADD_ENUM_TEST(Format_IMC2);
-    ADD_ENUM_TEST(Format_IMC3);
-    ADD_ENUM_TEST(Format_IMC4);
-    ADD_ENUM_TEST(Format_Y8);
-    ADD_ENUM_TEST(Format_Y16);
-
-    ADD_ENUM_TEST(Format_Jpeg);
-
-    ADD_ENUM_TEST(Format_CameraRaw);
-    ADD_ENUM_TEST(Format_AdobeDng);
-
-    // User enums are formatted differently
-    QTest::newRow("user 1000") << QVideoFrame::Format_User << QString::fromLatin1("UserType(1000)");
-    QTest::newRow("user 1005") << QVideoFrame::PixelFormat(QVideoFrame::Format_User + 5) << QString::fromLatin1("UserType(1005)");
-}
-
-void tst_QVideoFrame::debugFormat()
-{
-    QFETCH(QVideoFrame::PixelFormat, format);
-    QFETCH(QString, stringized);
-
-    QTest::ignoreMessage(QtDebugMsg, stringized.toLatin1().constData());
-    qDebug() << format;
-}
-
 QTEST_MAIN(tst_QVideoFrame)
 
 #include "tst_qvideoframe.moc"
diff --git a/tests/auto/unit/qvideosurfaceformat/tst_qvideosurfaceformat.cpp b/tests/auto/unit/qvideosurfaceformat/tst_qvideosurfaceformat.cpp
index 0a78e1b..35e76b7 100644
--- a/tests/auto/unit/qvideosurfaceformat/tst_qvideosurfaceformat.cpp
+++ b/tests/auto/unit/qvideosurfaceformat/tst_qvideosurfaceformat.cpp
@@ -93,8 +93,6 @@ private slots:
     void assignAllParameters ();
 
     void propertyEdgeCases();
-    void debugOperator();
-    void debugOperator_data();
 };
 
 tst_QVideoSurfaceFormat::tst_QVideoSurfaceFormat()
@@ -918,108 +916,6 @@ void tst_QVideoSurfaceFormat::propertyEdgeCases()
     QCOMPARE(original.pixelAspectRatio(), QSize(53, 45));
 }
 
-#define ADDDEBUGTEST(format, w, h, r) \
-    QTest::newRow(#format "-" #w "x" #h "@" #r) \
-        << QVideoFrame::Format_ ##format \
-        << "Format_" #format \
-        << QSize(w, h) \
-        << r;
-
-void tst_QVideoSurfaceFormat::debugOperator_data()
-{
-    // This is not too exhaustive
-    QTest::addColumn<QVideoFrame::PixelFormat>("format");
-    QTest::addColumn<QString>("formatString");
-    QTest::addColumn<QSize>("frameSize");
-    QTest::addColumn<int>("frameRate"); // could be double, but formatting is unstable
-
-    ADDDEBUGTEST(Invalid, 100, 200, 3);
-    ADDDEBUGTEST(ARGB32,101, 201, 4);
-    ADDDEBUGTEST(ARGB32_Premultiplied, 100, 202, 5);
-    ADDDEBUGTEST(RGB32, 8, 16, 30);
-    ADDDEBUGTEST(RGB24, 8, 16, 30);
-    ADDDEBUGTEST(RGB565, 8, 16, 30);
-    ADDDEBUGTEST(RGB555, 8, 16, 30);
-    ADDDEBUGTEST(ARGB8565_Premultiplied, 8, 16, 30);
-    ADDDEBUGTEST(BGRA32, 8, 16, 30);
-    ADDDEBUGTEST(BGRA32_Premultiplied, 8, 16, 30);
-    ADDDEBUGTEST(BGR32, 8, 16, 30);
-    ADDDEBUGTEST(BGR24, 8, 16, 30);
-    ADDDEBUGTEST(BGR565, 8, 16, 30);
-    ADDDEBUGTEST(BGR555, 8, 16, 30);
-    ADDDEBUGTEST(BGRA5658_Premultiplied, 8, 16, 30);
-
-    ADDDEBUGTEST(AYUV444, 8, 16, 30);
-    ADDDEBUGTEST(AYUV444, 8, 16, 31);
-    ADDDEBUGTEST(AYUV444_Premultiplied, 8, 16, 30);
-    ADDDEBUGTEST(YUV444, 8, 16, 30);
-    ADDDEBUGTEST(YUV420P, 8, 16, 30);
-    ADDDEBUGTEST(YV12, 8, 16, 30);
-    ADDDEBUGTEST(UYVY, 8, 16, 30);
-    ADDDEBUGTEST(YUYV, 8, 16, 30);
-    ADDDEBUGTEST(NV12, 8, 16, 30);
-    ADDDEBUGTEST(NV12, 80, 16, 30);
-    ADDDEBUGTEST(NV21, 8, 16, 30);
-    ADDDEBUGTEST(IMC1, 8, 16, 30);
-    ADDDEBUGTEST(IMC2, 8, 16, 30);
-    ADDDEBUGTEST(IMC3, 8, 16, 30);
-    ADDDEBUGTEST(IMC3, 8, 160, 30);
-    ADDDEBUGTEST(IMC4, 8, 16, 30);
-    ADDDEBUGTEST(Y8, 8, 16, 30);
-    ADDDEBUGTEST(Y16, 8, 16, 30);
-
-    ADDDEBUGTEST(Jpeg, 8, 16, 30);
-
-    ADDDEBUGTEST(CameraRaw, 8, 16, 30);
-    ADDDEBUGTEST(AdobeDng, 8, 16, 30);
-
-    // User is special
-    QTest::newRow("User-0x0@0)")
-                  << QVideoFrame::Format_User
-                  << "UserType(1000)"
-                  << QSize()
-                  << 0;
-}
-
-void tst_QVideoSurfaceFormat::debugOperator()
-{
-    QFETCH(QVideoFrame::PixelFormat, format);
-    QFETCH(QString, formatString);
-    QFETCH(QSize, frameSize);
-    QFETCH(int, frameRate);
-
-    QString templateOutput = QString("QVideoSurfaceFormat(%1, QSize(%2, %3) , viewport=QRect(0,1 800x600) , pixelAspectRatio=QSize(320, 200) "
-        ", handleType=GLTextureHandle, yCbCrColorSpace=YCbCr_BT709)\n"
-        "    handleType = QVariant(QAbstractVideoBuffer::HandleType, ) \n"
-        "     pixelFormat  =  QVariant(QVideoFrame::PixelFormat, ) \n"
-        "     frameSize  =  QVariant(QSize, QSize(%4, %5) ) \n"
-        "     frameWidth  =  QVariant(int, %6) \n"
-        "     viewport  =  QVariant(QRect, QRect(0,1 800x600) ) \n"
-        "     scanLineDirection  =  QVariant(QVideoSurfaceFormat::Direction, ) \n"
-        "     frameRate  =  QVariant(%7, %8) \n"
-        "     pixelAspectRatio  =  QVariant(QSize, QSize(320, 200) ) \n"
-        "     sizeHint  =  QVariant(QSize, QSize(1280, 600) ) \n"
-        "     yCbCrColorSpace  =  QVariant(QVideoSurfaceFormat::YCbCrColorSpace, )  ")
-            .arg(formatString)
-            .arg(frameSize.width())
-            .arg(frameSize.height())
-            .arg(frameSize.width())
-            .arg(frameSize.height())
-            .arg(frameSize.width())
-            .arg(sizeof(qreal) == sizeof(double) ? "double" : "float")
-            .arg(frameRate);
-
-    QVideoSurfaceFormat vsf(frameSize, format, QAbstractVideoBuffer::GLTextureHandle);
-    vsf.setViewport(QRect(0,1, 800, 600));
-    vsf.setPixelAspectRatio(QSize(320, 200));
-    vsf.setYCbCrColorSpace(QVideoSurfaceFormat::YCbCr_BT709);
-    vsf.setFrameRate(frameRate);
-
-    QTest::ignoreMessage(QtDebugMsg, templateOutput.toLatin1().constData());
-    qDebug() << vsf;
-}
-
-
 
 QTEST_MAIN(tst_QVideoSurfaceFormat)
 
